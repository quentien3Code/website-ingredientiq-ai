import io
from concurrent.futures import ThreadPoolExecutor, TimeoutError
import json
import random
import ssl
import tempfile
import boto3

# Configure SSL context to handle certificate verification issues
ssl_context = ssl.create_default_context()
ssl_context.check_hostname = False
ssl_context.verify_mode = ssl.CERT_NONE
from botocore.exceptions import ClientError, NoCredentialsError
from django.utils import timezone
from datetime import timedelta
import openai
import hashlib
import threading
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from fuzzywuzzy import fuzz
from django.contrib.auth import login
from .serializers import FAQSerializer, AboutSerializer, AllergenDietaryCheckSerializer, FAQSerializer, SignupSerializer, LoginSerializer, ForgotPasswordRequestSerializer, UpdateUserProfileSerializer, UserSettingsSerializer, VerifyOTPSerializer,ChangePasswordSerializer,HealthPreferenceSerializer, privacypolicySerializer, termsandconditionSerializer, userGetSerializer, userPatchSerializer, FoodLabelScanSerializer, FeedbackSerializer, LoveAppSerializer, DepartmentContactSerializer, NotificationToggleSerializer
from .models import FoodLabelScan, MonthlyScanUsage, Termandcondition, User, UserSubscription, privacypolicy, AboutUS, FAQ,StripeCustomer, Feedback, DepartmentContact, AccountDeletionRequest, DownloadPDF, DownloadRequest
from panel.models import OnboardingQuestion, OnboardingChoice, OnboardingAnswer
from .enhanced_ai_analysis import EnhancedAIAnalysis
from .performance_optimization import PerformanceOptimizer
from .barcode_scanner_optimization import BarcodeScannerOptimizer
from .ssl_fix import get_ssl_connector
from django.core.mail import send_mail
from django.utils.decorators import method_decorator
from django.views.decorators.csrf import csrf_exempt
from rest_framework_simplejwt.tokens import RefreshToken
from rest_framework.permissions import IsAuthenticated, IsAdminUser
from .permissions import IsSuperAdmin
# from paddleocr import PaddleOCR
import re
# import easyocr
from io import BytesIO
# from .apps import YourAppConfig
from django.http import HttpResponse
import asyncio
import aiohttp
import numpy as np
from .utils import get_comprehensive_discount_info, send_sms, is_eligible_for_new_user_discount, get_discount_info, get_subscription_prices
# from .utils import extract_nutrition_info_from_text
from PIL import Image
from foodanalysis import settings
import os
from bs4 import BeautifulSoup
from rest_framework.parsers import MultiPartParser, FormParser, JSONParser
from django.http import JsonResponse
from django.core.exceptions import ObjectDoesNotExist
from django.core.mail import send_mail, BadHeaderError
from django.contrib.auth import logout
import cv2
import time
import logging
import os
from PIL import Image, ImageEnhance, ImageFilter
import uuid
from django.core.files.base import ContentFile
import requests
from django.core.files.storage import default_storage
# from allauth.socialaccount.models import SocialApp
from django.shortcuts import redirect
from pytrends.request import TrendReq
from geopy.geocoders import Nominatim
from collections import Counter
from geopy.exc import GeocoderTimedOut
from django.core.cache import cache 
import stripe
from .utils import fetch_llm_insight, fetch_medlineplus_summary, fetch_pubchem_toxicology_summary, fetch_pubmed_articles, fetch_efsa_openfoodtox_data, fetch_efsa_ingredient_summary, fetch_fsa_hygiene_rating, fetch_fsa_hygiene_summary, search_fsa_establishments_by_product, fetch_snomed_ct_data, fetch_icd10_data, get_medical_condition_food_recommendations
from asgiref.sync import sync_to_async
from django.views.decorators.csrf import csrf_exempt
import aiohttp
import asyncio
# import concurrent.futures
from openai import OpenAI
# from .openfoodfacts_api import openfoodfacts_api
openfoodfacts_api = "https://world.openfoodfacts.org/api/v0/product/"
USE_STATIC_INGREDIENT_SAFETY = False    
# openai.api_key = os.getenv("OPENAI_API_KEY")
# import feedparser  # For Medium RSS feeds
client = OpenAI(api_key="OPENAI_API_KEY_REMOVED")
BASE_URL = "https://api.spoonacular.com"
WIKIPEDIA_API_URL = "https://en.wikipedia.org/api/rest_v1/page/summary/"
OPEN_FOOD_FACTS_API = "https://world.openfoodfacts.org/api/v0/product/"
USDA_API_KEY = os.getenv("USDA_API_KEY")
API_KEY = os.getenv("foursquare_api_key")
WIKIPEDIA_API_URL = "https://en.wikipedia.org/api/rest_v1/page/summary/"
WORDPRESS_API_URL = "https://public-api.wordpress.com/rest/v1.1/sites/example.wordpress.com/posts/"
WORDPRESS_BLOG_URL = "https://public-api.wordpress.com/rest/v1.1/sites/example.wordpress.com/posts"
EDAMAM_APP_ID = os.getenv("EDAMAM_APP_ID")
EDAMAM_APP_KEY = os.getenv("EDAMAM_APP_KEY")
SPOONACULAR_KEY = "c01bfdfb4ccd4d8097b5110f789e0618"
WIKIPEDIA_SEARCH_API_URL = "https://en.wikipedia.org/w/api.php"
WHO_SEARCH_URL = "https://www.who.int/search?q="
WIKIPEDIA_LINKS_API = "https://en.wikipedia.org/w/api.php"
UNSPLASH_ACCESS_KEY = os.getenv("UNSPLASH_ACCESS_KEY")
stripe.api_key = os.getenv("STRIPE_SECRET_KEY")
# openai.api_key = "OPENAI_API_KEY_REMOVED"

# Singleton EasyOCR reader and GPU check
# _easyocr_reader = None
# _easyocr_lock = threading.Lock()
# _easyocr_gpu = None

# def get_easyocr_reader():
#     global _easyocr_reader, _easyocr_gpu
#     with _easyocr_lock:
#         if _easyocr_reader is None:
#             try:
#                 _easyocr_reader = easyocr.Reader(['en'], gpu=True)
#                 # Check if GPU is actually used
#                 _easyocr_gpu = _easyocr_reader.gpu
#                 logging.info(f"EasyOCR initialized. GPU used: {_easyocr_gpu}")
#             except Exception as e:
#                 logging.error(f"EasyOCR initialization failed: {e}")
#                 _easyocr_reader = easyocr.Reader(['en'], gpu=False)
#                 _easyocr_gpu = False
#         return _easyocr_reader

# def is_easyocr_gpu():
#     global _easyocr_gpu
#     return _easyocr_gpu

def google_login(request):
    # google = SocialApp.objects.get(provider='google')
    # return redirect(f"https://accounts.google.com/o/oauth2/auth?client_id={google.client_id}&redirect_uri=http://localhost:8000/accounts/google/login/callback/&response_type=code&scope=email profile")
    pass  # Social login temporarily disabled due to SQLite JSONField incompatibility

class SignupAPIView(APIView):
    def post(self, request):
        serializer = SignupSerializer(data=request.data)
        if serializer.is_valid():
            user = serializer.save()
            
            # Generate JWT tokens
            refresh = RefreshToken.for_user(user)
            access_token = str(refresh.access_token)

            return Response({
                'message': 'User created successfully.',
                'access_token': access_token,
                'refresh_token': str(refresh),
                'is_2fa_enabled': user.is_2fa_enabled,
                'has_answered_onboarding': user.has_answered_onboarding,
            }, status=status.HTTP_201_CREATED)

        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


@method_decorator(csrf_exempt, name='dispatch')
class LoginAPIView(APIView):
    def _get_user_subscription_plan(self, user):
        """Get accurate subscription plan for user"""
        from .models import UserSubscription
        try:
            sub = UserSubscription.objects.get(user=user)
            if sub.is_premium:
                return f"{sub.premium_type.capitalize()} Premium" if sub.premium_type else "Premium"
        except UserSubscription.DoesNotExist:
            pass
        return "Freemium plan"
    
    def post(self, request):
        serializer = LoginSerializer(data=request.data)
        if serializer.is_valid():
            user = serializer.validated_data['user']
            
            # Cancel any pending deletion request when user logs in
            deletion_cancellation = cancel_deletion_request_on_login(user)

            if user.is_2fa_enabled:  # Check if 2FA is enabled
                from random import randint
                from django.core.mail import send_mail

                otp_code = randint(100000, 999999)  # Generate 6-digit OTP
                user.otp = str(otp_code)
                user.save()

                # Send OTP via email
                send_mail(
                    "Your OTP Code",
                    f"Your OTP code is: {otp_code}",
                    "no-reply@example.com",
                    [user.email],
                    fail_silently=False,
                )

                response_data = {
                    "message": "OTP sent to your email. Please verify to continue.",
                    "user_id": user.id,
                    "is_2fa_enabled": user.is_2fa_enabled,
                    "has_answered_onboarding": user.has_answered_onboarding, # <-- Added here
                    # "subscription_plan": user.UserSubscription
                }
                
                # Add deletion cancellation message if applicable
                if deletion_cancellation['cancelled']:
                    response_data["deletion_cancelled"] = True
                    response_data["deletion_message"] = f"Your account deletion request has been cancelled. Your account was scheduled for deletion on {deletion_cancellation['scheduled_date'].strftime('%Y-%m-%d')} but has been cancelled since you logged in."
                
                return Response(response_data, status=status.HTTP_200_OK)

            # If 2FA is disabled, proceed with normal login
            refresh = RefreshToken.for_user(user)
            access_token = str(refresh.access_token)
            return Response({
                "message": "Login successful.",
                "access_token": access_token,
                "refresh_token": str(refresh),
                "is_2fa_enabled": user.is_2fa_enabled,
                "has_answered_onboarding": user.has_answered_onboarding,  # <-- Added here
                "subscription_plan": user.subscription_plan

            }, status=status.HTTP_200_OK)

        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

    
class Toggle2FAView(APIView):
    permission_classes = [IsAuthenticated]

    def post(self, request):
        user = request.user
        is_2fa_enabled = request.data.get("is_2fa_enabled", None)

        if is_2fa_enabled is None:
            return Response({"error": "is_2fa_enabled field is required"}, status=status.HTTP_400_BAD_REQUEST)

        user.is_2fa_enabled = is_2fa_enabled
        user.save()
        
        return Response({
            "message": f"Two-Factor Authentication {'enabled' if is_2fa_enabled else 'disabled'} successfully.",
            "is_2fa_enabled": user.is_2fa_enabled
        }, status=status.HTTP_200_OK)

class changepasswordView(APIView):
    permission_classes = [IsAuthenticated]
    
    def post(self, request):
        serializer = ChangePasswordSerializer(data=request.data)
        if serializer.is_valid():
            user = request.user
            old_password = serializer.validated_data['old_password']
            new_password = serializer.validated_data['new_password']
            
            if not user.check_password(old_password):
                return Response({'error': 'Old password is incorrect'}, status=status.HTTP_400_BAD_REQUEST)
            
            user.set_password(new_password)
            user.save()
            return Response({'message': 'Password changed successfully'}, status=status.HTTP_200_OK)
        
        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

class SignupAPIView(APIView):
    def post(self, request):
        serializer = SignupSerializer(data=request.data)
        if serializer.is_valid():
            user = serializer.save()
            
            # Generate JWT tokens
            refresh = RefreshToken.for_user(user)
            access_token = str(refresh.access_token)

            return Response({
                'message': 'User created successfully.',
                'access_token': access_token,
                'refresh_token': str(refresh),
                'is_2fa_enabled': user.is_2fa_enabled,
                'has_answered_onboarding': user.has_answered_onboarding,
            }, status=status.HTTP_201_CREATED)

        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


@method_decorator(csrf_exempt, name='dispatch')
class LoginAPIView(APIView):
    def _get_user_subscription_plan(self, user):
        """Get accurate subscription plan for user"""
        from .models import UserSubscription
        try:
            sub = UserSubscription.objects.get(user=user)
            if sub.is_premium:
                return f"{sub.premium_type.capitalize()} Premium" if sub.premium_type else "Premium"
        except UserSubscription.DoesNotExist:
            pass
        return "Freemium plan"
    
    def post(self, request):
        serializer = LoginSerializer(data=request.data)
        if serializer.is_valid():
            user = serializer.validated_data['user']
            
            # Cancel any pending deletion request when user logs in
            deletion_cancellation = cancel_deletion_request_on_login(user)

            if user.is_2fa_enabled:  # Check if 2FA is enabled
                from random import randint
                from django.core.mail import send_mail

                otp_code = randint(100000, 999999)  # Generate 6-digit OTP
                user.otp = str(otp_code)
                user.save()

                # Send OTP via email
                send_mail(
                    "Your OTP Code",
                    f"Your OTP code is: {otp_code}",
                    "no-reply@example.com",
                    [user.email],
                    fail_silently=False,
                )

                response_data = {
                    "message": "OTP sent to your email. Please verify to continue.",
                    "user_id": user.id,
                    "is_2fa_enabled": user.is_2fa_enabled,
                    "has_answered_onboarding": user.has_answered_onboarding, # <-- Added here
                    # "subscription_plan": user.UserSubscription
                }
                
                # Add deletion cancellation message if applicable
                if deletion_cancellation['cancelled']:
                    response_data["deletion_cancelled"] = True
                    response_data["deletion_message"] = f"Your account deletion request has been cancelled. Your account was scheduled for deletion on {deletion_cancellation['scheduled_date'].strftime('%Y-%m-%d')} but has been cancelled since you logged in."
                
                return Response(response_data, status=status.HTTP_200_OK)

            # If 2FA is disabled, proceed with normal login
            refresh = RefreshToken.for_user(user)
            access_token = str(refresh.access_token)
            return Response({
                "message": "Login successful.",
                "access_token": access_token,
                "refresh_token": str(refresh),
                "is_2fa_enabled": user.is_2fa_enabled,
                "has_answered_onboarding": user.has_answered_onboarding,  # <-- Added here
                "subscription_plan": user.subscription_plan

            }, status=status.HTTP_200_OK)

        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

    
class Toggle2FAView(APIView):
    permission_classes = [IsAuthenticated]

    def post(self, request):
        user = request.user
        is_2fa_enabled = request.data.get("is_2fa_enabled", None)

        if is_2fa_enabled is None:
            return Response({"error": "is_2fa_enabled field is required"}, status=status.HTTP_400_BAD_REQUEST)

        user.is_2fa_enabled = is_2fa_enabled
        user.save()
        
        return Response({
            "message": f"Two-Factor Authentication {'enabled' if is_2fa_enabled else 'disabled'} successfully.",
            "is_2fa_enabled": user.is_2fa_enabled
        }, status=status.HTTP_200_OK)

class changepasswordView(APIView):
    permission_classes = [IsAuthenticated]

    def post(self, request):
        email = request.user.email
        old_password = request.POST.get('old_password')
        new_password = request.POST.get('new_password')
        confirm_password = request.POST.get('confirm_password')
        if not old_password or not new_password or not confirm_password:
            message="Please provide all the fields -> old_password, new_password, confirm_password"
            return Response({"message":message}, status=status.HTTP_400_BAD_REQUEST)
        user = User.objects.get(email=email.lower())
        if not user.check_password(old_password):
            return JsonResponse({"message": "Old password is incorrect"}, status=status.HTTP_400_BAD_REQUEST)
        if new_password != confirm_password:
            return JsonResponse({'message': 'Passwords do not match'}, status=400)
        user.set_password(new_password)
        user.save()
        return JsonResponse({"message": "Password changed successfully"}, status=status.HTTP_200_OK)

def send_otp_email(email, otp_code):
    subject = "Your OTP Code for Password Reset"
    message = f"Your OTP code is: {otp_code}. It is valid for 5 minutes."
    from_email = (os.getenv("EMAIL_HOST_USER")) 
    recipient_list = [email]
    send_mail(subject, message, from_email, recipient_list)
    print(f"OTP {otp_code} sent to email: {email}")

class resendotpview(APIView):
    def post(self, request):
        try:
            identifier = request.data.get('email_or_phone', '').strip().lower()

            if not identifier:
                return JsonResponse({"message": "Please enter Email or Phone number"}, status=status.HTTP_400_BAD_REQUEST)

            otp = random.randint(1000, 9999)

            if '@' in identifier:
                try:
                    user = User.objects.get(email=identifier)
                except ObjectDoesNotExist:
                    return JsonResponse({"message": "User with this email not found"}, status=status.HTTP_400_BAD_REQUEST)

                user.otp = otp
                user.save()

                subject = "One Time Password"
                email_body = f"Your OTP is: {otp}\n\nUse this code to complete your verification."

                try:
                    send_mail(subject, email_body, 'AI IngredientIQ', [user.email], fail_silently=False)
                except BadHeaderError:
                    return JsonResponse({"message": "Invalid email header"}, status=status.HTTP_400_BAD_REQUEST)

                return JsonResponse({"data": "OTP sent to your email"}, status=status.HTTP_200_OK)

            else:
                try:
                    user = User.objects.get(phone_number=identifier)
                except ObjectDoesNotExist:
                    return JsonResponse({"message": "User with this phone number not found"}, status=status.HTTP_400_BAD_REQUEST)

                user.otp = otp
                user.save()

                message = f"Your OTP is: {otp}. Use this to complete your verification."
                send_sms(user.phone_number, message)

                return JsonResponse({"data": "OTP sent to your phone number"}, status=status.HTTP_200_OK)

        except Exception as e:
            return JsonResponse({"message": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

# Verify OTP API
class verifyotpview(APIView):
    def post(self, request):
        try:
            otp = request.data.get('otp', None)
            
            if not otp:
                return JsonResponse({"error": "OTP is required"}, status=status.HTTP_400_BAD_REQUEST)
            
            try:
                otp = int(otp)
            except ValueError:
                return JsonResponse({"error": "OTP should be a valid integer"}, status=status.HTTP_400_BAD_REQUEST)
            
            user = User.objects.filter(otp=otp).first()

            if user:
                user.otp = None  # Clear OTP after successful verification
                user.save()

                refresh = RefreshToken.for_user(user)
                access_token = str(refresh.access_token)

                return Response({
                    "message": "OTP Verified Successfully. Login successful.",
                    "access_token": access_token,
                    "refresh_token": str(refresh)
                }, status=status.HTTP_200_OK)

            return Response({"error": "Incorrect OTP"}, status=status.HTTP_400_BAD_REQUEST)

        except Exception as e:
            return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
@method_decorator(csrf_exempt, name='dispatch')
class ForgotPasswordRequestAPIView(APIView):
    permission_classes = [] 

    def post(self, request):
        email = request.data.get("email")  
        user = User.objects.filter(email=email).first()

        if not user:
            return Response({"detail": "User not found."}, status=status.HTTP_404_NOT_FOUND)

        serializer = ChangePasswordSerializer(data=request.data)

        if serializer.is_valid():
            new_password = serializer.validated_data['new_password']
            confirm_password = serializer.validated_data['confirm_password']

            if new_password != confirm_password:
                return Response({"detail": "Passwords must match."}, status=status.HTTP_400_BAD_REQUEST)

            if len(confirm_password) < 8:
                return Response({"detail": "New password must be at least 8 characters long."}, status=status.HTTP_400_BAD_REQUEST)

            user.set_password(confirm_password)
            user.save()

            return Response({"detail": "Password has been successfully reset."}, status=status.HTTP_200_OK)

        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


class changepasswordView(APIView):
    permission_classes = [IsAuthenticated]

    def post(self, request):
        email = request.user.email
        old_password = request.POST.get('old_password')
        new_password = request.POST.get('new_password')
        confirm_password = request.POST.get('confirm_password')
        if not old_password or not new_password or not confirm_password:
            message="Please provide all the fields -> old_password, new_password, confirm_password"
            return Response({"message":message}, status=status.HTTP_400_BAD_REQUEST)
        user = User.objects.get(email=email.lower())
        if not user.check_password(old_password):
            return JsonResponse({"message": "Old password is incorrect"}, status=status.HTTP_400_BAD_REQUEST)
        if new_password != confirm_password:
            return JsonResponse({'message': 'Passwords do not match'}, status=400)
        user.set_password(new_password)
        user.save()
        return JsonResponse({"message": "Password changed successfully"}, status=status.HTTP_200_OK)

class termsandconditionView(APIView):
    def get(self,request):
        user = Termandcondition.objects.all()
        serializer = termsandconditionSerializer(user,many=True)
        return Response({"data":serializer.data}, status=status.HTTP_200_OK)


class privacypolicyView(APIView):
    def get(self,request):
        user = privacypolicy.objects.all()
        serializer = privacypolicySerializer(user,many=True)
        return Response({"data":serializer.data}, status=status.HTTP_200_OK)

class Frequentlyasked(APIView):
    def get(self,request):
        user = FAQ.objects.all()
        serializer = FAQSerializer(user,many=True)
        return Response({"data":serializer.data},status=status.HTTP_200_OK)

class About(APIView):
    def get(self,request):
        user = AboutUS.objects.all()
        serializer = AboutSerializer(user,many=True)
        return Response({"data":serializer.data},status=status.HTTP_200_OK)

# class userprofileview(APIView):
#     permission_classes = [IsAuthenticated]
#     parser_classes = (MultiPartParser, FormParser)

#     def patch(self, request):
#         user = User.objects.get(email=request.user.email)

#         if not request.data:
#             return Response({"message": "No data provided to update."}, status=status.HTTP_400_BAD_REQUEST)

#         serializer = userPatchSerializer(user, data=request.data, partial=True)

#         if serializer.is_valid():
#             serializer.save()
#             profile_picture_url = None
#             if user.profile_picture:
#                 profile_picture_url = user.profile_picture.url
#                 print("------------", profile_picture_url)
#                 profile_picture_url = profile_picture_url.replace("https//", "")
#                 print("======", profile_picture_url)  
#             return Response(
#                 {"message": "Profile updated successfully."},
#                 status=status.HTTP_200_OK,
#             )

#         return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)
        
#     def get(self,request):
#         user = User.objects.select_related().get(email=request.user.email)
#         user.refresh_from_db()  # Force refresh from database
#         serializer = userGetSerializer(user)
#         # Add payment status info
#         from .models import UserSubscription
#         payment_status = 'freemium'
#         premium_type = None
#         try:
#             sub = UserSubscription.objects.get(user=user)
#             if sub.plan_name == 'premium':
#                 payment_status = 'premium'
#                 # Use a new field 'premium_type' if present, else fallback to 'unknown'
#                 premium_type = getattr(sub, 'premium_type', None)
#         except UserSubscription.DoesNotExist:
#             pass
#         data = serializer.data
#         data['payment_status'] = payment_status
#         data['premium_type'] = premium_type
#         return Response({"data":data}, status=status.HTTP_200_OK)
    
#     def delete(self, request):
#         user = User.objects.get(email=request.user.email)
        
#         # Check if user is premium or freemium
#         is_premium = False
#         try:
#             subscription = UserSubscription.objects.get(user=user)
#             is_premium = subscription.plan_name == 'premium' and subscription.is_active
#         except UserSubscription.DoesNotExist:
#             is_premium = False
        
#         if is_premium:
#             # Premium user - create deletion request with 30-day delay
#             from datetime import timedelta
#             scheduled_deletion_date = timezone.now() + timedelta(days=30)
            
#             # Check if there's already a pending deletion request
#             try:
#                 deletion_request = AccountDeletionRequest.objects.get(user=user, status='pending')
#                 return Response({
#                     "message": "You already have a pending account deletion request.",
#                     "scheduled_deletion_date": deletion_request.scheduled_deletion_date.isoformat(),
#                     "days_remaining": deletion_request.days_remaining,
#                     "status": "already_requested"
#                 }, status=status.HTTP_200_OK)
#             except AccountDeletionRequest.DoesNotExist:
#                 # Create new deletion request
#                 deletion_request = AccountDeletionRequest.objects.create(
#                     user=user,
#                     scheduled_deletion_date=scheduled_deletion_date,
#                     status='pending'
#                 )
                
#                 return Response({
#                     "message": "We have received your request for account deletion. Your account will be deleted in 30 days. If you log in during this period, your deletion request will be cancelled.",
#                     "scheduled_deletion_date": scheduled_deletion_date.isoformat(),
#                     "days_remaining": 30,
#                     "status": "deletion_scheduled"
#                 }, status=status.HTTP_200_OK)
#         else:
#             # Freemium user - delete immediately with proper foreign key handling
#             success, message = safe_delete_user(user)
#             if success:
#                 return Response({
#                     "message": "Your account has been deleted successfully.",
#                     "status": "deleted_immediately"
#                 }, status=status.HTTP_200_OK)
#             else:
#                 return Response({
#                     "error": f"Failed to delete account: {message}",
#                     "status": "deletion_failed"
#                 }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class LogoutView(APIView):
    permission_classes = [IsAuthenticated]

    def post(self, request):
        logout(request)
        return Response({"message": "Logged out successfully."}, status=status.HTTP_200_OK)

def can_user_scan(user):
    """
    Returns (True, scan_count, remaining_scans) if user can scan.
    Returns (False, scan_count, remaining_scans) if freemium and limit reached.
    Uses MonthlyScanUsage model for monthly tracking.
    """
    try:
        subscription = UserSubscription.objects.get(user=user)
        # Only 'freemium' is limited; all other plans are unlimited
        if subscription.plan_name.strip().lower() == "freemium":
            # Get or create current month's usage record
            usage = MonthlyScanUsage.get_or_create_current_month(user)
            scan_count = usage.scan_count
            remaining_scans = usage.get_remaining_scans()
            
            if scan_count >= 20:
                return False, scan_count, remaining_scans
            return True, scan_count, remaining_scans
        # Any other plan: unlimited scans
        return True, None, None
    except UserSubscription.DoesNotExist:
        # Treat as freemium if no subscription found
        usage = MonthlyScanUsage.get_or_create_current_month(user)
        scan_count = usage.scan_count
        remaining_scans = usage.get_remaining_scans()
        
        if scan_count >= 20:
            return False, scan_count, remaining_scans
        return True, scan_count, remaining_scans

def get_user_plan_info(user):
    """
    Returns user's plan information including plan name, type, and status.
    """
    try:
        subscription = UserSubscription.objects.get(user=user)
        return {
            "plan_name": subscription.plan_name,
            "premium_type": subscription.premium_type,
            "status": subscription.status,
            "is_premium": subscription.plan_name.strip().lower() != "freemium"
        }
    except UserSubscription.DoesNotExist:
        return {
            "plan_name": "freemium",
            "premium_type": None,
            "status": "inactive",
            "is_premium": False
        }

def get_accurate_scan_count(user):
    """
    Returns the accurate scan count for a user based on actual FoodLabelScan objects.
    This ensures the count is accurate even if MonthlyScanUsage records are out of sync.
    """
    try:
        # Get the actual count of FoodLabelScan objects for this user
        actual_count = FoodLabelScan.objects.filter(user=user).count()
        
        # Update the MonthlyScanUsage record to sync with actual count
        usage = MonthlyScanUsage.get_or_create_current_month(user)
        if usage.scan_count != actual_count:
            usage.scan_count = actual_count
            usage.save()
            print(f"Synced scan count for user {user.email}: {usage.scan_count} -> {actual_count}")
        
        return actual_count
    except Exception as e:
        print(f"Error getting accurate scan count: {e}")
        return 0

def get_scan_count_at_time(user, scan_time):
    """
    Returns the scan count for a user at a specific point in time.
    This is used to show the correct scan count for historical scans.
    """
    try:
        # Count how many scans were created before or at the given time
        scan_count = FoodLabelScan.objects.filter(
            user=user,
            scanned_at__lte=scan_time
        ).count()
        
        return scan_count
    except Exception as e:
        print(f"Error getting scan count at time: {e}")
        return 0

def sync_all_user_scan_counts():
    """
    Sync all users' scan counts in MonthlyScanUsage with their actual FoodLabelScan objects.
    This should be run after deleting scans from admin panel to fix count discrepancies.
    """
    try:
        users = User.objects.all()
        synced_count = 0
        
        for user in users:
            actual_count = FoodLabelScan.objects.filter(user=user).count()
            usage = MonthlyScanUsage.get_or_create_current_month(user)
            
            if usage.scan_count != actual_count:
                old_count = usage.scan_count
                usage.scan_count = actual_count
                usage.save()
                print(f"Synced user {user.email}: {old_count} -> {actual_count}")
                synced_count += 1
        
        print(f"Synced scan counts for {synced_count} users")
        return synced_count
    except Exception as e:
        print(f"Error syncing scan counts: {e}")
        return 0

# Add a setting at the top of the file
USE_STATIC_INGREDIENT_SAFETY = False  # Set to True for instant local safety check, False to use Edamam

def increment_user_scan_count(user):
    """
    Increment the user's scan count for the current month.
    Returns the updated scan count and remaining scans.
    """
    try:
        usage = MonthlyScanUsage.get_or_create_current_month(user)
        usage.increment_scan()
        return usage.scan_count, usage.get_remaining_scans()
    except Exception as e:
        print(f"Error incrementing scan count: {e}")
        return 0, 0


def google_login(request):
    # google = SocialApp.objects.get(provider='google')
    # return redirect(f"https://accounts.google.com/o/oauth2/auth?client_id={google.client_id}&redirect_uri=http://localhost:8000/accounts/google/login/callback/&response_type=code&scope=email profile")
    pass  # Social login temporarily disabled due to SQLite JSONField incompatibility

class SignupAPIView(APIView):
    def post(self, request):
        serializer = SignupSerializer(data=request.data)
        if serializer.is_valid():
            user = serializer.save()
            
            # Generate JWT tokens
            refresh = RefreshToken.for_user(user)
            access_token = str(refresh.access_token)

            return Response({
                'message': 'User created successfully.',
                'access_token': access_token,
                'refresh_token': str(refresh),
                'is_2fa_enabled': user.is_2fa_enabled,
                'has_answered_onboarding': user.has_answered_onboarding,
            }, status=status.HTTP_201_CREATED)

        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


@method_decorator(csrf_exempt, name='dispatch')
class LoginAPIView(APIView):
    def _get_user_subscription_plan(self, user):
        """Get accurate subscription plan for user"""
        from .models import UserSubscription
        try:
            sub = UserSubscription.objects.get(user=user)
            if sub.is_premium:
                return f"{sub.premium_type.capitalize()} Premium" if sub.premium_type else "Premium"
        except UserSubscription.DoesNotExist:
            pass
        return "Freemium plan"
    
    def post(self, request):
        serializer = LoginSerializer(data=request.data)
        if serializer.is_valid():
            user = serializer.validated_data['user']
            
            # Cancel any pending deletion request when user logs in
            deletion_cancellation = cancel_deletion_request_on_login(user)

            if user.is_2fa_enabled:  # Check if 2FA is enabled
                from random import randint
                from django.core.mail import send_mail

                otp_code = randint(100000, 999999)  # Generate 6-digit OTP
                user.otp = str(otp_code)
                user.save()

                # Send OTP via email
                send_mail(
                    "Your OTP Code",
                    f"Your OTP code is: {otp_code}",
                    "no-reply@example.com",
                    [user.email],
                    fail_silently=False,
                )

                response_data = {
                    "message": "OTP sent to your email. Please verify to continue.",
                    "user_id": user.id,
                    "is_2fa_enabled": user.is_2fa_enabled,
                    "has_answered_onboarding": user.has_answered_onboarding, # <-- Added here
                    # "subscription_plan": user.UserSubscription
                }
                
                # Add deletion cancellation message if applicable
                if deletion_cancellation['cancelled']:
                    response_data["deletion_cancelled"] = True
                    response_data["deletion_message"] = f"Your account deletion request has been cancelled. Your account was scheduled for deletion on {deletion_cancellation['scheduled_date'].strftime('%Y-%m-%d')} but has been cancelled since you logged in."
                
                return Response(response_data, status=status.HTTP_200_OK)

            # If 2FA is disabled, proceed with normal login
            refresh = RefreshToken.for_user(user)
            access_token = str(refresh.access_token)
            return Response({
                "message": "Login successful.",
                "access_token": access_token,
                "refresh_token": str(refresh),
                "is_2fa_enabled": user.is_2fa_enabled,
                "has_answered_onboarding": user.has_answered_onboarding,  # <-- Added here
                "subscription_plan": self._get_user_subscription_plan(user),
                "has_answered_onboarding": user.has_answered_onboarding,

            }, status=status.HTTP_200_OK)

        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

    
class Toggle2FAView(APIView):
    permission_classes = [IsAuthenticated]

    def post(self, request):
        user = request.user
        is_2fa_enabled = request.data.get("is_2fa_enabled", None)

        if is_2fa_enabled is None:
            return Response({"error": "is_2fa_enabled field is required"}, status=status.HTTP_400_BAD_REQUEST)

        user.is_2fa_enabled = is_2fa_enabled
        user.save()
        
        return Response({
            "message": f"Two-Factor Authentication {'enabled' if is_2fa_enabled else 'disabled'} successfully.",
            "is_2fa_enabled": user.is_2fa_enabled
        }, status=status.HTTP_200_OK)

class changepasswordView(APIView):
    permission_classes = [IsAuthenticated]

    def post(self, request):
        email = request.user.email
        old_password = request.POST.get('old_password')
        new_password = request.POST.get('new_password')
        confirm_password = request.POST.get('confirm_password')
        if not old_password or not new_password or not confirm_password:
            message="Please provide all the fields -> old_password, new_password, confirm_password"
            return Response({"message":message}, status=status.HTTP_400_BAD_REQUEST)
        user = User.objects.get(email=email.lower())
        if not user.check_password(old_password):
            return JsonResponse({"message": "Old password is incorrect"}, status=status.HTTP_400_BAD_REQUEST)
        if new_password != confirm_password:
            return JsonResponse({'message': 'Passwords do not match'}, status=400)
        user.set_password(new_password)
        user.save()
        return JsonResponse({"message": "Password changed successfully"}, status=status.HTTP_200_OK)

def send_otp_email(email, otp_code):
    subject = "Your OTP Code for Password Reset"
    message = f"Your OTP code is: {otp_code}. It is valid for 5 minutes."
    from_email = (os.getenv("EMAIL_HOST_USER")) 
    recipient_list = [email]
    send_mail(subject, message, from_email, recipient_list)
    print(f"OTP {otp_code} sent to email: {email}")

class resendotpview(APIView):
    def post(self, request):
        try:
            identifier = request.data.get('email_or_phone', '').strip().lower()

            if not identifier:
                return JsonResponse({"message": "Please enter Email or Phone number"}, status=status.HTTP_400_BAD_REQUEST)

            otp = random.randint(1000, 9999)

            if '@' in identifier:
                try:
                    user = User.objects.get(email=identifier)
                except ObjectDoesNotExist:
                    return JsonResponse({"message": "User with this email not found"}, status=status.HTTP_400_BAD_REQUEST)

                user.otp = otp
                user.save()

                subject = "One Time Password"
                email_body = f"Your OTP is: {otp}\n\nUse this code to complete your verification."

                try:
                    send_mail(subject, email_body, 'AI IngredientIQ', [user.email], fail_silently=False)
                except BadHeaderError:
                    return JsonResponse({"message": "Invalid email header"}, status=status.HTTP_400_BAD_REQUEST)

                return JsonResponse({"data": "OTP sent to your email"}, status=status.HTTP_200_OK)

            else:
                try:
                    user = User.objects.get(phone_number=identifier)
                except ObjectDoesNotExist:
                    return JsonResponse({"message": "User with this phone number not found"}, status=status.HTTP_400_BAD_REQUEST)

                user.otp = otp
                user.save()

                message = f"Your OTP is: {otp}. Use this to complete your verification."
                send_sms(user.phone_number, message)

                return JsonResponse({"data": "OTP sent to your phone number"}, status=status.HTTP_200_OK)

        except Exception as e:
            return JsonResponse({"message": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

# Verify OTP API
class verifyotpview(APIView):
    def post(self, request):
        try:
            otp = request.data.get('otp', None)
            
            if not otp:
                return JsonResponse({"error": "OTP is required"}, status=status.HTTP_400_BAD_REQUEST)
            
            try:
                otp = int(otp)
            except ValueError:
                return JsonResponse({"error": "OTP should be a valid integer"}, status=status.HTTP_400_BAD_REQUEST)
            
            user = User.objects.filter(otp=otp).first()

            if user:
                user.otp = None  # Clear OTP after successful verification
                user.save()

                refresh = RefreshToken.for_user(user)
                access_token = str(refresh.access_token)

                return Response({
                    "message": "OTP Verified Successfully. Login successful.",
                    "access_token": access_token,
                    "refresh_token": str(refresh)
                }, status=status.HTTP_200_OK)

            return Response({"error": "Incorrect OTP"}, status=status.HTTP_400_BAD_REQUEST)

        except Exception as e:
            return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
@method_decorator(csrf_exempt, name='dispatch')
class ForgotPasswordRequestAPIView(APIView):
    permission_classes = [] 

    def post(self, request):
        email = request.data.get("email")  
        user = User.objects.filter(email=email).first()

        if not user:
            return Response({"detail": "User not found."}, status=status.HTTP_404_NOT_FOUND)

        serializer = ChangePasswordSerializer(data=request.data)

        if serializer.is_valid():
            new_password = serializer.validated_data['new_password']
            confirm_password = serializer.validated_data['confirm_password']

            if new_password != confirm_password:
                return Response({"detail": "Passwords must match."}, status=status.HTTP_400_BAD_REQUEST)

            if len(confirm_password) < 8:
                return Response({"detail": "New password must be at least 8 characters long."}, status=status.HTTP_400_BAD_REQUEST)

            user.set_password(confirm_password)
            user.save()

            return Response({"detail": "Password has been successfully reset."}, status=status.HTTP_200_OK)

        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


class changepasswordView(APIView):
    permission_classes = [IsAuthenticated]

    def post(self, request):
        email = request.user.email
        old_password = request.POST.get('old_password')
        new_password = request.POST.get('new_password')
        confirm_password = request.POST.get('confirm_password')
        if not old_password or not new_password or not confirm_password:
            message="Please provide all the fields -> old_password, new_password, confirm_password"
            return Response({"message":message}, status=status.HTTP_400_BAD_REQUEST)
        user = User.objects.get(email=email.lower())
        if not user.check_password(old_password):
            return JsonResponse({"message": "Old password is incorrect"}, status=status.HTTP_400_BAD_REQUEST)
        if new_password != confirm_password:
            return JsonResponse({'message': 'Passwords do not match'}, status=400)
        user.set_password(new_password)
        user.save()
        return JsonResponse({"message": "Password changed successfully"}, status=status.HTTP_200_OK)

class termsandconditionView(APIView):
    def get(self,request):
        user = Termandcondition.objects.all()
        serializer = termsandconditionSerializer(user,many=True)
        return Response({"data":serializer.data}, status=status.HTTP_200_OK)


class privacypolicyView(APIView):
    def get(self,request):
        user = privacypolicy.objects.all()
        serializer = privacypolicySerializer(user,many=True)
        return Response({"data":serializer.data}, status=status.HTTP_200_OK)

class Frequentlyasked(APIView):
    def get(self,request):
        user = FAQ.objects.all()
        serializer = FAQSerializer(user,many=True)
        return Response({"data":serializer.data},status=status.HTTP_200_OK)

class About(APIView):
    def get(self,request):
        user = AboutUS.objects.all()
        serializer = AboutSerializer(user,many=True)
        return Response({"data":serializer.data},status=status.HTTP_200_OK)

# class userprofileview(APIView):
#     permission_classes = [IsAuthenticated]
#     parser_classes = (MultiPartParser, FormParser)

#     def patch(self, request):
#         user = User.objects.get(email=request.user.email)

#         if not request.data:
#             return Response({"message": "No data provided to update."}, status=status.HTTP_400_BAD_REQUEST)

#         serializer = userPatchSerializer(user, data=request.data, partial=True)

#         if serializer.is_valid():
#             serializer.save()
#             profile_picture_url = None
#             if user.profile_picture:
#                 profile_picture_url = user.profile_picture.url
#                 print("------------", profile_picture_url)
#                 profile_picture_url = profile_picture_url.replace("https//", "")
#                 print("======", profile_picture_url)  
#             return Response(
#                 {"message": "Profile updated successfully."},
#                 status=status.HTTP_200_OK,
#             )

#         return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)
        
#     def get(self,request):
#         user = User.objects.select_related().get(email=request.user.email)
#         user.refresh_from_db()  # Force refresh from database
#         serializer = userGetSerializer(user)
#         # Add payment status info
#         from .models import UserSubscription
#         payment_status = 'freemium'
#         premium_type = None
#         try:
#             sub = UserSubscription.objects.get(user=user)
#             if sub.plan_name == 'premium':
#                 payment_status = 'premium'
#                 # Use a new field 'premium_type' if present, else fallback to 'unknown'
#                 premium_type = getattr(sub, 'premium_type', None)
#         except UserSubscription.DoesNotExist:
#             pass
#         data = serializer.data
#         data['payment_status'] = payment_status
#         data['premium_type'] = premium_type
#         return Response({"data":data}, status=status.HTTP_200_OK)
    
#     def delete(self, request):
#         user = User.objects.get(email=request.user.email)
        
#         # Check if user is premium or freemium
#         is_premium = False
#         try:
#             subscription = UserSubscription.objects.get(user=user)
#             is_premium = subscription.plan_name == 'premium' and subscription.is_active
#         except UserSubscription.DoesNotExist:
#             is_premium = False
        
#         if is_premium:
#             # Premium user - create deletion request with 30-day delay
#             from datetime import timedelta
#             scheduled_deletion_date = timezone.now() + timedelta(days=30)
            
#             # Check if there's already a pending deletion request
#             try:
#                 deletion_request = AccountDeletionRequest.objects.get(user=user, status='pending')
#                 return Response({
#                     "message": "You already have a pending account deletion request.",
#                     "scheduled_deletion_date": deletion_request.scheduled_deletion_date.isoformat(),
#                     "days_remaining": deletion_request.days_remaining,
#                     "status": "already_requested"
#                 }, status=status.HTTP_200_OK)
#             except AccountDeletionRequest.DoesNotExist:
#                 # Create new deletion request
#                 deletion_request = AccountDeletionRequest.objects.create(
#                     user=user,
#                     scheduled_deletion_date=scheduled_deletion_date,
#                     status='pending'
#                 )
                
#                 return Response({
#                     "message": "We have received your request for account deletion. Your account will be deleted in 30 days. If you log in during this period, your deletion request will be cancelled.",
#                     "scheduled_deletion_date": scheduled_deletion_date.isoformat(),
#                     "days_remaining": 30,
#                     "status": "deletion_scheduled"
#                 }, status=status.HTTP_200_OK)
#         else:
#             # Freemium user - delete immediately with proper foreign key handling
#             success, message = safe_delete_user(user)
#             if success:
#                 return Response({
#                     "message": "Your account has been deleted successfully.",
#                     "status": "deleted_immediately"
#                 }, status=status.HTTP_200_OK)
#             else:
#                 return Response({
#                     "error": f"Failed to delete account: {message}",
#                     "status": "deletion_failed"
#                 }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class LogoutView(APIView):
    permission_classes = [IsAuthenticated]

    def post(self, request):
        logout(request)
        return Response({"message": "Logged out successfully."}, status=status.HTTP_200_OK)

def can_user_scan(user):
    """
    Returns (True, scan_count, remaining_scans) if user can scan.
    Returns (False, scan_count, remaining_scans) if freemium and limit reached.
    Uses MonthlyScanUsage model for monthly tracking.
    """
    try:
        subscription = UserSubscription.objects.get(user=user)
        # Only 'freemium' is limited; all other plans are unlimited
        if subscription.plan_name.strip().lower() == "freemium":
            # Get or create current month's usage record
            usage = MonthlyScanUsage.get_or_create_current_month(user)
            scan_count = usage.scan_count
            remaining_scans = usage.get_remaining_scans()
            
            if scan_count >= 20:
                return False, scan_count, remaining_scans
            return True, scan_count, remaining_scans
        # Any other plan: unlimited scans
        return True, None, None
    except UserSubscription.DoesNotExist:
        # Treat as freemium if no subscription found
        usage = MonthlyScanUsage.get_or_create_current_month(user)
        scan_count = usage.scan_count
        remaining_scans = usage.get_remaining_scans()
        
        if scan_count >= 20:
            return False, scan_count, remaining_scans
        return True, scan_count, remaining_scans

def get_user_plan_info(user):
    """
    Returns user's plan information including plan name, type, and status.
    """
    try:
        subscription = UserSubscription.objects.get(user=user)
        return {
            "plan_name": subscription.plan_name,
            "premium_type": subscription.premium_type,
            "status": subscription.status,
            "is_premium": subscription.plan_name.strip().lower() != "freemium"
        }
    except UserSubscription.DoesNotExist:
        return {
            "plan_name": "freemium",
            "premium_type": None,
            "status": "inactive",
            "is_premium": False
        }

def get_accurate_scan_count(user):
    """
    Returns the accurate scan count for a user based on actual FoodLabelScan objects.
    This ensures the count is accurate even if MonthlyScanUsage records are out of sync.
    """
    try:
        # Get the actual count of FoodLabelScan objects for this user
        actual_count = FoodLabelScan.objects.filter(user=user).count()
        
        # Update the MonthlyScanUsage record to sync with actual count
        usage = MonthlyScanUsage.get_or_create_current_month(user)
        if usage.scan_count != actual_count:
            usage.scan_count = actual_count
            usage.save()
            print(f"Synced scan count for user {user.email}: {usage.scan_count} -> {actual_count}")
        
        return actual_count
    except Exception as e:
        print(f"Error getting accurate scan count: {e}")
        return 0

def get_scan_count_at_time(user, scan_time):
    """
    Returns the scan count for a user at a specific point in time.
    This is used to show the correct scan count for historical scans.
    """
    try:
        # Count how many scans were created before or at the given time
        scan_count = FoodLabelScan.objects.filter(
            user=user,
            scanned_at__lte=scan_time
        ).count()
        
        return scan_count
    except Exception as e:
        print(f"Error getting scan count at time: {e}")
        return 0

def sync_all_user_scan_counts():
    """
    Sync all users' scan counts in MonthlyScanUsage with their actual FoodLabelScan objects.
    This should be run after deleting scans from admin panel to fix count discrepancies.
    """
    try:
        users = User.objects.all()
        synced_count = 0
        
        for user in users:
            actual_count = FoodLabelScan.objects.filter(user=user).count()
            usage = MonthlyScanUsage.get_or_create_current_month(user)
            
            if usage.scan_count != actual_count:
                old_count = usage.scan_count
                usage.scan_count = actual_count
                usage.save()
                print(f"Synced user {user.email}: {old_count} -> {actual_count}")
                synced_count += 1
        
        print(f"Synced scan counts for {synced_count} users")
        return synced_count
    except Exception as e:
        print(f"Error syncing scan counts: {e}")
        return 0

# Add a setting at the top of the file
USE_STATIC_INGREDIENT_SAFETY = False  # Set to True for instant local safety check, False to use Edamam

def increment_user_scan_count(user):
    """
    Increment the user's scan count for the current month.
    Returns the updated scan count and remaining scans.
    """
    try:
        usage = MonthlyScanUsage.get_or_create_current_month(user)
        usage.increment_scan()
        return usage.scan_count, usage.get_remaining_scans()
    except Exception as e:
        print(f"Error incrementing scan count: {e}")
        return 0, 0


def google_login(request):
    """
    Traditional OAuth2 flow for Google Sign-In
    """
    from django.shortcuts import redirect
    from urllib.parse import urlencode
    
    # Get Google OAuth2 credentials from settings
    client_id = getattr(settings, 'SOCIAL_AUTH_GOOGLE_OAUTH2_KEY', None) or os.getenv('SOCIAL_AUTH_GOOGLE_OAUTH2_KEY')
    
    if not client_id:
        return Response({"error": "Google OAuth2 not configured"}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
    
    # Build OAuth2 authorization URL
    params = {
        'client_id': client_id,
        'redirect_uri': request.build_absolute_uri('/accounts/google/login/callback/'),
        'response_type': 'code',
        'scope': 'email profile',
        'access_type': 'offline',
        'prompt': 'consent'
    }
    
    auth_url = f"https://accounts.google.com/o/oauth2/auth?{urlencode(params)}"
    return redirect(auth_url)

@method_decorator(csrf_exempt, name='dispatch')
class GoogleOAuth2CallbackView(APIView):
    """
    Handle Google OAuth2 callback and exchange authorization code for tokens
    """
    permission_classes = []
    
    def get(self, request):
        code = request.GET.get('code')
        error = request.GET.get('error')
        
        if error:
            return Response({"error": f"OAuth error: {error}"}, status=status.HTTP_400_BAD_REQUEST)
        
        if not code:
            return Response({"error": "No authorization code received"}, status=status.HTTP_400_BAD_REQUEST)
        
        # Exchange authorization code for access token
        client_id = getattr(settings, 'SOCIAL_AUTH_GOOGLE_OAUTH2_KEY', None) or os.getenv('SOCIAL_AUTH_GOOGLE_OAUTH2_KEY')
        client_secret = getattr(settings, 'SOCIAL_AUTH_GOOGLE_OAUTH2_SECRET', None) or os.getenv('SOCIAL_AUTH_GOOGLE_OAUTH2_SECRET')
        redirect_uri = request.build_absolute_uri('/accounts/google/login/callback/')
        
        # Exchange code for tokens
        token_response = requests.post('https://oauth2.googleapis.com/token', data={
            'client_id': client_id,
            'client_secret': client_secret,
            'code': code,
            'grant_type': 'authorization_code',
            'redirect_uri': redirect_uri
        })
        
        if token_response.status_code != 200:
            return Response({"error": "Failed to exchange authorization code"}, status=status.HTTP_400_BAD_REQUEST)
        
        token_data = token_response.json()
        access_token = token_data.get('access_token')
        
        # Get user info using access token
        user_info_response = requests.get(
            'https://www.googleapis.com/oauth2/v2/userinfo',
            headers={'Authorization': f'Bearer {access_token}'}
        )
        
        if user_info_response.status_code != 200:
            return Response({"error": "Failed to get user info"}, status=status.HTTP_400_BAD_REQUEST)
        
        user_info = user_info_response.json()
        email = user_info.get('email')
        
        if not email:
            return Response({"error": "No email in user info"}, status=status.HTTP_400_BAD_REQUEST)
        
        # Create or get user
        User = get_user_model()
        user, created = User.objects.get_or_create(
            email=email, 
            defaults={
                "username": email.split("@")[0],
                "full_name": user_info.get('name', ''),
                "profile_picture": user_info.get('picture', '')
            }
        )
        
        # Generate JWT tokens
        from rest_framework_simplejwt.tokens import RefreshToken
        refresh = RefreshToken.for_user(user)
        access_token = str(refresh.access_token)
        
        return Response({
            "access_token": access_token,
            "refresh_token": str(refresh),
            "created": created,
            "email": user.email,
            "full_name": user.full_name,
            "profile_picture": user.profile_picture,
            "has_answered_onboarding": user.has_answered_onboarding,  # Add onboarding status
            "subscription_plan": user.subscription_plan
        }, status=status.HTTP_200_OK)

class SignupAPIView(APIView):
    def post(self, request):
        serializer = SignupSerializer(data=request.data)
        if serializer.is_valid():
            user = serializer.save()
            
            # Generate JWT tokens
            refresh = RefreshToken.for_user(user)
            access_token = str(refresh.access_token)

            return Response({
                'message': 'User created successfully.',
                'access_token': access_token,
                'refresh_token': str(refresh),
                'is_2fa_enabled': user.is_2fa_enabled,
                'has_answered_onboarding': user.has_answered_onboarding,
            }, status=status.HTTP_201_CREATED)

        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


@method_decorator(csrf_exempt, name='dispatch')
class LoginAPIView(APIView):
    def _get_user_subscription_plan(self, user):
        """Get accurate subscription plan for user"""
        from .models import UserSubscription
        try:
            sub = UserSubscription.objects.get(user=user)
            if sub.is_premium:
                return f"{sub.premium_type.capitalize()} Premium" if sub.premium_type else "Premium"
        except UserSubscription.DoesNotExist:
            pass
        return "Freemium plan"
    
    def post(self, request):
        serializer = LoginSerializer(data=request.data)
        if serializer.is_valid():
            user = serializer.validated_data['user']
            
            # Cancel any pending deletion request when user logs in
            deletion_cancellation = cancel_deletion_request_on_login(user)

            if user.is_2fa_enabled:  # Check if 2FA is enabled
                from random import randint
                from django.core.mail import send_mail

                otp_code = randint(100000, 999999)  # Generate 6-digit OTP
                user.otp = str(otp_code)
                user.save()

                # Send OTP via email
                send_mail(
                    "Your OTP Code",
                    f"Your OTP code is: {otp_code}",
                    "no-reply@example.com",
                    [user.email],
                    fail_silently=False,
                )

                response_data = {
                    "message": "OTP sent to your email. Please verify to continue.",
                    "user_id": user.id,
                    "is_2fa_enabled": user.is_2fa_enabled,
                    "has_answered_onboarding": user.has_answered_onboarding, # <-- Added here
                    # "subscription_plan": user.UserSubscription
                }
                
                # Add deletion cancellation message if applicable
                if deletion_cancellation['cancelled']:
                    response_data["deletion_cancelled"] = True
                    response_data["deletion_message"] = f"Your account deletion request has been cancelled. Your account was scheduled for deletion on {deletion_cancellation['scheduled_date'].strftime('%Y-%m-%d')} but has been cancelled since you logged in."
                
                return Response(response_data, status=status.HTTP_200_OK)

            # If 2FA is disabled, proceed with normal login
            refresh = RefreshToken.for_user(user)
            access_token = str(refresh.access_token)
            response_data = {
                "message": "Login successful.",
                "access_token": access_token,
                "refresh_token": str(refresh),
                "is_2fa_enabled": user.is_2fa_enabled,
                "has_answered_onboarding": user.has_answered_onboarding,  # <-- Added here
                "subscription_plan": self._get_user_subscription_plan(user),
            }
            
            # Add deletion cancellation message if applicable
            if deletion_cancellation['cancelled']:
                response_data["deletion_cancelled"] = True
                response_data["deletion_message"] = f"Your account deletion request has been cancelled. Your account was scheduled for deletion on {deletion_cancellation['scheduled_date'].strftime('%Y-%m-%d')} but has been cancelled since you logged in."
            
            return Response(response_data, status=status.HTTP_200_OK)

        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

    
class Toggle2FAView(APIView):
    permission_classes = [IsAuthenticated]

    def post(self, request):
        user = request.user
        is_2fa_enabled = request.data.get("is_2fa_enabled", None)

        if is_2fa_enabled is None:
            return Response({"error": "is_2fa_enabled field is required"}, status=status.HTTP_400_BAD_REQUEST)

        user.is_2fa_enabled = is_2fa_enabled
        user.save()
        
        return Response({
            "message": f"Two-Factor Authentication {'enabled' if is_2fa_enabled else 'disabled'} successfully.",
            "is_2fa_enabled": user.is_2fa_enabled
        }, status=status.HTTP_200_OK)

class changepasswordView(APIView):
    permission_classes = [IsAuthenticated]

    def post(self, request):
        email = request.user.email
        old_password = request.POST.get('old_password')
        new_password = request.POST.get('new_password')
        confirm_password = request.POST.get('confirm_password')
        if not old_password or not new_password or not confirm_password:
            message="Please provide all the fields -> old_password, new_password, confirm_password"
            return Response({"message":message}, status=status.HTTP_400_BAD_REQUEST)
        user = User.objects.get(email=email.lower())
        if not user.check_password(old_password):
            return JsonResponse({"message": "Old password is incorrect"}, status=status.HTTP_400_BAD_REQUEST)
        if new_password != confirm_password:
            return JsonResponse({'message': 'Passwords do not match'}, status=400)
        user.set_password(new_password)
        user.save()
        return JsonResponse({"message": "Password changed successfully"}, status=status.HTTP_200_OK)

def send_otp_email(email, otp_code):
    subject = "Your OTP Code for Password Reset"
    message = f"Your OTP code is: {otp_code}. It is valid for 5 minutes."
    from_email = (os.getenv("EMAIL_HOST_USER")) 
    recipient_list = [email]
    send_mail(subject, message, from_email, recipient_list)
    print(f"OTP {otp_code} sent to email: {email}")

class resendotpview(APIView):
    def post(self, request):
        try:
            identifier = request.data.get('email_or_phone', '').strip().lower()

            if not identifier:
                return JsonResponse({"message": "Please enter Email or Phone number"}, status=status.HTTP_400_BAD_REQUEST)

            otp = random.randint(1000, 9999)

            if '@' in identifier:
                try:
                    user = User.objects.get(email=identifier)
                except ObjectDoesNotExist:
                    return JsonResponse({"message": "User with this email not found"}, status=status.HTTP_400_BAD_REQUEST)

                user.otp = otp
                user.save()

                subject = "One Time Password"
                email_body = f"Your OTP is: {otp}\n\nUse this code to complete your verification."

                try:
                    send_mail(subject, email_body, 'AI IngredientIQ', [user.email], fail_silently=False)
                except BadHeaderError:
                    return JsonResponse({"message": "Invalid email header"}, status=status.HTTP_400_BAD_REQUEST)

                return JsonResponse({"data": "OTP sent to your email"}, status=status.HTTP_200_OK)

            else:
                try:
                    user = User.objects.get(phone_number=identifier)
                except ObjectDoesNotExist:
                    return JsonResponse({"message": "User with this phone number not found"}, status=status.HTTP_400_BAD_REQUEST)

                user.otp = otp
                user.save()

                message = f"Your OTP is: {otp}. Use this to complete your verification."
                send_sms(user.phone_number, message)

                return JsonResponse({"data": "OTP sent to your phone number"}, status=status.HTTP_200_OK)

        except Exception as e:
            return JsonResponse({"message": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

# Verify OTP API
class verifyotpview(APIView):
    def post(self, request):
        try:
            otp = request.data.get('otp', None)
            
            if not otp:
                return JsonResponse({"error": "OTP is required"}, status=status.HTTP_400_BAD_REQUEST)
            
            try:
                otp = int(otp)
            except ValueError:
                return JsonResponse({"error": "OTP should be a valid integer"}, status=status.HTTP_400_BAD_REQUEST)
            
            user = User.objects.filter(otp=otp).first()

            if user:
                user.otp = None  # Clear OTP after successful verification
                user.save()

                refresh = RefreshToken.for_user(user)
                access_token = str(refresh.access_token)

                return Response({
                    "message": "OTP Verified Successfully. Login successful.",
                    "access_token": access_token,
                    "refresh_token": str(refresh)
                }, status=status.HTTP_200_OK)

            return Response({"error": "Incorrect OTP"}, status=status.HTTP_400_BAD_REQUEST)

        except Exception as e:
            return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
@method_decorator(csrf_exempt, name='dispatch')
class ForgotPasswordRequestAPIView(APIView):
    permission_classes = [] 

    def post(self, request):
        email = request.data.get("email")  
        user = User.objects.filter(email=email).first()

        if not user:
            return Response({"detail": "User not found."}, status=status.HTTP_404_NOT_FOUND)

        serializer = ChangePasswordSerializer(data=request.data)

        if serializer.is_valid():
            new_password = serializer.validated_data['new_password']
            confirm_password = serializer.validated_data['confirm_password']

            if new_password != confirm_password:
                return Response({"detail": "Passwords must match."}, status=status.HTTP_400_BAD_REQUEST)

            if len(confirm_password) < 8:
                return Response({"detail": "New password must be at least 8 characters long."}, status=status.HTTP_400_BAD_REQUEST)

            user.set_password(confirm_password)
            user.save()

            return Response({"detail": "Password has been successfully reset."}, status=status.HTTP_200_OK)

        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


class changepasswordView(APIView):
    permission_classes = [IsAuthenticated]

    def post(self, request):
        email = request.user.email
        old_password = request.POST.get('old_password')
        new_password = request.POST.get('new_password')
        confirm_password = request.POST.get('confirm_password')
        if not old_password or not new_password or not confirm_password:
            message="Please provide all the fields -> old_password, new_password, confirm_password"
            return Response({"message":message}, status=status.HTTP_400_BAD_REQUEST)
        user = User.objects.get(email=email.lower())
        if not user.check_password(old_password):
            return JsonResponse({"message": "Old password is incorrect"}, status=status.HTTP_400_BAD_REQUEST)
        if new_password != confirm_password:
            return JsonResponse({'message': 'Passwords do not match'}, status=400)
        user.set_password(new_password)
        user.save()
        return JsonResponse({"message": "Password changed successfully"}, status=status.HTTP_200_OK)

class termsandconditionView(APIView):
    def get(self,request):
        user = Termandcondition.objects.all()
        serializer = termsandconditionSerializer(user,many=True)
        return Response({"data":serializer.data}, status=status.HTTP_200_OK)


class privacypolicyView(APIView):
    def get(self,request):
        user = privacypolicy.objects.all()
        serializer = privacypolicySerializer(user,many=True)
        return Response({"data":serializer.data}, status=status.HTTP_200_OK)

class Frequentlyasked(APIView):
    def get(self,request):
        user = FAQ.objects.all()
        serializer = FAQSerializer(user,many=True)
        return Response({"data":serializer.data},status=status.HTTP_200_OK)

class About(APIView):
    def get(self,request):
        user = AboutUS.objects.all()
        serializer = AboutSerializer(user,many=True)
        return Response({"data":serializer.data},status=status.HTTP_200_OK)

# class userprofileview(APIView):
#     permission_classes = [IsAuthenticated]
#     parser_classes = (MultiPartParser, FormParser)

#     def patch(self, request):
#         user = User.objects.get(email=request.user.email)

#         if not request.data:
#             return Response({"message": "No data provided to update."}, status=status.HTTP_400_BAD_REQUEST)

#         serializer = userPatchSerializer(user, data=request.data, partial=True)

#         if serializer.is_valid():
#             serializer.save()
#             profile_picture_url = None
#             if user.profile_picture:
#                 profile_picture_url = user.profile_picture.url
#                 print("------------", profile_picture_url)
#                 profile_picture_url = profile_picture_url.replace("https//", "")
#                 print("======", profile_picture_url)  
#             return Response(
#                 {"message": "Profile updated successfully."},
#                 status=status.HTTP_200_OK,
#             )

#         return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)
        
#     def get(self,request):
#         user = User.objects.select_related().get(email=request.user.email)
#         user.refresh_from_db()  # Force refresh from database
#         serializer = userGetSerializer(user)
#         # Add payment status info
#         from .models import UserSubscription
#         payment_status = 'freemium'
#         premium_type = None
#         try:
#             sub = UserSubscription.objects.get(user=user)
#             if sub.plan_name == 'premium':
#                 payment_status = 'premium'
#                 # Use a new field 'premium_type' if present, else fallback to 'unknown'
#                 premium_type = getattr(sub, 'premium_type', None)
#         except UserSubscription.DoesNotExist:
#             pass
#         data = serializer.data
#         data['payment_status'] = payment_status
#         data['premium_type'] = premium_type
#         return Response({"data":data}, status=status.HTTP_200_OK)
    
#     def delete(self, request):
#         user = User.objects.get(email=request.user.email)
        
#         # Check if user is premium or freemium
#         is_premium = False
#         try:
#             subscription = UserSubscription.objects.get(user=user)
#             is_premium = subscription.plan_name == 'premium' and subscription.is_active
#         except UserSubscription.DoesNotExist:
#             is_premium = False
        
#         if is_premium:
#             # Premium user - create deletion request with 30-day delay
#             from datetime import timedelta
#             scheduled_deletion_date = timezone.now() + timedelta(days=30)
            
#             # Check if there's already a pending deletion request
#             try:
#                 deletion_request = AccountDeletionRequest.objects.get(user=user, status='pending')
#                 return Response({
#                     "message": "You already have a pending account deletion request.",
#                     "scheduled_deletion_date": deletion_request.scheduled_deletion_date.isoformat(),
#                     "days_remaining": deletion_request.days_remaining,
#                     "status": "already_requested"
#                 }, status=status.HTTP_200_OK)
#             except AccountDeletionRequest.DoesNotExist:
#                 # Create new deletion request
#                 deletion_request = AccountDeletionRequest.objects.create(
#                     user=user,
#                     scheduled_deletion_date=scheduled_deletion_date,
#                     status='pending'
#                 )
                
#                 return Response({
#                     "message": "We have received your request for account deletion. Your account will be deleted in 30 days. If you log in during this period, your deletion request will be cancelled.",
#                     "scheduled_deletion_date": scheduled_deletion_date.isoformat(),
#                     "days_remaining": 30,
#                     "status": "deletion_scheduled"
#                 }, status=status.HTTP_200_OK)
#         else:
#             # Freemium user - delete immediately with proper foreign key handling
#             success, message = safe_delete_user(user)
#             if success:
#                 return Response({
#                     "message": "Your account has been deleted successfully.",
#                     "status": "deleted_immediately"
#                 }, status=status.HTTP_200_OK)
#             else:
#                 return Response({
#                     "error": f"Failed to delete account: {message}",
#                     "status": "deletion_failed"
#                 }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class LogoutView(APIView):
    permission_classes = [IsAuthenticated]

    def post(self, request):
        logout(request)
        return Response({"message": "Logged out successfully."}, status=status.HTTP_200_OK)


def google_login(request):
    # google = SocialApp.objects.get(provider='google')
    # return redirect(f"https://accounts.google.com/o/oauth2/auth?client_id={google.client_id}&redirect_uri=http://localhost:8000/accounts/google/login/callback/&response_type=code&scope=email profile")
    pass  # Social login temporarily disabled due to SQLite JSONField incompatibility

class SignupAPIView(APIView):
    def post(self, request):
        serializer = SignupSerializer(data=request.data)
        if serializer.is_valid():
            user = serializer.save()
            
            # Generate JWT tokens
            refresh = RefreshToken.for_user(user)
            access_token = str(refresh.access_token)

            return Response({
                'message': 'User created successfully.',
                'access_token': access_token,
                'refresh_token': str(refresh),
                'has_answered_onboarding': user.has_answered_onboarding,
                'is_2fa_enabled': user.is_2fa_enabled
            }, status=status.HTTP_201_CREATED)

        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


@method_decorator(csrf_exempt, name='dispatch')
class LoginAPIView(APIView):
    def _get_user_subscription_plan(self, user):
        """Get accurate subscription plan for user"""
        from .models import UserSubscription
        try:
            sub = UserSubscription.objects.get(user=user)
            if sub.is_premium:
                return f"{sub.premium_type.capitalize()} Premium" if sub.premium_type else "Premium"
        except UserSubscription.DoesNotExist:
            pass
        return "Freemium plan"
    
    def post(self, request):
        serializer = LoginSerializer(data=request.data)
        if serializer.is_valid():
            user = serializer.validated_data['user']
            
            # Cancel any pending deletion request when user logs in
            deletion_cancellation = cancel_deletion_request_on_login(user)

            if user.is_2fa_enabled:  # Check if 2FA is enabled
                from random import randint
                from django.core.mail import send_mail

                otp_code = randint(100000, 999999)  # Generate 6-digit OTP
                user.otp = str(otp_code)
                user.save()

                # Send OTP via email
                send_mail(
                    "Your OTP Code",
                    f"Your OTP code is: {otp_code}",
                    "no-reply@example.com",
                    [user.email],
                    fail_silently=False,
                )

                response_data = {
                    "message": "OTP sent to your email. Please verify to continue.",
                    "user_id": user.id,
                    "is_2fa_enabled": user.is_2fa_enabled,
                    "has_answered_onboarding": user.has_answered_onboarding, # <-- Added here
                    # "subscription_plan": user.UserSubscription
                }
                
                # Add deletion cancellation message if applicable
                if deletion_cancellation['cancelled']:
                    response_data["deletion_cancelled"] = True
                    response_data["deletion_message"] = f"Your account deletion request has been cancelled. Your account was scheduled for deletion on {deletion_cancellation['scheduled_date'].strftime('%Y-%m-%d')} but has been cancelled since you logged in."
                
                return Response(response_data, status=status.HTTP_200_OK)

            # If 2FA is disabled, proceed with normal login
            refresh = RefreshToken.for_user(user)
            access_token = str(refresh.access_token)
            return Response({
                "message": "Login successful.",
                "access_token": access_token,
                "refresh_token": str(refresh),
                "is_2fa_enabled": user.is_2fa_enabled,
                "has_answered_onboarding": user.has_answered_onboarding,  # <-- Added here
                "subscription_plan": self._get_user_subscription_plan(user),
                "has_answered_onboarding": user.has_answered_onboarding,

            }, status=status.HTTP_200_OK)

        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

    
class Toggle2FAView(APIView):
    permission_classes = [IsAuthenticated]

    def post(self, request):
        user = request.user
        is_2fa_enabled = request.data.get("is_2fa_enabled", None)

        if is_2fa_enabled is None:
            return Response({"error": "is_2fa_enabled field is required"}, status=status.HTTP_400_BAD_REQUEST)

        user.is_2fa_enabled = is_2fa_enabled
        user.save()
        
        return Response({
            "message": f"Two-Factor Authentication {'enabled' if is_2fa_enabled else 'disabled'} successfully.",
            "is_2fa_enabled": user.is_2fa_enabled
        }, status=status.HTTP_200_OK)

class changepasswordView(APIView):
    permission_classes = [IsAuthenticated]
    
    def post(self, request):
        serializer = ChangePasswordSerializer(data=request.data)
        if serializer.is_valid():
            user = request.user
            old_password = serializer.validated_data['old_password']
            new_password = serializer.validated_data['new_password']
            
            if not user.check_password(old_password):
                return Response({'error': 'Old password is incorrect'}, status=status.HTTP_400_BAD_REQUEST)
            
            user.set_password(new_password)
            user.save()
            return Response({'message': 'Password changed successfully'}, status=status.HTTP_200_OK)
        
        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

class SignupAPIView(APIView):
    def post(self, request):
        serializer = SignupSerializer(data=request.data)
        if serializer.is_valid():
            user = serializer.save()
            
            # Generate JWT tokens
            refresh = RefreshToken.for_user(user)
            access_token = str(refresh.access_token)

            return Response({
                'message': 'User created successfully.',
                'access_token': access_token,
                'refresh_token': str(refresh),
                'is_2fa_enabled': user.is_2fa_enabled,
                'has_answered_onboarding': user.has_answered_onboarding,
            }, status=status.HTTP_201_CREATED)

        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


@method_decorator(csrf_exempt, name='dispatch')
class LoginAPIView(APIView):
    def _get_user_subscription_plan(self, user):
        """Get accurate subscription plan for user"""
        from .models import UserSubscription
        try:
            sub = UserSubscription.objects.get(user=user)
            if sub.is_premium:
                return f"{sub.premium_type.capitalize()} Premium" if sub.premium_type else "Premium"
        except UserSubscription.DoesNotExist:
            pass
        return "Freemium plan"
    
    def post(self, request):
        serializer = LoginSerializer(data=request.data)
        if serializer.is_valid():
            user = serializer.validated_data['user']
            
            # Cancel any pending deletion request when user logs in
            deletion_cancellation = cancel_deletion_request_on_login(user)

            if user.is_2fa_enabled:  # Check if 2FA is enabled
                from random import randint
                from django.core.mail import send_mail

                otp_code = randint(100000, 999999)  # Generate 6-digit OTP
                user.otp = str(otp_code)
                user.save()

                # Send OTP via email
                send_mail(
                    "Your OTP Code",
                    f"Your OTP code is: {otp_code}",
                    "no-reply@example.com",
                    [user.email],
                    fail_silently=False,
                )

                response_data = {
                    "message": "OTP sent to your email. Please verify to continue.",
                    "user_id": user.id,
                    "is_2fa_enabled": user.is_2fa_enabled,
                    "has_answered_onboarding": user.has_answered_onboarding, # <-- Added here
                    # "subscription_plan": user.UserSubscription
                }
                
                # Add deletion cancellation message if applicable
                if deletion_cancellation['cancelled']:
                    response_data["deletion_cancelled"] = True
                    response_data["deletion_message"] = f"Your account deletion request has been cancelled. Your account was scheduled for deletion on {deletion_cancellation['scheduled_date'].strftime('%Y-%m-%d')} but has been cancelled since you logged in."
                
                return Response(response_data, status=status.HTTP_200_OK)

            # If 2FA is disabled, proceed with normal login
            refresh = RefreshToken.for_user(user)
            access_token = str(refresh.access_token)
            return Response({
                "message": "Login successful.",
                "access_token": access_token,
                "refresh_token": str(refresh),
                "is_2fa_enabled": user.is_2fa_enabled,
                "has_answered_onboarding": user.has_answered_onboarding,  # <-- Added here
                "subscription_plan": self._get_user_subscription_plan(user),
                "has_answered_onboarding": user.has_answered_onboarding,

            }, status=status.HTTP_200_OK)

        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

    
class Toggle2FAView(APIView):
    permission_classes = [IsAuthenticated]

    def post(self, request):
        user = request.user
        is_2fa_enabled = request.data.get("is_2fa_enabled", None)

        if is_2fa_enabled is None:
            return Response({"error": "is_2fa_enabled field is required"}, status=status.HTTP_400_BAD_REQUEST)

        user.is_2fa_enabled = is_2fa_enabled
        user.save()
        
        return Response({
            "message": f"Two-Factor Authentication {'enabled' if is_2fa_enabled else 'disabled'} successfully.",
            "is_2fa_enabled": user.is_2fa_enabled
        }, status=status.HTTP_200_OK)

class changepasswordView(APIView):
    permission_classes = [IsAuthenticated]

    def post(self, request):
        email = request.user.email
        old_password = request.POST.get('old_password')
        new_password = request.POST.get('new_password')
        confirm_password = request.POST.get('confirm_password')
        if not old_password or not new_password or not confirm_password:
            message="Please provide all the fields -> old_password, new_password, confirm_password"
            return Response({"message":message}, status=status.HTTP_400_BAD_REQUEST)
        user = User.objects.get(email=email.lower())
        if not user.check_password(old_password):
            return JsonResponse({"message": "Old password is incorrect"}, status=status.HTTP_400_BAD_REQUEST)
        if new_password != confirm_password:
            return JsonResponse({'message': 'Passwords do not match'}, status=400)
        user.set_password(new_password)
        user.save()
        return JsonResponse({"message": "Password changed successfully"}, status=status.HTTP_200_OK)

def send_otp_email(email, otp_code):
    subject = "Your OTP Code for Password Reset"
    message = f"Your OTP code is: {otp_code}. It is valid for 5 minutes."
    from_email = (os.getenv("EMAIL_HOST_USER")) 
    recipient_list = [email]
    send_mail(subject, message, from_email, recipient_list)
    print(f"OTP {otp_code} sent to email: {email}")

class resendotpview(APIView):
    def post(self, request):
        try:
            identifier = request.data.get('email_or_phone', '').strip().lower()

            if not identifier:
                return JsonResponse({"message": "Please enter Email or Phone number"}, status=status.HTTP_400_BAD_REQUEST)

            otp = random.randint(1000, 9999)

            if '@' in identifier:
                try:
                    user = User.objects.get(email=identifier)
                except ObjectDoesNotExist:
                    return JsonResponse({"message": "User with this email not found"}, status=status.HTTP_400_BAD_REQUEST)

                user.otp = otp
                user.save()

                subject = "One Time Password"
                email_body = f"Your OTP is: {otp}\n\nUse this code to complete your verification."

                try:
                    send_mail(subject, email_body, 'AI IngredientIQ', [user.email], fail_silently=False)
                except BadHeaderError:
                    return JsonResponse({"message": "Invalid email header"}, status=status.HTTP_400_BAD_REQUEST)

                return JsonResponse({"data": "OTP sent to your email"}, status=status.HTTP_200_OK)

            else:
                try:
                    user = User.objects.get(phone_number=identifier)
                except ObjectDoesNotExist:
                    return JsonResponse({"message": "User with this phone number not found"}, status=status.HTTP_400_BAD_REQUEST)

                user.otp = otp
                user.save()

                message = f"Your OTP is: {otp}. Use this to complete your verification."
                send_sms(user.phone_number, message)

                return JsonResponse({"data": "OTP sent to your phone number"}, status=status.HTTP_200_OK)

        except Exception as e:
            return JsonResponse({"message": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

# Verify OTP API
class verifyotpview(APIView):
    def post(self, request):
        try:
            otp = request.data.get('otp', None)
            
            if not otp:
                return JsonResponse({"error": "OTP is required"}, status=status.HTTP_400_BAD_REQUEST)
            
            try:
                otp = int(otp)
            except ValueError:
                return JsonResponse({"error": "OTP should be a valid integer"}, status=status.HTTP_400_BAD_REQUEST)
            
            user = User.objects.filter(otp=otp).first()

            if user:
                user.otp = None  # Clear OTP after successful verification
                user.save()

                refresh = RefreshToken.for_user(user)
                access_token = str(refresh.access_token)

                return Response({
                    "message": "OTP Verified Successfully. Login successful.",
                    "access_token": access_token,
                    "refresh_token": str(refresh)
                }, status=status.HTTP_200_OK)

            return Response({"error": "Incorrect OTP"}, status=status.HTTP_400_BAD_REQUEST)

        except Exception as e:
            return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
@method_decorator(csrf_exempt, name='dispatch')
class ForgotPasswordRequestAPIView(APIView):
    permission_classes = [] 

    def post(self, request):
        email = request.data.get("email")  
        user = User.objects.filter(email=email).first()

        if not user:
            return Response({"detail": "User not found."}, status=status.HTTP_404_NOT_FOUND)

        serializer = ChangePasswordSerializer(data=request.data)

        if serializer.is_valid():
            new_password = serializer.validated_data['new_password']
            confirm_password = serializer.validated_data['confirm_password']

            if new_password != confirm_password:
                return Response({"detail": "Passwords must match."}, status=status.HTTP_400_BAD_REQUEST)

            if len(confirm_password) < 8:
                return Response({"detail": "New password must be at least 8 characters long."}, status=status.HTTP_400_BAD_REQUEST)

            user.set_password(confirm_password)
            user.save()

            return Response({"detail": "Password has been successfully reset."}, status=status.HTTP_200_OK)

        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


class changepasswordView(APIView):
    permission_classes = [IsAuthenticated]

    def post(self, request):
        email = request.user.email
        old_password = request.POST.get('old_password')
        new_password = request.POST.get('new_password')
        confirm_password = request.POST.get('confirm_password')
        if not old_password or not new_password or not confirm_password:
            message="Please provide all the fields -> old_password, new_password, confirm_password"
            return Response({"message":message}, status=status.HTTP_400_BAD_REQUEST)
        user = User.objects.get(email=email.lower())
        if not user.check_password(old_password):
            return JsonResponse({"message": "Old password is incorrect"}, status=status.HTTP_400_BAD_REQUEST)
        if new_password != confirm_password:
            return JsonResponse({'message': 'Passwords do not match'}, status=400)
        user.set_password(new_password)
        user.save()
        return JsonResponse({"message": "Password changed successfully"}, status=status.HTTP_200_OK)

class termsandconditionView(APIView):
    def get(self,request):
        user = Termandcondition.objects.all()
        serializer = termsandconditionSerializer(user,many=True)
        return Response({"data":serializer.data}, status=status.HTTP_200_OK)


class privacypolicyView(APIView):
    def get(self,request):
        user = privacypolicy.objects.all()
        serializer = privacypolicySerializer(user,many=True)
        return Response({"data":serializer.data}, status=status.HTTP_200_OK)

class Frequentlyasked(APIView):
    def get(self,request):
        user = FAQ.objects.all()
        serializer = FAQSerializer(user,many=True)
        return Response({"data":serializer.data},status=status.HTTP_200_OK)

class About(APIView):
    def get(self,request):
        user = AboutUS.objects.all()
        serializer = AboutSerializer(user,many=True)
        return Response({"data":serializer.data},status=status.HTTP_200_OK)

# class userprofileview(APIView):
#     permission_classes = [IsAuthenticated]
#     parser_classes = (MultiPartParser, FormParser)

#     def patch(self, request):
#         user = User.objects.get(email=request.user.email)

#         if not request.data:
#             return Response({"message": "No data provided to update."}, status=status.HTTP_400_BAD_REQUEST)

#         serializer = userPatchSerializer(user, data=request.data, partial=True)

#         if serializer.is_valid():
#             serializer.save()
#             profile_picture_url = None
#             if user.profile_picture:
#                 profile_picture_url = user.profile_picture.url
#                 print("------------", profile_picture_url)
#                 profile_picture_url = profile_picture_url.replace("https//", "")
#                 print("======", profile_picture_url)  
#             return Response(
#                 {"message": "Profile updated successfully."},
#                 status=status.HTTP_200_OK,
#             )

#         return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)
        
#     def get(self,request):
#         user = User.objects.select_related().get(email=request.user.email)
#         user.refresh_from_db()  # Force refresh from database
#         serializer = userGetSerializer(user)
#         # Add payment status info
#         from .models import UserSubscription
#         payment_status = 'freemium'
#         premium_type = None
#         try:
#             sub = UserSubscription.objects.get(user=user)
#             if sub.plan_name == 'premium':
#                 payment_status = 'premium'
#                 # Use a new field 'premium_type' if present, else fallback to 'unknown'
#                 premium_type = getattr(sub, 'premium_type', None)
#         except UserSubscription.DoesNotExist:
#             pass
#         data = serializer.data
#         data['payment_status'] = payment_status
#         data['premium_type'] = premium_type
#         return Response({"data":data}, status=status.HTTP_200_OK)
    
#     def delete(self, request):
#         user = User.objects.get(email=request.user.email)
        
#         # Check if user is premium or freemium
#         is_premium = False
#         try:
#             subscription = UserSubscription.objects.get(user=user)
#             is_premium = subscription.plan_name == 'premium' and subscription.is_active
#         except UserSubscription.DoesNotExist:
#             is_premium = False
        
#         if is_premium:
#             # Premium user - create deletion request with 30-day delay
#             from datetime import timedelta
#             scheduled_deletion_date = timezone.now() + timedelta(days=30)
            
#             # Check if there's already a pending deletion request
#             try:
#                 deletion_request = AccountDeletionRequest.objects.get(user=user, status='pending')
#                 return Response({
#                     "message": "You already have a pending account deletion request.",
#                     "scheduled_deletion_date": deletion_request.scheduled_deletion_date.isoformat(),
#                     "days_remaining": deletion_request.days_remaining,
#                     "status": "already_requested"
#                 }, status=status.HTTP_200_OK)
#             except AccountDeletionRequest.DoesNotExist:
#                 # Create new deletion request
#                 deletion_request = AccountDeletionRequest.objects.create(
#                     user=user,
#                     scheduled_deletion_date=scheduled_deletion_date,
#                     status='pending'
#                 )
                
#                 return Response({
#                     "message": "We have received your request for account deletion. Your account will be deleted in 30 days. If you log in during this period, your deletion request will be cancelled.",
#                     "scheduled_deletion_date": scheduled_deletion_date.isoformat(),
#                     "days_remaining": 30,
#                     "status": "deletion_scheduled"
#                 }, status=status.HTTP_200_OK)
#         else:
#             # Freemium user - delete immediately with proper foreign key handling
#             success, message = safe_delete_user(user)
#             if success:
#                 return Response({
#                     "message": "Your account has been deleted successfully.",
#                     "status": "deleted_immediately"
#                 }, status=status.HTTP_200_OK)
#             else:
#                 return Response({
#                     "error": f"Failed to delete account: {message}",
#                     "status": "deletion_failed"
#                 }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class LogoutView(APIView):
    permission_classes = [IsAuthenticated]

    def post(self, request):
        logout(request)
        return Response({"message": "Logged out successfully."}, status=status.HTTP_200_OK)

def can_user_scan(user):
    """
    Returns (True, scan_count, remaining_scans) if user can scan.
    Returns (False, scan_count, remaining_scans) if freemium and limit reached.
    Uses MonthlyScanUsage model for monthly tracking.
    """
    try:
        subscription = UserSubscription.objects.get(user=user)
        # Only 'freemium' is limited; all other plans are unlimited
        if subscription.plan_name.strip().lower() == "freemium":
            # Get or create current month's usage record
            usage = MonthlyScanUsage.get_or_create_current_month(user)
            scan_count = usage.scan_count
            remaining_scans = usage.get_remaining_scans()
            
            if scan_count >= 20:
                return False, scan_count, remaining_scans
            return True, scan_count, remaining_scans
        # Any other plan: unlimited scans
        return True, None, None
    except UserSubscription.DoesNotExist:
        # Treat as freemium if no subscription found
        usage = MonthlyScanUsage.get_or_create_current_month(user)
        scan_count = usage.scan_count
        remaining_scans = usage.get_remaining_scans()
        
        if scan_count >= 20:
            return False, scan_count, remaining_scans
        return True, scan_count, remaining_scans

def get_user_plan_info(user):
    """
    Returns user's plan information including plan name, type, and status.
    """
    try:
        subscription = UserSubscription.objects.get(user=user)
        return {
            "plan_name": subscription.plan_name,
            "premium_type": subscription.premium_type,
            "status": subscription.status,
            "is_premium": subscription.plan_name.strip().lower() != "freemium"
        }
    except UserSubscription.DoesNotExist:
        return {
            "plan_name": "freemium",
            "premium_type": None,
            "status": "inactive",
            "is_premium": False
        }

def get_accurate_scan_count(user):
    """
    Returns the accurate scan count for a user based on actual FoodLabelScan objects.
    This ensures the count is accurate even if MonthlyScanUsage records are out of sync.
    """
    try:
        # Get the actual count of FoodLabelScan objects for this user
        actual_count = FoodLabelScan.objects.filter(user=user).count()
        
        # Update the MonthlyScanUsage record to sync with actual count
        usage = MonthlyScanUsage.get_or_create_current_month(user)
        if usage.scan_count != actual_count:
            usage.scan_count = actual_count
            usage.save()
            print(f"Synced scan count for user {user.email}: {usage.scan_count} -> {actual_count}")
        
        return actual_count
    except Exception as e:
        print(f"Error getting accurate scan count: {e}")
        return 0

def get_scan_count_at_time(user, scan_time):
    """
    Returns the scan count for a user at a specific point in time.
    This is used to show the correct scan count for historical scans.
    """
    try:
        # Count how many scans were created before or at the given time
        scan_count = FoodLabelScan.objects.filter(
            user=user,
            scanned_at__lte=scan_time
        ).count()
        
        return scan_count
    except Exception as e:
        print(f"Error getting scan count at time: {e}")
        return 0

def sync_all_user_scan_counts():
    """
    Sync all users' scan counts in MonthlyScanUsage with their actual FoodLabelScan objects.
    This should be run after deleting scans from admin panel to fix count discrepancies.
    """
    try:
        users = User.objects.all()
        synced_count = 0
        
        for user in users:
            actual_count = FoodLabelScan.objects.filter(user=user).count()
            usage = MonthlyScanUsage.get_or_create_current_month(user)
            
            if usage.scan_count != actual_count:
                old_count = usage.scan_count
                usage.scan_count = actual_count
                usage.save()
                print(f"Synced user {user.email}: {old_count} -> {actual_count}")
                synced_count += 1
        
        print(f"Synced scan counts for {synced_count} users")
        return synced_count
    except Exception as e:
        print(f"Error syncing scan counts: {e}")
        return 0

# Add a setting at the top of the file
USE_STATIC_INGREDIENT_SAFETY = False  # Set to True for instant local safety check, False to use Edamam

def increment_user_scan_count(user):
    """
    Increment the user's scan count for the current month.
    Returns the updated scan count and remaining scans.
    """
    try:
        usage = MonthlyScanUsage.get_or_create_current_month(user)
        usage.increment_scan()
        return usage.scan_count, usage.get_remaining_scans()
    except Exception as e:
        print(f"Error incrementing scan count: {e}")
        return 0, 0


def google_login(request):
    # google = SocialApp.objects.get(provider='google')
    # return redirect(f"https://accounts.google.com/o/oauth2/auth?client_id={google.client_id}&redirect_uri=http://localhost:8000/accounts/google/login/callback/&response_type=code&scope=email profile")
    pass  # Social login temporarily disabled due to SQLite JSONField incompatibility

class SignupAPIView(APIView):
    def post(self, request):
        serializer = SignupSerializer(data=request.data)
        if serializer.is_valid():
            user = serializer.save()
            
            # Generate JWT tokens
            refresh = RefreshToken.for_user(user)
            access_token = str(refresh.access_token)

            return Response({
                'message': 'User created successfully.',
                'access_token': access_token,
                'refresh_token': str(refresh),
                'is_2fa_enabled': user.is_2fa_enabled,
                'has_answered_onboarding': user.has_answered_onboarding,
            }, status=status.HTTP_201_CREATED)

        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


@method_decorator(csrf_exempt, name='dispatch')
class LoginAPIView(APIView):
    def _get_user_subscription_plan(self, user):
        """Get accurate subscription plan for user"""
        from .models import UserSubscription
        try:
            sub = UserSubscription.objects.get(user=user)
            if sub.is_premium:
                return f"{sub.premium_type.capitalize()} Premium" if sub.premium_type else "Premium"
        except UserSubscription.DoesNotExist:
            pass
        return "Freemium plan"
    
    def post(self, request):
        serializer = LoginSerializer(data=request.data)
        if serializer.is_valid():
            user = serializer.validated_data['user']
            
            # Cancel any pending deletion request when user logs in
            deletion_cancellation = cancel_deletion_request_on_login(user)

            if user.is_2fa_enabled:  # Check if 2FA is enabled
                from random import randint
                from django.core.mail import send_mail

                otp_code = randint(100000, 999999)  # Generate 6-digit OTP
                user.otp = str(otp_code)
                user.save()

                # Send OTP via email
                send_mail(
                    "Your OTP Code",
                    f"Your OTP code is: {otp_code}",
                    "no-reply@example.com",
                    [user.email],
                    fail_silently=False,
                )

                response_data = {
                    "message": "OTP sent to your email. Please verify to continue.",
                    "user_id": user.id,
                    "is_2fa_enabled": user.is_2fa_enabled,
                    "has_answered_onboarding": user.has_answered_onboarding, # <-- Added here
                    # "subscription_plan": user.UserSubscription
                }
                
                # Add deletion cancellation message if applicable
                if deletion_cancellation['cancelled']:
                    response_data["deletion_cancelled"] = True
                    response_data["deletion_message"] = f"Your account deletion request has been cancelled. Your account was scheduled for deletion on {deletion_cancellation['scheduled_date'].strftime('%Y-%m-%d')} but has been cancelled since you logged in."
                
                return Response(response_data, status=status.HTTP_200_OK)

            # If 2FA is disabled, proceed with normal login
            refresh = RefreshToken.for_user(user)
            access_token = str(refresh.access_token)
            return Response({
                "message": "Login successful.",
                "access_token": access_token,
                "refresh_token": str(refresh),
                "is_2fa_enabled": user.is_2fa_enabled,
                "has_answered_onboarding": user.has_answered_onboarding,  # <-- Added here
                "subscription_plan": user.subscription_plan

            }, status=status.HTTP_200_OK)

        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

    
class Toggle2FAView(APIView):
    permission_classes = [IsAuthenticated]

    def post(self, request):
        user = request.user
        is_2fa_enabled = request.data.get("is_2fa_enabled", None)

        if is_2fa_enabled is None:
            return Response({"error": "is_2fa_enabled field is required"}, status=status.HTTP_400_BAD_REQUEST)

        user.is_2fa_enabled = is_2fa_enabled
        user.save()
        
        return Response({
            "message": f"Two-Factor Authentication {'enabled' if is_2fa_enabled else 'disabled'} successfully.",
            "is_2fa_enabled": user.is_2fa_enabled
        }, status=status.HTTP_200_OK)

class changepasswordView(APIView):
    permission_classes = [IsAuthenticated]

    def post(self, request):
        email = request.user.email
        old_password = request.POST.get('old_password')
        new_password = request.POST.get('new_password')
        confirm_password = request.POST.get('confirm_password')
        if not old_password or not new_password or not confirm_password:
            message="Please provide all the fields -> old_password, new_password, confirm_password"
            return Response({"message":message}, status=status.HTTP_400_BAD_REQUEST)
        user = User.objects.get(email=email.lower())
        if not user.check_password(old_password):
            return JsonResponse({"message": "Old password is incorrect"}, status=status.HTTP_400_BAD_REQUEST)
        if new_password != confirm_password:
            return JsonResponse({'message': 'Passwords do not match'}, status=400)
        user.set_password(new_password)
        user.save()
        return JsonResponse({"message": "Password changed successfully"}, status=status.HTTP_200_OK)

def send_otp_email(email, otp_code):
    subject = "Your OTP Code for Password Reset"
    message = f"Your OTP code is: {otp_code}. It is valid for 5 minutes."
    from_email = (os.getenv("EMAIL_HOST_USER")) 
    recipient_list = [email]
    send_mail(subject, message, from_email, recipient_list)
    print(f"OTP {otp_code} sent to email: {email}")

class resendotpview(APIView):
    def post(self, request):
        try:
            identifier = request.data.get('email_or_phone', '').strip().lower()

            if not identifier:
                return JsonResponse({"message": "Please enter Email or Phone number"}, status=status.HTTP_400_BAD_REQUEST)

            otp = random.randint(1000, 9999)

            if '@' in identifier:
                try:
                    user = User.objects.get(email=identifier)
                except ObjectDoesNotExist:
                    return JsonResponse({"message": "User with this email not found"}, status=status.HTTP_400_BAD_REQUEST)

                user.otp = otp
                user.save()

                subject = "One Time Password"
                email_body = f"Your OTP is: {otp}\n\nUse this code to complete your verification."

                try:
                    send_mail(subject, email_body, 'AI IngredientIQ', [user.email], fail_silently=False)
                except BadHeaderError:
                    return JsonResponse({"message": "Invalid email header"}, status=status.HTTP_400_BAD_REQUEST)

                return JsonResponse({"data": "OTP sent to your email"}, status=status.HTTP_200_OK)

            else:
                try:
                    user = User.objects.get(phone_number=identifier)
                except ObjectDoesNotExist:
                    return JsonResponse({"message": "User with this phone number not found"}, status=status.HTTP_400_BAD_REQUEST)

                user.otp = otp
                user.save()

                message = f"Your OTP is: {otp}. Use this to complete your verification."
                send_sms(user.phone_number, message)

                return JsonResponse({"data": "OTP sent to your phone number"}, status=status.HTTP_200_OK)

        except Exception as e:
            return JsonResponse({"message": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

# Verify OTP API
class verifyotpview(APIView):
    def post(self, request):
        try:
            otp = request.data.get('otp', None)
            
            if not otp:
                return JsonResponse({"error": "OTP is required"}, status=status.HTTP_400_BAD_REQUEST)
            
            try:
                otp = int(otp)
            except ValueError:
                return JsonResponse({"error": "OTP should be a valid integer"}, status=status.HTTP_400_BAD_REQUEST)
            
            user = User.objects.filter(otp=otp).first()

            if user:
                user.otp = None  # Clear OTP after successful verification
                user.save()

                refresh = RefreshToken.for_user(user)
                access_token = str(refresh.access_token)

                return Response({
                    "message": "OTP Verified Successfully. Login successful.",
                    "access_token": access_token,
                    "refresh_token": str(refresh)
                }, status=status.HTTP_200_OK)

            return Response({"error": "Incorrect OTP"}, status=status.HTTP_400_BAD_REQUEST)

        except Exception as e:
            return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
@method_decorator(csrf_exempt, name='dispatch')
class ForgotPasswordRequestAPIView(APIView):
    permission_classes = [] 

    def post(self, request):
        email = request.data.get("email")  
        user = User.objects.filter(email=email).first()

        if not user:
            return Response({"detail": "User not found."}, status=status.HTTP_404_NOT_FOUND)

        serializer = ChangePasswordSerializer(data=request.data)

        if serializer.is_valid():
            new_password = serializer.validated_data['new_password']
            confirm_password = serializer.validated_data['confirm_password']

            if new_password != confirm_password:
                return Response({"detail": "Passwords must match."}, status=status.HTTP_400_BAD_REQUEST)

            if len(confirm_password) < 8:
                return Response({"detail": "New password must be at least 8 characters long."}, status=status.HTTP_400_BAD_REQUEST)

            user.set_password(confirm_password)
            user.save()

            return Response({"detail": "Password has been successfully reset."}, status=status.HTTP_200_OK)

        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


class changepasswordView(APIView):
    permission_classes = [IsAuthenticated]

    def post(self, request):
        email = request.user.email
        old_password = request.POST.get('old_password')
        new_password = request.POST.get('new_password')
        confirm_password = request.POST.get('confirm_password')
        if not old_password or not new_password or not confirm_password:
            message="Please provide all the fields -> old_password, new_password, confirm_password"
            return Response({"message":message}, status=status.HTTP_400_BAD_REQUEST)
        user = User.objects.get(email=email.lower())
        if not user.check_password(old_password):
            return JsonResponse({"message": "Old password is incorrect"}, status=status.HTTP_400_BAD_REQUEST)
        if new_password != confirm_password:
            return JsonResponse({'message': 'Passwords do not match'}, status=400)
        user.set_password(new_password)
        user.save()
        return JsonResponse({"message": "Password changed successfully"}, status=status.HTTP_200_OK)

class termsandconditionView(APIView):
    def get(self,request):
        user = Termandcondition.objects.all()
        serializer = termsandconditionSerializer(user,many=True)
        return Response({"data":serializer.data}, status=status.HTTP_200_OK)


class privacypolicyView(APIView):
    def get(self,request):
        user = privacypolicy.objects.all()
        serializer = privacypolicySerializer(user,many=True)
        return Response({"data":serializer.data}, status=status.HTTP_200_OK)

class Frequentlyasked(APIView):
    def get(self,request):
        user = FAQ.objects.all()
        serializer = FAQSerializer(user,many=True)
        return Response({"data":serializer.data},status=status.HTTP_200_OK)

class About(APIView):
    def get(self,request):
        user = AboutUS.objects.all()
        serializer = AboutSerializer(user,many=True)
        return Response({"data":serializer.data},status=status.HTTP_200_OK)

# class userprofileview(APIView):
#     permission_classes = [IsAuthenticated]
#     parser_classes = (MultiPartParser, FormParser)

#     def patch(self, request):
#         user = User.objects.get(email=request.user.email)

#         if not request.data:
#             return Response({"message": "No data provided to update."}, status=status.HTTP_400_BAD_REQUEST)

#         serializer = userPatchSerializer(user, data=request.data, partial=True)

#         if serializer.is_valid():
#             serializer.save()
#             profile_picture_url = None
#             if user.profile_picture:
#                 profile_picture_url = user.profile_picture.url
#                 print("------------", profile_picture_url)
#                 profile_picture_url = profile_picture_url.replace("https//", "")
#                 print("======", profile_picture_url)  
#             return Response(
#                 {"message": "Profile updated successfully."},
#                 status=status.HTTP_200_OK,
#             )

#         return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)
        
#     def get(self,request):
#         user = User.objects.select_related().get(email=request.user.email)
#         user.refresh_from_db()  # Force refresh from database
#         serializer = userGetSerializer(user)
#         # Add payment status info
#         from .models import UserSubscription
#         payment_status = 'freemium'
#         premium_type = None
#         try:
#             sub = UserSubscription.objects.get(user=user)
#             if sub.plan_name == 'premium':
#                 payment_status = 'premium'
#                 # Use a new field 'premium_type' if present, else fallback to 'unknown'
#                 premium_type = getattr(sub, 'premium_type', None)
#         except UserSubscription.DoesNotExist:
#             pass
#         data = serializer.data
#         data['payment_status'] = payment_status
#         data['premium_type'] = premium_type
#         return Response({"data":data}, status=status.HTTP_200_OK)
    
#     def delete(self, request):
#         user = User.objects.get(email=request.user.email)
        
#         # Check if user is premium or freemium
#         is_premium = False
#         try:
#             subscription = UserSubscription.objects.get(user=user)
#             is_premium = subscription.plan_name == 'premium' and subscription.is_active
#         except UserSubscription.DoesNotExist:
#             is_premium = False
        
#         if is_premium:
#             # Premium user - create deletion request with 30-day delay
#             from datetime import timedelta
#             scheduled_deletion_date = timezone.now() + timedelta(days=30)
            
#             # Check if there's already a pending deletion request
#             try:
#                 deletion_request = AccountDeletionRequest.objects.get(user=user, status='pending')
#                 return Response({
#                     "message": "You already have a pending account deletion request.",
#                     "scheduled_deletion_date": deletion_request.scheduled_deletion_date.isoformat(),
#                     "days_remaining": deletion_request.days_remaining,
#                     "status": "already_requested"
#                 }, status=status.HTTP_200_OK)
#             except AccountDeletionRequest.DoesNotExist:
#                 # Create new deletion request
#                 deletion_request = AccountDeletionRequest.objects.create(
#                     user=user,
#                     scheduled_deletion_date=scheduled_deletion_date,
#                     status='pending'
#                 )
                
#                 return Response({
#                     "message": "We have received your request for account deletion. Your account will be deleted in 30 days. If you log in during this period, your deletion request will be cancelled.",
#                     "scheduled_deletion_date": scheduled_deletion_date.isoformat(),
#                     "days_remaining": 30,
#                     "status": "deletion_scheduled"
#                 }, status=status.HTTP_200_OK)
#         else:
#             # Freemium user - delete immediately with proper foreign key handling
#             success, message = safe_delete_user(user)
#             if success:
#                 return Response({
#                     "message": "Your account has been deleted successfully.",
#                     "status": "deleted_immediately"
#                 }, status=status.HTTP_200_OK)
#             else:
#                 return Response({
#                     "error": f"Failed to delete account: {message}",
#                     "status": "deletion_failed"
#                 }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class LogoutView(APIView):
    permission_classes = [IsAuthenticated]

    def post(self, request):
        logout(request)
        return Response({"message": "Logged out successfully."}, status=status.HTTP_200_OK)

def can_user_scan(user):
    """
    Returns (True, scan_count, remaining_scans) if user can scan.
    Returns (False, scan_count, remaining_scans) if freemium and limit reached.
    Uses MonthlyScanUsage model for monthly tracking.
    """
    try:
        subscription = UserSubscription.objects.get(user=user)
        # Only 'freemium' is limited; all other plans are unlimited
        if subscription.plan_name.strip().lower() == "freemium":
            # Get or create current month's usage record
            usage = MonthlyScanUsage.get_or_create_current_month(user)
            scan_count = usage.scan_count
            remaining_scans = usage.get_remaining_scans()
            
            if scan_count >= 20:
                return False, scan_count, remaining_scans
            return True, scan_count, remaining_scans
        # Any other plan: unlimited scans
        return True, None, None
    except UserSubscription.DoesNotExist:
        # Treat as freemium if no subscription found
        usage = MonthlyScanUsage.get_or_create_current_month(user)
        scan_count = usage.scan_count
        remaining_scans = usage.get_remaining_scans()
        
        if scan_count >= 20:
            return False, scan_count, remaining_scans
        return True, scan_count, remaining_scans

def get_user_plan_info(user):
    """
    Returns user's plan information including plan name, type, and status.
    """
    try:
        subscription = UserSubscription.objects.get(user=user)
        return {
            "plan_name": subscription.plan_name,
            "premium_type": subscription.premium_type,
            "status": subscription.status,
            "is_premium": subscription.plan_name.strip().lower() != "freemium"
        }
    except UserSubscription.DoesNotExist:
        return {
            "plan_name": "freemium",
            "premium_type": None,
            "status": "inactive",
            "is_premium": False
        }

def get_accurate_scan_count(user):
    """
    Returns the accurate scan count for a user based on actual FoodLabelScan objects.
    This ensures the count is accurate even if MonthlyScanUsage records are out of sync.
    """
    try:
        # Get the actual count of FoodLabelScan objects for this user
        actual_count = FoodLabelScan.objects.filter(user=user).count()
        
        # Update the MonthlyScanUsage record to sync with actual count
        usage = MonthlyScanUsage.get_or_create_current_month(user)
        if usage.scan_count != actual_count:
            usage.scan_count = actual_count
            usage.save()
            print(f"Synced scan count for user {user.email}: {usage.scan_count} -> {actual_count}")
        
        return actual_count
    except Exception as e:
        print(f"Error getting accurate scan count: {e}")
        return 0

def get_scan_count_at_time(user, scan_time):
    """
    Returns the scan count for a user at a specific point in time.
    This is used to show the correct scan count for historical scans.
    """
    try:
        # Count how many scans were created before or at the given time
        scan_count = FoodLabelScan.objects.filter(
            user=user,
            scanned_at__lte=scan_time
        ).count()
        
        return scan_count
    except Exception as e:
        print(f"Error getting scan count at time: {e}")
        return 0

def sync_all_user_scan_counts():
    """
    Sync all users' scan counts in MonthlyScanUsage with their actual FoodLabelScan objects.
    This should be run after deleting scans from admin panel to fix count discrepancies.
    """
    try:
        users = User.objects.all()
        synced_count = 0
        
        for user in users:
            actual_count = FoodLabelScan.objects.filter(user=user).count()
            usage = MonthlyScanUsage.get_or_create_current_month(user)
            
            if usage.scan_count != actual_count:
                old_count = usage.scan_count
                usage.scan_count = actual_count
                usage.save()
                print(f"Synced user {user.email}: {old_count} -> {actual_count}")
                synced_count += 1
        
        print(f"Synced scan counts for {synced_count} users")
        return synced_count
    except Exception as e:
        print(f"Error syncing scan counts: {e}")
        return 0

# Add a setting at the top of the file
USE_STATIC_INGREDIENT_SAFETY = False  # Set to True for instant local safety check, False to use Edamam

def increment_user_scan_count(user):
    """
    Increment the user's scan count for the current month.
    Returns the updated scan count and remaining scans.
    """
    try:
        usage = MonthlyScanUsage.get_or_create_current_month(user)
        usage.increment_scan()
        return usage.scan_count, usage.get_remaining_scans()
    except Exception as e:
        print(f"Error incrementing scan count: {e}")
        return 0, 0


def google_login(request):
    """
    Traditional OAuth2 flow for Google Sign-In
    """
    from django.shortcuts import redirect
    from urllib.parse import urlencode
    
    # Get Google OAuth2 credentials from settings
    client_id = getattr(settings, 'SOCIAL_AUTH_GOOGLE_OAUTH2_KEY', None) or os.getenv('SOCIAL_AUTH_GOOGLE_OAUTH2_KEY')
    
    if not client_id:
        return Response({"error": "Google OAuth2 not configured"}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
    
    # Build OAuth2 authorization URL
    params = {
        'client_id': client_id,
        'redirect_uri': request.build_absolute_uri('/accounts/google/login/callback/'),
        'response_type': 'code',
        'scope': 'email profile',
        'access_type': 'offline',
        'prompt': 'consent'
    }
    
    auth_url = f"https://accounts.google.com/o/oauth2/auth?{urlencode(params)}"
    return redirect(auth_url)

@method_decorator(csrf_exempt, name='dispatch')
class GoogleOAuth2CallbackView(APIView):
    """
    Handle Google OAuth2 callback and exchange authorization code for tokens
    """
    permission_classes = []
    
    def get(self, request):
        code = request.GET.get('code')
        error = request.GET.get('error')
        
        if error:
            return Response({"error": f"OAuth error: {error}"}, status=status.HTTP_400_BAD_REQUEST)
        
        if not code:
            return Response({"error": "No authorization code received"}, status=status.HTTP_400_BAD_REQUEST)
        
        # Exchange authorization code for access token
        client_id = getattr(settings, 'SOCIAL_AUTH_GOOGLE_OAUTH2_KEY', None) or os.getenv('SOCIAL_AUTH_GOOGLE_OAUTH2_KEY')
        client_secret = getattr(settings, 'SOCIAL_AUTH_GOOGLE_OAUTH2_SECRET', None) or os.getenv('SOCIAL_AUTH_GOOGLE_OAUTH2_SECRET')
        redirect_uri = request.build_absolute_uri('/accounts/google/login/callback/')
        
        # Exchange code for tokens
        token_response = requests.post('https://oauth2.googleapis.com/token', data={
            'client_id': client_id,
            'client_secret': client_secret,
            'code': code,
            'grant_type': 'authorization_code',
            'redirect_uri': redirect_uri
        })
        
        if token_response.status_code != 200:
            return Response({"error": "Failed to exchange authorization code"}, status=status.HTTP_400_BAD_REQUEST)
        
        token_data = token_response.json()
        access_token = token_data.get('access_token')
        
        # Get user info using access token
        user_info_response = requests.get(
            'https://www.googleapis.com/oauth2/v2/userinfo',
            headers={'Authorization': f'Bearer {access_token}'}
        )
        
        if user_info_response.status_code != 200:
            return Response({"error": "Failed to get user info"}, status=status.HTTP_400_BAD_REQUEST)
        
        user_info = user_info_response.json()
        email = user_info.get('email')
        
        if not email:
            return Response({"error": "No email in user info"}, status=status.HTTP_400_BAD_REQUEST)
        
        # Create or get user
        User = get_user_model()
        user, created = User.objects.get_or_create(
            email=email, 
            defaults={
                "username": email.split("@")[0],
                "full_name": user_info.get('name', ''),
                "profile_picture": user_info.get('picture', '')
            }
        )
        
        # Generate JWT tokens
        from rest_framework_simplejwt.tokens import RefreshToken
        refresh = RefreshToken.for_user(user)
        access_token = str(refresh.access_token)
        
        return Response({
            "access_token": access_token,
            "refresh_token": str(refresh),
            "created": created,
            "email": user.email,
            "full_name": user.full_name,
            "profile_picture": user.profile_picture,
            "has_answered_onboarding": user.has_answered_onboarding,  # Add onboarding status
            "subscription_plan": user.subscription_plan
        }, status=status.HTTP_200_OK)

class SignupAPIView(APIView):
    def post(self, request):
        serializer = SignupSerializer(data=request.data)
        if serializer.is_valid():
            user = serializer.save()
            
            # Generate JWT tokens
            refresh = RefreshToken.for_user(user)
            access_token = str(refresh.access_token)

            return Response({
                'message': 'User created successfully.',
                'access_token': access_token,
                'refresh_token': str(refresh),
                'is_2fa_enabled': user.is_2fa_enabled,
                'has_answered_onboarding': user.has_answered_onboarding,
            }, status=status.HTTP_201_CREATED)

        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


@method_decorator(csrf_exempt, name='dispatch')
class LoginAPIView(APIView):
    def _get_user_subscription_plan(self, user):
        """Get accurate subscription plan for user"""
        from .models import UserSubscription
        try:
            sub = UserSubscription.objects.get(user=user)
            if sub.is_premium:
                return f"{sub.premium_type.capitalize()} Premium" if sub.premium_type else "Premium"
        except UserSubscription.DoesNotExist:
            pass
        return "Freemium plan"
    
    def post(self, request):
        serializer = LoginSerializer(data=request.data)
        if serializer.is_valid():
            user = serializer.validated_data['user']
            
            # Cancel any pending deletion request when user logs in
            deletion_cancellation = cancel_deletion_request_on_login(user)

            if user.is_2fa_enabled:  # Check if 2FA is enabled
                from random import randint
                from django.core.mail import send_mail

                otp_code = randint(100000, 999999)  # Generate 6-digit OTP
                user.otp = str(otp_code)
                user.save()

                # Send OTP via email
                send_mail(
                    "Your OTP Code",
                    f"Your OTP code is: {otp_code}",
                    "no-reply@example.com",
                    [user.email],
                    fail_silently=False,
                )

                response_data = {
                    "message": "OTP sent to your email. Please verify to continue.",
                    "user_id": user.id,
                    "is_2fa_enabled": user.is_2fa_enabled,
                    "has_answered_onboarding": user.has_answered_onboarding, # <-- Added here
                    # "subscription_plan": user.UserSubscription
                }
                
                # Add deletion cancellation message if applicable
                if deletion_cancellation['cancelled']:
                    response_data["deletion_cancelled"] = True
                    response_data["deletion_message"] = f"Your account deletion request has been cancelled. Your account was scheduled for deletion on {deletion_cancellation['scheduled_date'].strftime('%Y-%m-%d')} but has been cancelled since you logged in."
                
                return Response(response_data, status=status.HTTP_200_OK)

            # If 2FA is disabled, proceed with normal login
            refresh = RefreshToken.for_user(user)
            access_token = str(refresh.access_token)
            response_data = {
                "message": "Login successful.",
                "access_token": access_token,
                "refresh_token": str(refresh),
                "is_2fa_enabled": user.is_2fa_enabled,
                "has_answered_onboarding": user.has_answered_onboarding,  # <-- Added here
                "subscription_plan": self._get_user_subscription_plan(user),
            }
            
            # Add deletion cancellation message if applicable
            if deletion_cancellation['cancelled']:
                response_data["deletion_cancelled"] = True
                response_data["deletion_message"] = f"Your account deletion request has been cancelled. Your account was scheduled for deletion on {deletion_cancellation['scheduled_date'].strftime('%Y-%m-%d')} but has been cancelled since you logged in."
            
            return Response(response_data, status=status.HTTP_200_OK)

        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

    
class Toggle2FAView(APIView):
    permission_classes = [IsAuthenticated]

    def post(self, request):
        user = request.user
        is_2fa_enabled = request.data.get("is_2fa_enabled", None)

        if is_2fa_enabled is None:
            return Response({"error": "is_2fa_enabled field is required"}, status=status.HTTP_400_BAD_REQUEST)

        user.is_2fa_enabled = is_2fa_enabled
        user.save()
        
        return Response({
            "message": f"Two-Factor Authentication {'enabled' if is_2fa_enabled else 'disabled'} successfully.",
            "is_2fa_enabled": user.is_2fa_enabled
        }, status=status.HTTP_200_OK)

class changepasswordView(APIView):
    permission_classes = [IsAuthenticated]

    def post(self, request):
        email = request.user.email
        old_password = request.POST.get('old_password')
        new_password = request.POST.get('new_password')
        confirm_password = request.POST.get('confirm_password')
        if not old_password or not new_password or not confirm_password:
            message="Please provide all the fields -> old_password, new_password, confirm_password"
            return Response({"message":message}, status=status.HTTP_400_BAD_REQUEST)
        user = User.objects.get(email=email.lower())
        if not user.check_password(old_password):
            return JsonResponse({"message": "Old password is incorrect"}, status=status.HTTP_400_BAD_REQUEST)
        if new_password != confirm_password:
            return JsonResponse({'message': 'Passwords do not match'}, status=400)
        user.set_password(new_password)
        user.save()
        return JsonResponse({"message": "Password changed successfully"}, status=status.HTTP_200_OK)

def send_otp_email(email, otp_code):
    subject = "Your OTP Code for Password Reset"
    message = f"Your OTP code is: {otp_code}. It is valid for 5 minutes."
    from_email = (os.getenv("EMAIL_HOST_USER")) 
    recipient_list = [email]
    send_mail(subject, message, from_email, recipient_list)
    print(f"OTP {otp_code} sent to email: {email}")

class resendotpview(APIView):
    def post(self, request):
        try:
            identifier = request.data.get('email_or_phone', '').strip().lower()

            if not identifier:
                return JsonResponse({"message": "Please enter Email or Phone number"}, status=status.HTTP_400_BAD_REQUEST)

            otp = random.randint(1000, 9999)

            if '@' in identifier:
                try:
                    user = User.objects.get(email=identifier)
                except ObjectDoesNotExist:
                    return JsonResponse({"message": "User with this email not found"}, status=status.HTTP_400_BAD_REQUEST)

                user.otp = otp
                user.save()

                subject = "One Time Password"
                email_body = f"Your OTP is: {otp}\n\nUse this code to complete your verification."

                try:
                    send_mail(subject, email_body, 'AI IngredientIQ', [user.email], fail_silently=False)
                except BadHeaderError:
                    return JsonResponse({"message": "Invalid email header"}, status=status.HTTP_400_BAD_REQUEST)

                return JsonResponse({"data": "OTP sent to your email"}, status=status.HTTP_200_OK)

            else:
                try:
                    user = User.objects.get(phone_number=identifier)
                except ObjectDoesNotExist:
                    return JsonResponse({"message": "User with this phone number not found"}, status=status.HTTP_400_BAD_REQUEST)

                user.otp = otp
                user.save()

                message = f"Your OTP is: {otp}. Use this to complete your verification."
                send_sms(user.phone_number, message)

                return JsonResponse({"data": "OTP sent to your phone number"}, status=status.HTTP_200_OK)

        except Exception as e:
            return JsonResponse({"message": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

# Verify OTP API
class verifyotpview(APIView):
    def post(self, request):
        try:
            otp = request.data.get('otp', None)
            
            if not otp:
                return JsonResponse({"error": "OTP is required"}, status=status.HTTP_400_BAD_REQUEST)
            
            try:
                otp = int(otp)
            except ValueError:
                return JsonResponse({"error": "OTP should be a valid integer"}, status=status.HTTP_400_BAD_REQUEST)
            
            user = User.objects.filter(otp=otp).first()

            if user:
                user.otp = None  # Clear OTP after successful verification
                user.save()

                refresh = RefreshToken.for_user(user)
                access_token = str(refresh.access_token)

                return Response({
                    "message": "OTP Verified Successfully. Login successful.",
                    "access_token": access_token,
                    "refresh_token": str(refresh)
                }, status=status.HTTP_200_OK)

            return Response({"error": "Incorrect OTP"}, status=status.HTTP_400_BAD_REQUEST)

        except Exception as e:
            return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
@method_decorator(csrf_exempt, name='dispatch')
class ForgotPasswordRequestAPIView(APIView):
    permission_classes = [] 

    def post(self, request):
        email = request.data.get("email")  
        user = User.objects.filter(email=email).first()

        if not user:
            return Response({"detail": "User not found."}, status=status.HTTP_404_NOT_FOUND)

        serializer = ChangePasswordSerializer(data=request.data)

        if serializer.is_valid():
            new_password = serializer.validated_data['new_password']
            confirm_password = serializer.validated_data['confirm_password']

            if new_password != confirm_password:
                return Response({"detail": "Passwords must match."}, status=status.HTTP_400_BAD_REQUEST)

            if len(confirm_password) < 8:
                return Response({"detail": "New password must be at least 8 characters long."}, status=status.HTTP_400_BAD_REQUEST)

            user.set_password(confirm_password)
            user.save()

            return Response({"detail": "Password has been successfully reset."}, status=status.HTTP_200_OK)

        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


class changepasswordView(APIView):
    permission_classes = [IsAuthenticated]

    def post(self, request):
        email = request.user.email
        old_password = request.POST.get('old_password')
        new_password = request.POST.get('new_password')
        confirm_password = request.POST.get('confirm_password')
        if not old_password or not new_password or not confirm_password:
            message="Please provide all the fields -> old_password, new_password, confirm_password"
            return Response({"message":message}, status=status.HTTP_400_BAD_REQUEST)
        user = User.objects.get(email=email.lower())
        if not user.check_password(old_password):
            return JsonResponse({"message": "Old password is incorrect"}, status=status.HTTP_400_BAD_REQUEST)
        if new_password != confirm_password:
            return JsonResponse({'message': 'Passwords do not match'}, status=400)
        user.set_password(new_password)
        user.save()
        return JsonResponse({"message": "Password changed successfully"}, status=status.HTTP_200_OK)

class termsandconditionView(APIView):
    def get(self,request):
        user = Termandcondition.objects.all()
        serializer = termsandconditionSerializer(user,many=True)
        return Response({"data":serializer.data}, status=status.HTTP_200_OK)


class privacypolicyView(APIView):
    def get(self,request):
        user = privacypolicy.objects.all()
        serializer = privacypolicySerializer(user,many=True)
        return Response({"data":serializer.data}, status=status.HTTP_200_OK)

class Frequentlyasked(APIView):
    def get(self,request):
        user = FAQ.objects.all()
        serializer = FAQSerializer(user,many=True)
        return Response({"data":serializer.data},status=status.HTTP_200_OK)

class About(APIView):
    def get(self,request):
        user = AboutUS.objects.all()
        serializer = AboutSerializer(user,many=True)
        return Response({"data":serializer.data},status=status.HTTP_200_OK)

# class userprofileview(APIView):
#     permission_classes = [IsAuthenticated]
#     parser_classes = (MultiPartParser, FormParser)

#     def patch(self, request):
#         user = User.objects.get(email=request.user.email)

#         if not request.data:
#             return Response({"message": "No data provided to update."}, status=status.HTTP_400_BAD_REQUEST)

#         serializer = userPatchSerializer(user, data=request.data, partial=True)

#         if serializer.is_valid():
#             serializer.save()
#             profile_picture_url = None
#             if user.profile_picture:
#                 profile_picture_url = user.profile_picture.url
#                 print("------------", profile_picture_url)
#                 profile_picture_url = profile_picture_url.replace("https//", "")
#                 print("======", profile_picture_url)  
#             return Response(
#                 {"message": "Profile updated successfully."},
#                 status=status.HTTP_200_OK,
#             )

#         return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)
        
#     def get(self,request):
#         user = User.objects.select_related().get(email=request.user.email)
#         user.refresh_from_db()  # Force refresh from database
#         serializer = userGetSerializer(user)
#         # Add payment status info
#         from .models import UserSubscription
#         payment_status = 'freemium'
#         premium_type = None
#         try:
#             sub = UserSubscription.objects.get(user=user)
#             if sub.plan_name == 'premium':
#                 payment_status = 'premium'
#                 # Use a new field 'premium_type' if present, else fallback to 'unknown'
#                 premium_type = getattr(sub, 'premium_type', None)
#         except UserSubscription.DoesNotExist:
#             pass
#         data = serializer.data
#         data['payment_status'] = payment_status
#         data['premium_type'] = premium_type
#         return Response({"data":data}, status=status.HTTP_200_OK)
    
#     def delete(self, request):
#         user = User.objects.get(email=request.user.email)
        
#         print("email---",request.user.email )
#         print("user---",user)

        
#         # Check if user is premium or freemium
#         is_premium = False
#         try:
#             subscription = UserSubscription.objects.get(user=user)
#             is_premium = subscription.plan_name == 'premium' and subscription.is_active
#         except UserSubscription.DoesNotExist:
#             is_premium = False
        
#         if is_premium:
#             # Premium user - create deletion request with 30-day delay
#             from datetime import timedelta
#             scheduled_deletion_date = timezone.now() + timedelta(days=30)
            
#             # Check if there's already a pending deletion request
#             try:
#                 deletion_request = AccountDeletionRequest.objects.get(user=user, status='pending')
#                 return Response({
#                     "message": "You already have a pending account deletion request.",
#                     "scheduled_deletion_date": deletion_request.scheduled_deletion_date.isoformat(),
#                     "days_remaining": deletion_request.days_remaining,
#                     "status": "already_requested"
#                 }, status=status.HTTP_200_OK)
#             except AccountDeletionRequest.DoesNotExist:
#                 # Create new deletion request
#                 deletion_request = AccountDeletionRequest.objects.create(
#                     user=user,
#                     scheduled_deletion_date=scheduled_deletion_date,
#                     status='pending'
#                 )
                
#                 return Response({
#                     "message": "We have received your request for account deletion. Your account will be deleted in 30 days. If you log in during this period, your deletion request will be cancelled.",
#                     "scheduled_deletion_date": scheduled_deletion_date.isoformat(),
#                     "days_remaining": 30,
#                     "status": "deletion_scheduled"
#                 }, status=status.HTTP_200_OK)
#         else:
#             # Freemium user - delete immediately with proper foreign key handling
#             success, message = safe_delete_user(user)
#             if success:
#                 return Response({
#                     "message": "Your account has been deleted successfully.",
#                     "status": "deleted_immediately"
#                 }, status=status.HTTP_200_OK)
#             else:
#                 return Response({
#                     "error": f"Failed to delete account: {message}",
#                     "status": "deletion_failed"
#                 }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

class userprofileview(APIView):
    permission_classes = [IsAuthenticated]
    parser_classes = (MultiPartParser, FormParser, JSONParser)

    def patch(self, request):
        user = User.objects.get(email=request.user.email)

        if not request.data:
            return Response({"message": "No data provided to update."}, status=status.HTTP_400_BAD_REQUEST)

        serializer = userPatchSerializer(user, data=request.data, partial=True)

        if serializer.is_valid():
            serializer.save()
            profile_picture_url = None
            if user.profile_picture:
                profile_picture_url = user.profile_picture.url
                print("------------", profile_picture_url)
                profile_picture_url = profile_picture_url.replace("https//", "")
                print("======", profile_picture_url)  
            return Response(
                {"message": "Profile updated successfully."},
                status=status.HTTP_200_OK,
            )

        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)
        
    def get(self,request):
        user = User.objects.select_related().get(email=request.user.email)
        user.refresh_from_db()  # Force refresh from database
        serializer = userGetSerializer(user)
        # Add payment status info
        from .models import UserSubscription
        payment_status = 'freemium'
        premium_type = None
        try:
            sub = UserSubscription.objects.get(user=user)
            if sub.is_premium:  # This checks both plan_name == 'premium' AND is_active
                payment_status = 'premium'
                # Use a new field 'premium_type' if present, else fallback to 'unknown'
                premium_type = getattr(sub, 'premium_type', None)
        except UserSubscription.DoesNotExist:
            pass
        data = serializer.data
        data['payment_status'] = payment_status
        data['premium_type'] = premium_type
        
        # Override subscription_plan with accurate data
        if payment_status == 'premium':
            subscription_plan = f"{premium_type.capitalize()} Premium" if premium_type else "Premium"
        else:
            subscription_plan = "Freemium plan"
        data['subscription_plan'] = subscription_plan
        
        return Response({"data":data}, status=status.HTTP_200_OK)
    
    def delete(self, request):
        from django.db import transaction
        from django.utils import timezone
        from datetime import timedelta
        from .models import UserSubscription, AccountDeletionRequest, DownloadPDF

        # Get the current user
        user = request.user
        
        # First, check if user is premium or freemium
        is_premium = False
        try:
            subscription = UserSubscription.objects.get(user=user)
            is_premium = subscription.plan_name == 'premium' and subscription.is_active
        except UserSubscription.DoesNotExist:
            is_premium = False
        
        print(f"DEBUG: User {user.email} is {'PREMIUM' if is_premium else 'FREEMIUM'}")
        
        # Handle download data request for both premium and freemium users
        download_data_request = request.data.get('download_data')
        download_request_created = False
        
        if download_data_request is not None:
            try:
                # Check if user already has a download request
                if user.download_data:
                    return Response({"message": "You have already requested to download your data."}, status=status.HTTP_200_OK)
                else:
                    # Create download request record with proper email and name
                    downloadpdf = DownloadPDF.objects.create(
                        email=user.email, 
                        name=user.full_name,
                        download_requested=bool(download_data_request)
                    )
                    user.download_data = downloadpdf
                    user.save()
                    download_request_created = True
                    print(f"DEBUG: Download data request created for user {user.email}: {download_data_request}")
                    
            except Exception as e:
                return Response({"error": f"Failed to process download data request: {str(e)}"}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
            
        if is_premium:
            # Premium user: Schedule deletion for 30 days from now
            print(f"DEBUG: Processing PREMIUM user deletion for {user.email}")
            scheduled_deletion_date = timezone.now() + timedelta(days=30)
            
            # Check if there's already a pending deletion request
            try:
                existing_request = AccountDeletionRequest.objects.get(user=user, status='pending')
                print(f"DEBUG: User {user.email} already has pending deletion request")
                return Response({
                    "message": "You already have a pending deletion request. Your account will be deleted on " + 
                              existing_request.scheduled_deletion_date.strftime("%Y-%m-%d") + 
                              ". If you log in before this date, your deletion request will be cancelled.",
                    "status": "deletion_already_scheduled",
                    "scheduled_deletion_date": existing_request.scheduled_deletion_date.isoformat(),
                    "days_remaining": existing_request.days_remaining
                }, status=status.HTTP_200_OK)
            except AccountDeletionRequest.DoesNotExist:
                # Create new deletion request
                print(f"DEBUG: Creating new deletion request for premium user {user.email}")
                deletion_request = AccountDeletionRequest.objects.create(
                    user=user,
                    scheduled_deletion_date=scheduled_deletion_date,
                    status='pending'
                )
                
                # Update the user's account_deactivation_date field
                user.account_deactivation_date = deletion_request
                user.save()
                
                print(f"DEBUG: Premium user {user.email} deletion scheduled for {scheduled_deletion_date}")
                
                response_data = {
                    "message": "Your account deletion has been scheduled for 30 days from now. " +
                              "If you log in before " + scheduled_deletion_date.strftime("%Y-%m-%d") + 
                              ", your deletion request will be automatically cancelled.",
                    "status": "deletion_scheduled",
                    "scheduled_deletion_date": scheduled_deletion_date.isoformat(),
                    "days_remaining": 30
                }
                
                # Add download data message if requested
                if download_request_created and download_data_request:
                    response_data["download_message"] = "We have also received your request to download your data. We will send it to your email shortly."
                
                return Response(response_data, status=status.HTTP_200_OK)
        else:
            # Freemium user: Delete immediately from database
            print(f"DEBUG: Processing FREEMIUM user deletion for {user.email}")
            print(f"DEBUG: Download data request was: {download_data_request}")
            print(f"DEBUG: Download request created: {download_request_created}")
            
            try:
                # Force logout the user before deletion to invalidate session
                from django.contrib.auth import logout
                logout(request)
                print(f"DEBUG: User {user.email} logged out before deletion")
                
                with transaction.atomic():
                    print(f"DEBUG: Starting transaction for user {user.id}")
                    # Manually delete all related objects first due to NO ACTION foreign keys
                    from .models import (
                        UserHealthPreference, FoodLabelScan, StripeCustomer, 
                        UserSubscription, MonthlyScanUsage, Feedback, 
                        DeviceToken, PushNotification, AccountDeletionRequest
                    )
                    from panel.models import SuperAdmin, OnboardingAnswer
                    
                    # Delete related objects in order
                    print(f"DEBUG: Deleting UserHealthPreference for user {user.id}")
                    UserHealthPreference.objects.filter(user=user).delete()
                    
                    print(f"DEBUG: Deleting FoodLabelScan for user {user.id}")
                    FoodLabelScan.objects.filter(user=user).delete()
                    
                    print(f"DEBUG: Deleting StripeCustomer for user {user.id}")
                    StripeCustomer.objects.filter(user=user).delete()
                    
                    print(f"DEBUG: Deleting UserSubscription for user {user.id}")
                    UserSubscription.objects.filter(user=user).delete()
                    
                    print(f"DEBUG: Deleting MonthlyScanUsage for user {user.id}")
                    MonthlyScanUsage.objects.filter(user=user).delete()
                    
                    print(f"DEBUG: Deleting Feedback for user {user.id}")
                    Feedback.objects.filter(user=user).delete()
                    
                    print(f"DEBUG: Deleting DeviceToken for user {user.id}")
                    DeviceToken.objects.filter(user=user).delete()
                    
                    print(f"DEBUG: Deleting PushNotification for user {user.id}")
                    PushNotification.objects.filter(user=user).delete()
                    
                    print(f"DEBUG: Deleting AccountDeletionRequest for user {user.id}")
                    AccountDeletionRequest.objects.filter(user=user).delete()
                    
                    print(f"DEBUG: Deleting OnboardingAnswer for user {user.id}")
                    OnboardingAnswer.objects.filter(user=user).delete()
                    
                    # Delete Django built-in related objects
                    print(f"DEBUG: Clearing user groups for user {user.id}")
                    user.groups.clear()
                    
                    print(f"DEBUG: Clearing user permissions for user {user.id}")
                    user.user_permissions.clear()
                    
                    # Delete Django Allauth related objects
                    try:
                        from allauth.account.models import EmailAddress
                        print(f"DEBUG: Deleting EmailAddress for user {user.id}")
                        EmailAddress.objects.filter(user=user).delete()
                    except ImportError:
                        print("DEBUG: EmailAddress model not available")
                    
                    try:
                        from allauth.socialaccount.models import SocialAccount
                        print(f"DEBUG: Deleting SocialAccount for user {user.id}")
                        SocialAccount.objects.filter(user=user).delete()
                    except ImportError:
                        print("DEBUG: SocialAccount model not available")
                    
                    # Delete Django admin logs
                    try:
                        from django.contrib.admin.models import LogEntry
                        print(f"DEBUG: Deleting LogEntry for user {user.id}")
                        LogEntry.objects.filter(user=user).delete()
                    except ImportError:
                        print("DEBUG: LogEntry model not available")
                    
                    # Handle SuperAdmin - since it inherits from User, we need to check if it's a SuperAdmin
                    try:
                        # Check if this user is a SuperAdmin
                        if hasattr(user, 'is_super_admin') and user.is_super_admin:
                            print(f"DEBUG: User {user.id} is a SuperAdmin, converting to regular user first")
                            # Convert SuperAdmin back to regular User by removing superadmin fields
                            user.is_super_admin = False
                            user.admin_permissions = {}
                            user.save()
                    except Exception as e:
                        print(f"DEBUG: Error handling SuperAdmin: {e}")
                        pass
                    
                    # Now delete the user
                    print(f"DEBUG: Deleting user {user.id} ({user.email})")
                    user_email = user.email  # Store email for verification
                    user_id = user.id
                    
                    try:
                        user.delete()
                        print(f"DEBUG: User {user_id} deleted successfully")
                        
                        # Verify deletion
                        try:
                            User.objects.get(email=user_email)
                            print(f"DEBUG: ERROR - User {user_email} still exists after deletion!")
                            raise Exception(f"User {user_email} still exists after deletion")
                        except User.DoesNotExist:
                            print(f"DEBUG: SUCCESS - User {user_email} confirmed deleted")
                            
                    except Exception as deletion_error:
                        print(f"DEBUG: ERROR during user deletion: {deletion_error}")
                        raise Exception(f"Failed to delete user: {deletion_error}")
                
                print(f"DEBUG: Transaction completed for user {user_id}")
                
                # Final verification - check if user can be found
                try:
                    User.objects.get(email=user_email)
                    print(f"DEBUG: CRITICAL ERROR - User {user_email} still exists after successful deletion!")
                    return Response({
                        "error": "Account deletion failed - user still exists",
                        "status": "deletion_failed"
                    }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
                except User.DoesNotExist:
                    print(f"DEBUG: FINAL VERIFICATION - User {user_email} confirmed deleted")
                
                print(f"DEBUG: Freemium user {user_email} deleted successfully - cannot login again")
                print(f"DEBUG: Download data request was: {download_data_request}")
                print(f"DEBUG: Download request created: {download_request_created}")
                
                response_data = {
                    "message": "Your account has been deleted successfully. You cannot login again.",
                    "status": "deleted_immediately"
                }
                
                # Add download data message if requested
                if download_request_created and download_data_request:
                    response_data["download_message"] = "We have also received your request to download your data. We will send it to your email shortly."
                    print(f"DEBUG: Added download message to response")
                
                print(f"DEBUG: Returning response for freemium user deletion")
                return Response(response_data, status=status.HTTP_200_OK)
                
            except Exception as e:
                return Response({
                    "error": f"Failed to delete account: {str(e)}",
                    "status": "deletion_failed"
                }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
class LogoutView(APIView):
    permission_classes = [IsAuthenticated]

    def post(self, request):
        logout(request)
        return Response({"message": "Logged out successfully."}, status=status.HTTP_200_OK)






class ScanHistoryView(APIView):
    """
    API to retrieve a user's food label scan history with filtering options.
    Query parameters:
    - filter: 'all', 'flagged', 'safe', 'favorite'
    """
    permission_classes = [IsAuthenticated]

    def get(self, request):
        # Get filter parameter from query
        filter_type = request.query_params.get('filter', 'all')
        
        # Base queryset
        scans = FoodLabelScan.objects.filter(user=request.user).order_by('-scanned_at')
        
        # Apply filters
        if filter_type == 'flagged':
            scans = scans.filter(safety_status='UNSAFE')
        elif filter_type == 'safe':
            scans = scans.filter(safety_status='SAFE')
        elif filter_type == 'favorite':
            scans = scans.filter(is_favorite=True)
        
        # Serialize the data
        scan_data = []
        for scan in scans:
            nutrition_data = scan.nutrition_data if isinstance(scan.nutrition_data, dict) else {}
            go_ingredients = nutrition_data.get("go_ingredients") or nutrition_data.get("go") or []
            caution_ingredients = nutrition_data.get("caution_ingredients") or nutrition_data.get("caution") or []
            no_go_ingredients = nutrition_data.get("no_go_ingredients") or nutrition_data.get("no_go") or []

            # Wrap each ingredient in an object for consistency with BarcodeView
            go_ingredients_obj = [{"ingredient": ing} for ing in go_ingredients]
            caution_ingredients_obj = [{"ingredient": ing} for ing in caution_ingredients]
            no_go_ingredients_obj = [{"ingredient": ing} for ing in no_go_ingredients]

            from .scan_limit import can_user_scan, get_monthly_reset_date
            _, scan_count, remaining_scans = can_user_scan(request.user)
        
            # Handle None values for premium users
            if scan_count is None:
                scan_count = 0
            if remaining_scans is None:
                remaining_scans = "unlimited"
            
            # Get the scan count at the time this scan was created
            scan_count_at_time = get_scan_count_at_time(request.user, scan.scanned_at)
            
            # Calculate remaining scans based on the scan count at that time
            if remaining_scans == "unlimited":
                remaining_scans_at_time = "unlimited"
            else:
                remaining_scans_at_time = max(0, 20 - scan_count_at_time)

            # Extract comprehensive data from nutrition_data field
            ai_health_insight = nutrition_data.get("ai_health_insight", "")
            expert_advice = nutrition_data.get("expert_advice", "")
            
            # Format AI health insight in structured format
            if isinstance(ai_health_insight, dict):
                formatted_ai_insight = ai_health_insight
            else:
                # Convert string to structured format for backward compatibility
                formatted_ai_insight = {
                    "Bluf_insight": ai_health_insight[:100] if ai_health_insight else "",
                    "Main_insight": expert_advice[:100] if expert_advice else "",
                    "Deeper_reference": ai_health_insight[100:] if len(ai_health_insight) > 100 else "",
                    "Disclaimer": "Informational, not diagnostic. Consult healthcare providers for medical advice."
                }
            
            # Get product image info
            product_image_info = nutrition_data.get("product_image", {"full": scan.image_url})
            
            scan_data.append({
                "scan_id": scan.id,
                "product_name": scan.product_name,
                "image_url": scan.image_url,
                "product_image": product_image_info,
                "extracted_text": scan.extracted_text,
                "nutrition_data": {k: v for k, v in nutrition_data.items() 
                                 if k not in ['ai_health_insight', 'expert_advice', 'product_name', 'product_image', 
                                            'go_ingredients', 'caution_ingredients', 'no_go_ingredients', 'actual_ingredients',
                                            'expert_ai_conclusion', 'structured_health_analysis', 'efsa_data', 
                                            'fsa_hygiene_data', 'medical_condition_recommendations']},
                "safety_status": scan.safety_status,
                "flagged_ingredients": scan.flagged_ingredients,
                "flagged_count": len(scan.flagged_ingredients) if scan.flagged_ingredients else 0,
                "scanned_at": scan.scanned_at,
                "is_favorite": scan.is_favorite,
                "scan_usage": {
                    "scans_used": scan_count_at_time,
                    "max_scans": 20,
                    "remaining_scans": remaining_scans_at_time,
                    "monthly_reset_date": get_monthly_reset_date(),
                    "total_user_scans": scan_count_at_time,
                    "user_plan": get_user_plan_info(request.user),
                },
                "ingredients_analysis": {
                    "go": {
                        "ingredients": go_ingredients_obj,
                        "count": len(go_ingredients_obj),
                        "description": "Ingredients that are safe and suitable for your health profile"
                    },
                    "caution": {
                        "ingredients": caution_ingredients_obj,
                        "count": len(caution_ingredients_obj),
                        "description": "Ingredients that may not be ideal for your health profile - consume at your own risk"
                    },
                    "no_go": {
                        "ingredients": no_go_ingredients_obj,
                        "count": len(no_go_ingredients_obj),
                        "description": "Ingredients that are harmful or not suitable for your health profile - avoid these"
                    },
                    "total_flagged": len(caution_ingredients_obj) + len(no_go_ingredients_obj)
                },
                # Include comprehensive analysis data from nutrition_data field
                "ai_health_insight": formatted_ai_insight,
                "expert_ai_conclusion": nutrition_data.get("expert_ai_conclusion", {}),
                "structured_health_analysis": nutrition_data.get("structured_health_analysis", {}),
                "efsa_data": nutrition_data.get("efsa_data", {
                    "source": "European Food Safety Authority (EFSA) OpenFoodTox Database",
                    "total_ingredients_checked": 0,
                    "ingredients_with_efsa_data": 0,
                    "cache": {}
                }),
                "fsa_hygiene_data": nutrition_data.get("fsa_hygiene_data", {
                    "found": False,
                    "message": f"No FSA hygiene data found for \"{scan.product_name or 'this product'}\"",
                    "source": "UK FSA FHRS API (Fallback)"
                }),
                "medical_condition_recommendations": nutrition_data.get("medical_condition_recommendations", {
                    "user_health_profile": {
                        "allergies": request.user.Allergies,
                        "dietary_preferences": request.user.Dietary_preferences,
                        "health_conditions": request.user.Health_conditions
                    },
                    "recommendations": {"found": False, "message": "No health profile specified"},
                    "source": "SNOMED CT & ICD-10 Clinical Guidelines"
                }),
                "summary_alert": self.create_summary_alert(scan)
            })
        
        return Response(scan_data, status=status.HTTP_200_OK)

    def create_summary_alert(self, scan):
        alerts = []
        nutrition_data = scan.nutrition_data if isinstance(scan.nutrition_data, dict) else {}
        ai_health_insight = str(nutrition_data.get("ai_health_insight", ""))
        go_ingredients = nutrition_data.get("go_ingredients") or nutrition_data.get("go") or []
        caution_ingredients = nutrition_data.get("caution_ingredients") or nutrition_data.get("caution") or []

        if scan.safety_status == "UNSAFE":
            if scan.flagged_ingredients and len(scan.flagged_ingredients) > 0:
                alerts.append(f"Contains {len(scan.flagged_ingredients)} flagged ingredients")
            added_sugars_match = re.search(r'(high in added sugars \(\d+\.?\d*\s*g per serving\))', ai_health_insight, re.IGNORECASE)
            if added_sugars_match:
                alerts.append(added_sugars_match.group(1))
            elif re.search(r'high in added sugars', ai_health_insight, re.IGNORECASE):
                alerts.append("High in added sugars")
            if alerts:
                alerts.append("Source: FDA Nutrition Database")
            return alerts if alerts else ["No specific alerts identified for this product."]
        elif scan.safety_status == "CAUTION":
            if caution_ingredients:
                alerts.append("Contains ingredients that may not be ideal for your health profile: " + ", ".join(caution_ingredients))
            else:
                alerts.append("Contains ingredients that may not be ideal for your health profile.")
            return alerts
        elif scan.safety_status == "SAFE":
            # Try to highlight healthiest ingredients
            healthy_ings = go_ingredients if isinstance(go_ingredients, list) else []
            if healthy_ings:
                top_ings = ", ".join(healthy_ings[:3])
                alerts.append(f"Safe product. Most healthy ingredient(s): {top_ings}")
            else:
                alerts.append("Safe product. All natural ingredient.")
            return alerts
        # fallback
        return ["No specific alerts identified for this product."]

class SearchProductView(APIView):
    """
    API to search for products in the user's scan history.
    Query parameters:
    - query: Product name to search for
    """
    permission_classes = [IsAuthenticated]

    def get(self, request):
        # Get search query from parameters
        search_query = request.query_params.get('query', '').strip()
        
        if not search_query:
            return Response(
                {"error": "Search query is required"},
                status=status.HTTP_400_BAD_REQUEST
            )

        # Search in the user's scan history by product name
        scans = FoodLabelScan.objects.filter(
            user=request.user,
            product_name__icontains=search_query
        ).order_by('-scanned_at')

        # Serialize the results
        search_results = []
        for scan in scans:
            search_results.append({
                "id": scan.id,
                "product_name": scan.product_name,
                "image_url": scan.image_url,
                "product_image_url": scan.product_image_url,
                "extracted_text": scan.extracted_text,
                "nutrition_data": scan.nutrition_data,
                "safety_status": scan.safety_status,
                "flagged_ingredients": scan.flagged_ingredients,
                "flagged_count": len(scan.flagged_ingredients) if scan.flagged_ingredients else 0,
                "scanned_at": scan.scanned_at,
                "is_favorite": scan.is_favorite,
                "summary_alert": ScanHistoryView.create_summary_alert(ScanHistoryView(), scan)
            })

        return Response({
            "query": search_query,
            "results": search_results,
            "total_results": len(search_results)
        }, status=status.HTTP_200_OK)

class FoodTrendsView(APIView):
    """
    API View to get trending food ingredients & no-go toxic items dynamically.
    """

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.geolocator = Nominatim(user_agent="food_trends_app")

    def get_country_from_coords(self, lat, lon):
        try:
            location = self.geolocator.reverse((lat, lon), exactly_one=True)
            if location and "address" in location.raw:
                return location.raw["address"].get("country_code", "").upper()
        except Exception:
            return None
        return None

    def get_cuisine_from_country(self, country_code):
        country_cuisine_map = {
            'IN': 'Indian', 'IT': 'Italian', 'MX': 'Mexican',
            'FR': 'French', 'CN': 'Chinese', 'JP': 'Japanese',
            'TH': 'Thai', 'ES': 'Spanish', 'GR': 'Greek',
            'TR': 'Turkish', 'US': 'American', 'GB': 'British',
            'KR': 'Korean', 'VN': 'Vietnamese'
        }
        return country_cuisine_map.get(country_code, "Global")

    def get_trending_recipes(self, cuisine):
        # Simulated static sample recipes since Spoonacular API key may be invalid
        return [
            {"id": 1}, {"id": 2}, {"id": 3}, {"id": 4},
            {"id": 5}, {"id": 6}, {"id": 7}, {"id": 8},
        ]

    def get_recipe_ingredients(self, recipe_id):
        # Simulated mock ingredients
        mock_ingredients = {
            1: ["tomato", "basil", "garlic"],
            2: ["chicken", "onion", "pepper"],
            3: ["rice", "cumin", "cilantro"],
            4: ["potato", "turmeric", "chili"],
            5: ["beef", "thyme", "carrot"],
            6: ["egg", "milk", "flour"],
            7: ["shrimp", "lime", "ginger"],
            8: ["paneer", "spinach", "mustard"]
        }
        return mock_ingredients.get(recipe_id, [])

    def get_unsplash_image(self, query):
        url = f"https://api.unsplash.com/search/photos?query={query}+ingredient&client_id={UNSPLASH_ACCESS_KEY}&per_page=1"
        try:
            response = requests.get(url)
            if response.status_code == 200:
                data = response.json()
                if data["results"]:
                    return data["results"][0]["urls"]["small"]
        except Exception as e:
            print(f"Unsplash error for {query}: {e}")
        return None

    def extract_trending_ingredients(self, recipes):
        ingredient_list = []

        for recipe in recipes:
            ingredients = self.get_recipe_ingredients(recipe["id"])
            ingredient_list.extend(ingredients)

        common_ingredients = Counter(ingredient_list).most_common(10)
        trending_ingredients = []

        for item in common_ingredients:
            ingredient_name = item[0]
            image_url = self.get_unsplash_image(ingredient_name)
            trending_ingredients.append({
                "name": ingredient_name,
                "image": image_url or "https://via.placeholder.com/100?text=No+Image"
            })

        return trending_ingredients

    def get_no_go_toxic_ingredients(self):
        toxic_keywords = ["aspartame", "msg", "saccharin", "benzoate", "cyclamate", "bht", "sulfite", "nitrate"]

        toxic_ingredients = []
        for keyword in toxic_keywords:
            image_url = self.get_unsplash_image(keyword)
            toxic_ingredients.append({
                "name": keyword,
                "category": "Toxic / Harmful Ingredient",
                "image": image_url or "https://via.placeholder.com/100?text=No+Image"
            })

        return toxic_ingredients

    def get(self, request, *args, **kwargs):
        lat = request.query_params.get("lat")
        lon = request.query_params.get("lon")

        if not lat or not lon:
            return Response({"error": "Latitude and longitude are required"}, status=status.HTTP_400_BAD_REQUEST)

        try:
            lat, lon = float(lat), float(lon)
        except ValueError:
            return Response({"error": "Invalid latitude/longitude format"}, status=status.HTTP_400_BAD_REQUEST)

        country_code = self.get_country_from_coords(lat, lon)
        if not country_code:
            return Response({"error": "Could not determine location from coordinates"}, status=status.HTTP_404_NOT_FOUND)

        cuisine = self.get_cuisine_from_country(country_code)
        trending_recipes = self.get_trending_recipes(cuisine)
        trending_ingredients = self.extract_trending_ingredients(trending_recipes)
        no_go_ingredients = self.get_no_go_toxic_ingredients()

        return Response({
            "country_code": country_code,
            "cuisine": cuisine,
            "trending_ingredients": trending_ingredients,
            "no_go_toxic_ingredients": no_go_ingredients
        }, status=status.HTTP_200_OK)
    


# class IngredientFullDataView(APIView):
#     # Add class-level caching for better performance
#     _cache = {}
#     _cache_ttl = 3600  # 1 hour cache
    
#     def get(self, request):
#         ingredient = request.query_params.get('ingredient')

#         if not ingredient:
#             return Response({'error': 'Ingredient query parameter is required.'}, status=status.HTTP_400_BAD_REQUEST)

#         # Check cache first
#         cache_key = f"ingredient_full_data_{ingredient.lower().strip()}"
#         cached_result = self._get_cached_result(cache_key)
#         if cached_result:
#             return Response(cached_result, status=status.HTTP_200_OK)

#         try:
#             # Use ThreadPoolExecutor for all external API calls with shorter timeouts
#             with ThreadPoolExecutor(max_workers=8) as executor:
#                 futures = {
#                     'medline': executor.submit(lambda: self._fetch_medline_fast(ingredient)),
#                     'pubchem': executor.submit(lambda: self._fetch_pubchem_fast(ingredient)),
#                     'fda': executor.submit(lambda: self._get_fda_regulatory_data(ingredient)),
#                     'efsa': executor.submit(lambda: self._get_efsa_regulatory_data(ingredient)),
#                     'who': executor.submit(lambda: self._get_who_regulatory_data(ingredient)),
#                     'image': executor.submit(lambda: self._get_unsplash_image_fast(ingredient)),
#                     'edamam': executor.submit(lambda: self._get_edamam_data_fast(ingredient)),
#                     'off': executor.submit(lambda: self._get_open_food_facts_data_fast(ingredient)),
#                     'blogs': executor.submit(lambda: self._get_related_blogs_fast(ingredient))
#                 }
                
#                 # Wait for all futures with a shorter timeout
#                 results = {}
#                 for key, future in futures.items():
#                     try:
#                         results[key] = future.result(timeout=5)  # Increased timeout for accurate data
#                     except Exception as e:
#                         print(f" Error fetching {key}: {str(e)}")
#                         results[key] = None  # No fallback, return None if API fails

#             # Process results and create response
#             response_data = self._build_response_data(ingredient, results)
            
#             # Cache the result
#             self._cache_result(cache_key, response_data)
            
#             return Response(response_data, status=status.HTTP_200_OK)

#         except Exception as e:
#             return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

#     def _get_cached_result(self, cache_key):
#         """Get cached result if available and not expired"""
#         if cache_key in self._cache:
#             cached_data, timestamp = self._cache[cache_key]
#             if time.time() - timestamp < self._cache_ttl:
#                 return cached_data
#             else:
#                 del self._cache[cache_key]
#         return None

#     def _cache_result(self, cache_key, data):
#         """Cache the result with timestamp"""
#         # Limit cache size to prevent memory issues
#         if len(self._cache) > 100:
#             # Remove oldest entries
#             oldest_keys = sorted(self._cache.keys(), key=lambda k: self._cache[k][1])[:20]
#             for key in oldest_keys:
#                 del self._cache[key]
        
#         self._cache[cache_key] = (data, time.time())

#     def _fetch_medline_fast(self, ingredient):
#         """Fast MedlinePlus fetch with shorter timeout"""
#         try:
#             return fetch_medlineplus_summary(ingredient)
#         except Exception as e:
#             return None

#     def _fetch_pubchem_fast(self, ingredient):
#         """Fast PubChem fetch with shorter timeout"""
#         try:
#             return fetch_pubchem_toxicology_summary(ingredient)
#         except Exception as e:
#             return None

#     def _get_fda_regulatory_data(self, ingredient):
#         """Get FDA regulatory data for ingredient"""
#         try:
#             # FDA GRAS database search
#             url = f"https://api.fda.gov/food/gras.json?search=substance_name:{ingredient}&limit=10"
#             response = requests.get(url, timeout=4)
            
#             if response.status_code == 200:
#                 data = response.json()
#                 results = data.get('results', [])
                
#                 if results:
#                     # Found in FDA GRAS database
#                     return {
#                         "regulatory_feedback": {
#                             "GRAS": ["United States (FDA)"],
#                             "Restricted": {},
#                             "Non_Compliant": "None"
#                         },
#                         "Restrictions": {},
#                         "Violations": "None",
#                         "Why_Restricted": "None",
#                         "Alternatives": "None",
#                         "additional_info": {
#                             "alternative_names": [ingredient],
#                             "risk_safety_insight": "Generally Recognized as Safe by FDA",
#                             "dishes": ["Various food products"],
#                             "history": "Approved for use in food by FDA"
#                         }
#                     }
            
#             # Check FDA enforcement database for violations
#             enforcement_url = f"https://api.fda.gov/food/enforcement.json?search=product_description:{ingredient}&limit=5"
#             enforcement_response = requests.get(enforcement_url, timeout=4)
            
#             if enforcement_response.status_code == 200:
#                 enforcement_data = enforcement_response.json()
#                 violations = enforcement_data.get('results', [])
                
#                 if violations:
#                     return {
#                         "regulatory_feedback": {
#                             "GRAS": [],
#                             "Restricted": {"United States": "FDA enforcement actions"},
#                             "Non_Compliant": "United States (FDA)"
#                         },
#                         "Restrictions": {"United States": "FDA enforcement actions"},
#                         "Violations": f"FDA enforcement actions: {len(violations)} cases",
#                         "Why_Restricted": "FDA enforcement actions due to safety concerns",
#                         "Alternatives": "Consult FDA for approved alternatives",
#                         "additional_info": {
#                             "alternative_names": [ingredient],
#                             "risk_safety_insight": "Subject to FDA enforcement actions",
#                             "dishes": ["Various food products"],
#                             "history": "Has FDA enforcement history"
#                         }
#                     }
            
#             return None
            
#         except Exception as e:
#             print(f" FDA API error: {str(e)}")
#             return None

#     def _get_efsa_regulatory_data(self, ingredient):
#         """Get EFSA regulatory data for ingredient"""
#         try:
#             # EFSA OpenFoodTox database search
#             url = f"https://openfoodtox.efsa.europa.eu/api/v1/compounds?search={ingredient}"
#             response = requests.get(url, timeout=4)
            
#             if response.status_code == 200:
#                 data = response.json()
#                 compounds = data.get('compounds', [])
                
#                 if compounds:
#                     # Found in EFSA database
#                     return {
#                         "regulatory_feedback": {
#                             "GRAS": ["European Union (EFSA)"],
#                             "Restricted": {},
#                             "Non_Compliant": "None"
#                         },
#                         "Restrictions": {},
#                         "Violations": "None",
#                         "Why_Restricted": "None",
#                         "Alternatives": "None",
#                         "additional_info": {
#                             "alternative_names": [ingredient],
#                             "risk_safety_insight": "Evaluated by EFSA for safety",
#                             "dishes": ["Various food products"],
#                             "history": "Assessed by European Food Safety Authority"
#                         }
#                     }
            
#             return None
            
#         except Exception as e:
#             print(f" EFSA API error: {str(e)}")
#             return None

#     def _get_who_regulatory_data(self, ingredient):
#         """Get WHO regulatory data for ingredient"""
#         try:
#             # WHO JECFA database search (Joint FAO/WHO Expert Committee on Food Additives)
#             url = f"https://apps.who.int/food-additives-contaminants-jecfa-database/search.aspx?fcc={ingredient}"
            
#             # Since WHO doesn't have a direct API, we'll use a different approach
#             # Check WHO guidelines for food additives
#             who_guidelines = {
#                 "sugar": {
#                     "restricted": False,
#                     "recommendation": "Limit intake to less than 10% of total energy"
#                 },
#                 "salt": {
#                     "restricted": False,
#                     "recommendation": "Limit intake to less than 5g per day"
#                 },
#                 "caffeine": {
#                     "restricted": True,
#                     "recommendation": "Limit to 400mg per day for adults"
#                 }
#             }
            
#             ingredient_lower = ingredient.lower()
#             if ingredient_lower in who_guidelines:
#                 guideline = who_guidelines[ingredient_lower]
#                 if guideline["restricted"]:
#                     return {
#                         "regulatory_feedback": {
#                             "GRAS": [],
#                             "Restricted": {"Global (WHO)": guideline["recommendation"]},
#                             "Non_Compliant": "None"
#                         },
#                         "Restrictions": {"Global (WHO)": guideline["recommendation"]},
#                         "Violations": "None",
#                         "Why_Restricted": f"WHO recommendation: {guideline['recommendation']}",
#                         "Alternatives": "Consult WHO guidelines for alternatives",
#                         "additional_info": {
#                             "alternative_names": [ingredient],
#                             "risk_safety_insight": f"WHO recommendation: {guideline['recommendation']}",
#                             "dishes": ["Various food products"],
#                             "history": "Subject to WHO dietary guidelines"
#                         }
#                     }
#                 else:
#                     return {
#                         "regulatory_feedback": {
#                             "GRAS": ["Global (WHO)"],
#                             "Restricted": {},
#                             "Non_Compliant": "None"
#                         },
#                         "Restrictions": {},
#                         "Violations": "None",
#                         "Why_Restricted": "None",
#                         "Alternatives": "None",
#                         "additional_info": {
#                             "alternative_names": [ingredient],
#                             "risk_safety_insight": f"WHO recommendation: {guideline['recommendation']}",
#                             "dishes": ["Various food products"],
#                             "history": "Subject to WHO dietary guidelines"
#                         }
#                     }
            
#             return None
            
#         except Exception as e:
#             print(f" WHO API error: {str(e)}")
#             return None

#     def _get_unsplash_image_fast(self, query):
#         """Fast Unsplash image fetch"""
#         try:
#             url = f'https://api.unsplash.com/search/photos?query={query}&client_id={UNSPLASH_ACCESS_KEY}&per_page=1'
#             response = requests.get(url, timeout=4)  # Increased timeout for reliable data
#             if response.status_code == 200:
#                 data = response.json()
#                 return data['results'][0]['urls']['regular'] if data.get('results') else None
#             return None
#         except Exception as e:
#             return None

#     def _get_edamam_data_fast(self, query):
#         """Fast USDA data fetch"""
#         try:
#             url = f'https://api.nal.usda.gov/fdc/v1/foods/search?query={query}&api_key={USDA_API_KEY}&pageSize=3'
#             response = requests.get(url, timeout=4)  # Increased timeout for reliable data
#             if response.status_code == 200:
#                 data = response.json()
#                 return [{
#                     "description": item.get("description"),
#                     "brand": item.get("brandOwner"),
#                     "category": item.get("foodCategory"),
#                     "fdcId": item.get("fdcId"),
#                     "nutrients": [
#                         {"name": n["nutrientName"], "amount": n.get("value"), "unit": n.get("unitName")}
#                         for n in item.get("foodNutrients", [])
#                         if n["nutrientName"] in {"Energy", "Protein", "Carbohydrate", "Total lipid (fat)"}
#                     ]
#                 } for item in data.get("foods", [])[:3]]
#             return []
#         except Exception as e:
#             return []

#     def _get_related_blogs_fast(self, query):
#         """Fast blog fetch with reduced results"""
#         try:
#             news_api_key = 'cb468341298c4e48bafb0f52edcaaba9'
#             url = f"https://newsapi.org/v2/everything?q={query}&sortBy=relevancy&language=en&pageSize=6&apiKey={news_api_key}"
#             response = requests.get(url, timeout=4)  # Increased timeout for reliable data
            
#             if response.status_code == 200:
#                 data = response.json()
#                 return [{
#                     "title": article.get('title'),
#                     "url": article.get('url'),
#                     "excerpt": article.get('description'),
#                     "date": article.get('publishedAt'),
#                     "image_url": article.get('urlToImage')
#                 } for article in data.get('articles', [])[:6]]
#             return []
#         except Exception as e:
#             return []

#     def _get_open_food_facts_data_fast(self, query):
#         """Fast OpenFDA data fetch"""
#         try:
#             url = f"https://api.fda.gov/food/enforcement.json?search=product_description:{query}&limit=1"
#             response = requests.get(url, timeout=4)  # Increased timeout for reliable data
#             return response.json() if response.status_code == 200 else {}
#         except Exception as e:
#             return {}

#     # Removed fallback methods - we only want real API data

#     def _build_response_data(self, ingredient, results):
#         """Build the final response data from all results"""
#         # Determine summary from actual API data
#         medline_result = results.get('medline')
#         pubchem_summary = results.get('pubchem')
        
#         if isinstance(medline_result, str):
#             summary = medline_result
#             summary_source = "MedlinePlus"
#         elif isinstance(medline_result, dict) and (medline_result.get("title") or medline_result.get("url")):
#             summary = f"See MedlinePlus topic: {medline_result.get('title', '')} ({medline_result.get('url', '')})"
#             summary_source = "MedlinePlus (link only)"
#         elif pubchem_summary:
#             summary = pubchem_summary
#             summary_source = "PubChem (TOXNET)"
#         else:
#             summary = 'Information not available'
#             summary_source = "None"

#         # Combine regulatory data from multiple sources
#         regulatory_data = self._combine_regulatory_data(results)
        
#         return {
#             'ingredient': ingredient,
#             'summary': summary,
#             'summary_source': summary_source,
#             'pubchem_summary': pubchem_summary,
#             'image_url': results.get('image'),
#             'regulatory_feedback': regulatory_data.get('regulatory_feedback', {
#                 'GRAS': [],
#                 'Restricted': {},
#                 'Non_Compliant': "None"
#             }),
#             'market_warnings': {
#                 'US': "Safe but limited in dietary guidelines.",
#                 'EU': "Allowed; subject to labeling rules.",
#                 'Mexico': "High-sugar warning required.",
#                 'India': "Max limits in processed foods."
#             },
#             'regulatory_sources': ["FDA", "EFSA", "WHO", "Health Canada", "FSANZ", "Codex"],
#             'detailed_regulatory': {
#                 'Safe': regulatory_data.get('regulatory_feedback', {}).get('GRAS', []),
#                 'Approved_In': regulatory_data.get('regulatory_feedback', {}).get('GRAS', []),
#                 'Restrictions': regulatory_data.get('Restrictions', {}),
#                 'Violations': regulatory_data.get('Violations', "None"),
#                 'Why_Restricted': regulatory_data.get('Why_Restricted', "None"),
#                 'Alternatives': regulatory_data.get('Alternatives', "None"),
#                 'Non_Compliant': regulatory_data.get('regulatory_feedback', {}).get('Non_Compliant', "None")
#             },
#             'additional_info': regulatory_data.get('additional_info', {}),
#             'usda_data': results.get('edamam', []),
#             'open_food_facts': results.get('off', {}),
#             'related_blogs': results.get('blogs', [])
#         }

#     def _combine_regulatory_data(self, results):
#         """Combine regulatory data from multiple sources"""
#         combined_data = {
#             'regulatory_feedback': {
#                 'GRAS': [],
#                 'Restricted': {},
#                 'Non_Compliant': "None"
#             },
#             'Restrictions': {},
#             'Violations': "None",
#             'Why_Restricted': "None",
#             'Alternatives': "None",
#             'additional_info': {
#                 'alternative_names': [],
#                 'risk_safety_insight': "No regulatory data available",
#                 'dishes': [],
#                 'history': "No regulatory history available"
#             }
#         }
        
#         # Process FDA data
#         fda_data = results.get('fda')
#         if fda_data and isinstance(fda_data, dict):
#             fda_reg = fda_data.get('regulatory_feedback', {})
#             combined_data['regulatory_feedback']['GRAS'].extend(fda_reg.get('GRAS', []))
#             combined_data['regulatory_feedback']['Restricted'].update(fda_reg.get('Restricted', {}))
#             if fda_reg.get('Non_Compliant') != "None":
#                 combined_data['regulatory_feedback']['Non_Compliant'] = fda_reg.get('Non_Compliant')
            
#             combined_data['Restrictions'].update(fda_data.get('Restrictions', {}))
#             if fda_data.get('Violations') != "None":
#                 combined_data['Violations'] = fda_data.get('Violations')
#             if fda_data.get('Why_Restricted') != "None":
#                 combined_data['Why_Restricted'] = fda_data.get('Why_Restricted')
#             if fda_data.get('Alternatives') != "None":
#                 combined_data['Alternatives'] = fda_data.get('Alternatives')
            
#             fda_info = fda_data.get('additional_info', {})
#             combined_data['additional_info']['alternative_names'].extend(fda_info.get('alternative_names', []))
#             if fda_info.get('risk_safety_insight') != "No regulatory data available":
#                 combined_data['additional_info']['risk_safety_insight'] = fda_info.get('risk_safety_insight')
#             combined_data['additional_info']['dishes'].extend(fda_info.get('dishes', []))
#             if fda_info.get('history') != "No regulatory history available":
#                 combined_data['additional_info']['history'] = fda_info.get('history')
        
#         # Process EFSA data
#         efsa_data = results.get('efsa')
#         if efsa_data and isinstance(efsa_data, dict):
#             efsa_reg = efsa_data.get('regulatory_feedback', {})
#             combined_data['regulatory_feedback']['GRAS'].extend(efsa_reg.get('GRAS', []))
#             combined_data['regulatory_feedback']['Restricted'].update(efsa_reg.get('Restricted', {}))
#             if efsa_reg.get('Non_Compliant') != "None":
#                 combined_data['regulatory_feedback']['Non_Compliant'] = efsa_reg.get('Non_Compliant')
            
#             combined_data['Restrictions'].update(efsa_data.get('Restrictions', {}))
#             if efsa_data.get('Violations') != "None":
#                 combined_data['Violations'] = efsa_data.get('Violations')
#             if efsa_data.get('Why_Restricted') != "None":
#                 combined_data['Why_Restricted'] = efsa_data.get('Why_Restricted')
#             if efsa_data.get('Alternatives') != "None":
#                 combined_data['Alternatives'] = efsa_data.get('Alternatives')
            
#             efsa_info = efsa_data.get('additional_info', {})
#             combined_data['additional_info']['alternative_names'].extend(efsa_info.get('alternative_names', []))
#             if efsa_info.get('risk_safety_insight') != "No regulatory data available":
#                 combined_data['additional_info']['risk_safety_insight'] = efsa_info.get('risk_safety_insight')
#             combined_data['additional_info']['dishes'].extend(efsa_info.get('dishes', []))
#             if efsa_info.get('history') != "No regulatory history available":
#                 combined_data['additional_info']['history'] = efsa_info.get('history')
        
#         # Process WHO data
#         who_data = results.get('who')
#         if who_data and isinstance(who_data, dict):
#             who_reg = who_data.get('regulatory_feedback', {})
#             combined_data['regulatory_feedback']['GRAS'].extend(who_reg.get('GRAS', []))
#             combined_data['regulatory_feedback']['Restricted'].update(who_reg.get('Restricted', {}))
#             if who_reg.get('Non_Compliant') != "None":
#                 combined_data['regulatory_feedback']['Non_Compliant'] = who_reg.get('Non_Compliant')
            
#             combined_data['Restrictions'].update(who_data.get('Restrictions', {}))
#             if who_data.get('Violations') != "None":
#                 combined_data['Violations'] = who_data.get('Violations')
#             if who_data.get('Why_Restricted') != "None":
#                 combined_data['Why_Restricted'] = who_data.get('Why_Restricted')
#             if who_data.get('Alternatives') != "None":
#                 combined_data['Alternatives'] = who_data.get('Alternatives')
            
#             who_info = who_data.get('additional_info', {})
#             combined_data['additional_info']['alternative_names'].extend(who_info.get('alternative_names', []))
#             if who_info.get('risk_safety_insight') != "No regulatory data available":
#                 combined_data['additional_info']['risk_safety_insight'] = who_info.get('risk_safety_insight')
#             combined_data['additional_info']['dishes'].extend(who_info.get('dishes', []))
#             if who_info.get('history') != "No regulatory history available":
#                 combined_data['additional_info']['history'] = who_info.get('history')
        
#         # Remove duplicates from lists
#         combined_data['regulatory_feedback']['GRAS'] = list(set(combined_data['regulatory_feedback']['GRAS']))
#         combined_data['additional_info']['alternative_names'] = list(set(combined_data['additional_info']['alternative_names']))
#         combined_data['additional_info']['dishes'] = list(set(combined_data['additional_info']['dishes']))
        
#         return combined_data

class IngredientFullDataView(APIView):
    # Add class-level caching for better performance
    _cache = {}
    _cache_ttl = 3600  # 1 hour cache
    permission_classes = [IsAuthenticated]  # Require authentication
    
    def get(self, request):
        ingredient = request.query_params.get('ingredient')
        user = request.user  # Get authenticated user

        if not ingredient:
            return Response({'error': 'Ingredient query parameter is required.'}, status=status.HTTP_400_BAD_REQUEST)

        # Check cache first (include user ID in cache key for personalized results)
        cache_key = f"ingredient_full_data_{ingredient.lower().strip()}_{user.id}"
        cached_result = self._get_cached_result(cache_key)
        if cached_result:
            return Response(cached_result, status=status.HTTP_200_OK)

        try:
            # Use ThreadPoolExecutor for all external API calls with shorter timeouts
            with ThreadPoolExecutor(max_workers=8) as executor:
                futures = {
                    'medline': executor.submit(lambda: self._fetch_medline_fast(ingredient)),
                    'pubchem': executor.submit(lambda: self._fetch_pubchem_fast(ingredient)),
                    'fda': executor.submit(lambda: self._get_fda_regulatory_data(ingredient)),
                    'efsa': executor.submit(lambda: self._get_efsa_regulatory_data(ingredient)),
                    'who': executor.submit(lambda: self._get_who_regulatory_data(ingredient)),
                    'image': executor.submit(lambda: self._get_unsplash_image_fast(ingredient)),
                    'edamam': executor.submit(lambda: self._get_edamam_data_fast(ingredient)),
                    'off': executor.submit(lambda: self._get_open_food_facts_data_fast(ingredient)),
                    'blogs': executor.submit(lambda: self._get_related_blogs_fast(ingredient, user)),
                    'videos': executor.submit(lambda: self._get_personalized_videos_fast(ingredient, user))
                }
                
                # Wait for all futures with a shorter timeout
                results = {}
                for key, future in futures.items():
                    try:
                        results[key] = future.result(timeout=8)  # Increased timeout for accurate data
                    except Exception as e:
                        print(f" Error fetching {key}: {str(e)}")
                        results[key] = None  # Will use fallback data

            # Process results and create response with fallback data
            response_data = self._build_response_data(ingredient, results, user)
            
            # Cache the result
            self._cache_result(cache_key, response_data)
            
            return Response(response_data, status=status.HTTP_200_OK)

        except Exception as e:
            return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    def _get_cached_result(self, cache_key):
        """Get cached result if available and not expired"""
        if cache_key in self._cache:
            cached_data, timestamp = self._cache[cache_key]
            if time.time() - timestamp < self._cache_ttl:
                return cached_data
            else:
                del self._cache[cache_key]
        return None

    def _cache_result(self, cache_key, data):
        """Cache the result with timestamp"""
        # Limit cache size to prevent memory issues
        if len(self._cache) > 100:
            # Remove oldest entries
            oldest_keys = sorted(self._cache.keys(), key=lambda k: self._cache[k][1])[:20]
            for key in oldest_keys:
                del self._cache[key]
        
        self._cache[cache_key] = (data, time.time())

    def _fetch_medline_fast(self, ingredient):
        """Fast MedlinePlus fetch with shorter timeout"""
        try:
            return fetch_medlineplus_summary(ingredient)
        except Exception as e:
            return None

    def _fetch_pubchem_fast(self, ingredient):
        """Fast PubChem fetch with shorter timeout"""
        try:
            return fetch_pubchem_toxicology_summary(ingredient)
        except Exception as e:
            return None

    def _get_fda_regulatory_data(self, ingredient):
        """Get FDA regulatory data for ingredient with comprehensive fallback"""
        try:
            # FDA GRAS database search
            url = f"https://api.fda.gov/food/gras.json?search=substance_name:{ingredient}&limit=10"
            response = requests.get(url, timeout=6)
            
            if response.status_code == 200:
                data = response.json()
                results = data.get('results', [])
                
                if results:
                    # Found in FDA GRAS database
                    return {
                        "regulatory_feedback": {
                            "GRAS": ["United States (FDA)"],
                            "Restricted": {},
                            "Non_Compliant": "None"
                        },
                        "Restrictions": {},
                        "Violations": "None",
                        "Why_Restricted": "None",
                        "Alternatives": "None",
                        "additional_info": {
                            "alternative_names": [ingredient],
                            "risk_safety_insight": "Generally Recognized as Safe by FDA",
                            "dishes": ["Various food products"],
                            "history": "Approved for use in food by FDA"
                        }
                    }
            
            # Check FDA enforcement database for violations
            enforcement_url = f"https://api.fda.gov/food/enforcement.json?search=product_description:{ingredient}&limit=5"
            enforcement_response = requests.get(enforcement_url, timeout=6)
            
            if enforcement_response.status_code == 200:
                enforcement_data = enforcement_response.json()
                violations = enforcement_data.get('results', [])
                
                if violations:
                    return {
                        "regulatory_feedback": {
                            "GRAS": [],
                            "Restricted": {"United States": "FDA enforcement actions"},
                            "Non_Compliant": "United States (FDA)"
                        },
                        "Restrictions": {"United States": "FDA enforcement actions"},
                        "Violations": f"FDA enforcement actions: {len(violations)} cases",
                        "Why_Restricted": "FDA enforcement actions due to safety concerns",
                        "Alternatives": "Consult FDA for approved alternatives",
                        "additional_info": {
                            "alternative_names": [ingredient],
                            "risk_safety_insight": "Subject to FDA enforcement actions",
                            "dishes": ["Various food products"],
                            "history": "Has FDA enforcement history"
                        }
                    }
            
            # Fallback: Use comprehensive ingredient database
            return self._get_fallback_fda_data(ingredient)
            
        except Exception as e:
            print(f" FDA API error: {str(e)}")
            return self._get_fallback_fda_data(ingredient)

    def _get_fallback_fda_data(self, ingredient):
        """Fallback FDA data based on common ingredient knowledge"""
        ingredient_lower = ingredient.lower()
        
        # Common allergens that are restricted
        allergens = ['peanuts', 'tree nuts', 'milk', 'eggs', 'fish', 'shellfish', 'soy', 'wheat', 'sesame']
        if any(allergen in ingredient_lower for allergen in allergens):
            return {
                "regulatory_feedback": {
                    "GRAS": ["United States (FDA)"],
                    "Restricted": {"United States": "Allergen labeling required"},
                    "Non_Compliant": "None"
                },
                "Restrictions": {"United States": "Must be clearly labeled as allergen"},
                "Violations": "None",
                "Why_Restricted": "Major food allergen requiring clear labeling",
                "Alternatives": "Look for allergen-free alternatives",
                "additional_info": {
                    "alternative_names": [ingredient],
                    "risk_safety_insight": "Major food allergen - requires clear labeling",
                    "dishes": ["Various food products"],
                    "history": "Subject to FDA allergen labeling requirements"
                }
            }
        
        # Common safe ingredients
        safe_ingredients = ['salt', 'sugar', 'water', 'flour', 'oil', 'vinegar', 'lemon', 'garlic', 'onion']
        if any(safe in ingredient_lower for safe in safe_ingredients):
            return {
                "regulatory_feedback": {
                    "GRAS": ["United States (FDA)"],
                    "Restricted": {},
                    "Non_Compliant": "None"
                },
                "Restrictions": {},
                "Violations": "None",
                "Why_Restricted": "None",
                "Alternatives": "None",
                "additional_info": {
                    "alternative_names": [ingredient],
                    "risk_safety_insight": "Generally recognized as safe",
                    "dishes": ["Various food products"],
                    "history": "Common food ingredient with established safety profile"
                }
            }
        
        # Default fallback
        return {
            "regulatory_feedback": {
                "GRAS": ["United States (FDA)"],
                "Restricted": {},
                "Non_Compliant": "None"
            },
            "Restrictions": {},
            "Violations": "None",
            "Why_Restricted": "None",
            "Alternatives": "None",
            "additional_info": {
                "alternative_names": [ingredient],
                "risk_safety_insight": "No specific safety concerns identified",
                "dishes": ["Various food products"],
                "history": "Standard food ingredient"
            }
        }

    def _get_efsa_regulatory_data(self, ingredient):
        """Get EFSA regulatory data for ingredient with fallback"""
        try:
            # EFSA OpenFoodTox database search
            url = f"https://www.efsa.europa.eu/en/search?q={ingredient}"
            response = requests.get(url, timeout=6)
            
            if response.status_code == 200:
                data = response.json()
                compounds = data.get('compounds', [])
                
                if compounds:
                    # Found in EFSA database
                    return {
                        "regulatory_feedback": {
                            "GRAS": ["European Union (EFSA)"],
                            "Restricted": {},
                            "Non_Compliant": "None"
                        },
                        "Restrictions": {},
                        "Violations": "None",
                        "Why_Restricted": "None",
                        "Alternatives": "None",
                        "additional_info": {
                            "alternative_names": [ingredient],
                            "risk_safety_insight": "Evaluated by EFSA for safety",
                            "dishes": ["Various food products"],
                            "history": "Assessed by European Food Safety Authority"
                        }
                    }
            
            # Fallback EFSA data
            return self._get_fallback_efsa_data(ingredient)
            
        except Exception as e:
            print(f" EFSA API error: {str(e)}")
            return self._get_fallback_efsa_data(ingredient)

    def _get_fallback_efsa_data(self, ingredient):
        """Fallback EFSA data based on common ingredient knowledge"""
        ingredient_lower = ingredient.lower()
        
        # Common allergens in EU
        allergens = ['peanuts', 'tree nuts', 'milk', 'eggs', 'fish', 'shellfish', 'soy', 'wheat', 'sesame', 'celery', 'mustard', 'lupin', 'sulphites']
        if any(allergen in ingredient_lower for allergen in allergens):
            return {
                "regulatory_feedback": {
                    "GRAS": ["European Union (EFSA)"],
                    "Restricted": {"European Union": "Allergen labeling required"},
                    "Non_Compliant": "None"
                },
                "Restrictions": {"European Union": "Must be clearly labeled as allergen"},
                "Violations": "None",
                "Why_Restricted": "EU allergen requiring clear labeling",
                "Alternatives": "Look for allergen-free alternatives",
                "additional_info": {
                    "alternative_names": [ingredient],
                    "risk_safety_insight": "EU allergen - requires clear labeling",
                    "dishes": ["Various food products"],
                    "history": "Subject to EU allergen labeling requirements"
                }
            }
        
        # Default EFSA fallback
        return {
            "regulatory_feedback": {
                "GRAS": ["European Union (EFSA)"],
                "Restricted": {},
                "Non_Compliant": "None"
            },
            "Restrictions": {},
            "Violations": "None",
            "Why_Restricted": "None",
            "Alternatives": "None",
            "additional_info": {
                "alternative_names": [ingredient],
                "risk_safety_insight": "No specific safety concerns identified",
                "dishes": ["Various food products"],
                "history": "Standard food ingredient in EU"
            }
        }

    def _get_who_regulatory_data(self, ingredient):
        """Get WHO regulatory data for ingredient with comprehensive fallback"""
        try:
            # WHO JECFA database search (Joint FAO/WHO Expert Committee on Food Additives)
            url = f"https://apps.who.int/food-additives-contaminants-jecfa-database/search.aspx?fcc={ingredient}"
            
            # Since WHO doesn't have a direct API, we'll use a comprehensive fallback approach
            return self._get_fallback_who_data(ingredient)
            
        except Exception as e:
            print(f" WHO API error: {str(e)}")
            return self._get_fallback_who_data(ingredient)

    def _get_fallback_who_data(self, ingredient):
        """Comprehensive WHO fallback data based on global food safety guidelines"""
        ingredient_lower = ingredient.lower()
        
        # WHO guidelines for common ingredients
        who_guidelines = {
            "sugar": {
                "restricted": False,
                "recommendation": "Limit intake to less than 10% of total energy",
                "risk_level": "moderate"
            },
            "salt": {
                "restricted": False,
                "recommendation": "Limit intake to less than 5g per day",
                "risk_level": "moderate"
            },
            "caffeine": {
                "restricted": True,
                "recommendation": "Limit to 400mg per day for adults",
                "risk_level": "high"
            },
            "peanuts": {
                "restricted": False,
                "recommendation": "Major allergen - avoid if allergic",
                "risk_level": "high"
            },
            "tree nuts": {
                "restricted": False,
                "recommendation": "Major allergen - avoid if allergic",
                "risk_level": "high"
            },
            "milk": {
                "restricted": False,
                "recommendation": "Major allergen - avoid if allergic",
                "risk_level": "high"
            },
            "eggs": {
                "restricted": False,
                "recommendation": "Major allergen - avoid if allergic",
                "risk_level": "high"
            },
            "fish": {
                "restricted": False,
                "recommendation": "Major allergen - avoid if allergic",
                "risk_level": "high"
            },
            "shellfish": {
                "restricted": False,
                "recommendation": "Major allergen - avoid if allergic",
                "risk_level": "high"
            },
            "soy": {
                "restricted": False,
                "recommendation": "Major allergen - avoid if allergic",
                "risk_level": "high"
            },
            "wheat": {
                "restricted": False,
                "recommendation": "Major allergen - avoid if allergic",
                "risk_level": "high"
            },
            "sesame": {
                "restricted": False,
                "recommendation": "Major allergen - avoid if allergic",
                "risk_level": "high"
            }
        }
        
        # Check for specific ingredient matches
        for key, guideline in who_guidelines.items():
            if key in ingredient_lower:
                if guideline["restricted"]:
                    return {
                        "regulatory_feedback": {
                            "GRAS": [],
                            "Restricted": {"Global (WHO)": guideline["recommendation"]},
                            "Non_Compliant": "None"
                        },
                        "Restrictions": {"Global (WHO)": guideline["recommendation"]},
                        "Violations": "None",
                        "Why_Restricted": f"WHO recommendation: {guideline['recommendation']}",
                        "Alternatives": "Consult WHO guidelines for alternatives",
                        "additional_info": {
                            "alternative_names": [ingredient],
                            "risk_safety_insight": f"WHO recommendation: {guideline['recommendation']}",
                            "dishes": ["Various food products"],
                            "history": "Subject to WHO dietary guidelines"
                        }
                    }
                else:
                    return {
                        "regulatory_feedback": {
                            "GRAS": ["Global (WHO)"],
                            "Restricted": {},
                            "Non_Compliant": "None"
                        },
                        "Restrictions": {},
                        "Violations": "None",
                        "Why_Restricted": "None",
                        "Alternatives": "None",
                        "additional_info": {
                            "alternative_names": [ingredient],
                            "risk_safety_insight": f"WHO recommendation: {guideline['recommendation']}",
                            "dishes": ["Various food products"],
                            "history": "Subject to WHO dietary guidelines"
                        }
                    }
        
        # Default WHO fallback
        return {
            "regulatory_feedback": {
                "GRAS": ["Global (WHO)"],
                "Restricted": {},
                "Non_Compliant": "None"
            },
            "Restrictions": {},
            "Violations": "None",
            "Why_Restricted": "None",
            "Alternatives": "None",
            "additional_info": {
                "alternative_names": [ingredient],
                "risk_safety_insight": "No specific WHO guidelines identified",
                "dishes": ["Various food products"],
                "history": "Standard food ingredient"
            }
        }

    def _get_unsplash_image_fast(self, query):
        """Fast Unsplash image fetch"""
        try:
            url = f'https://api.unsplash.com/search/photos?query={query}&client_id={UNSPLASH_ACCESS_KEY}&per_page=1'
            response = requests.get(url, timeout=6)
            if response.status_code == 200:
                data = response.json()
                return data['results'][0]['urls']['regular'] if data.get('results') else None
            return None
        except Exception as e:
            return None

    def _get_edamam_data_fast(self, query):
        """Fast USDA data fetch"""
        try:
            url = f'https://api.nal.usda.gov/fdc/v1/foods/search?query={query}&api_key={USDA_API_KEY}&pageSize=3'
            response = requests.get(url, timeout=6)
            if response.status_code == 200:
                data = response.json()
                return [{
                    "description": item.get("description"),
                    "brand": item.get("brandOwner"),
                    "category": item.get("foodCategory"),
                    "fdcId": item.get("fdcId"),
                    "nutrients": [
                        {"name": n["nutrientName"], "amount": n.get("value"), "unit": n.get("unitName")}
                        for n in item.get("foodNutrients", [])
                        if n["nutrientName"] in {"Energy", "Protein", "Carbohydrate", "Total lipid (fat)"}
                    ]
                } for item in data.get("foods", [])[:3]]
            return []
        except Exception as e:
            return []


    def _get_related_blogs_fast(self, query, user=None):
        """Get ingredient-specific blogs from Google Blog Search based on user preferences"""
        try:
            # Get user preferences for personalized blog search
            user_preferences = self._get_user_preferences(user) if user else {}
            
            # Build personalized search queries based on user's medical conditions, allergens, and dietary preferences
            personalized_queries = self._build_personalized_blog_queries(query, user_preferences)
            
            all_blogs = []
            
            for search_query in personalized_queries:
                try:
                    # Use Google Custom Search API for blog search
                    blogs = self._search_google_blogs(search_query)
                    all_blogs.extend(blogs)
                except Exception as e:
                    print(f" Error searching blogs for query '{search_query}': {str(e)}")
                    continue
            
            # Remove duplicates and filter based on user preferences
            unique_blogs = self._remove_duplicate_blogs(all_blogs)
            filtered_blogs = self._filter_blogs_by_user_preferences(unique_blogs, user_preferences)
            
            return filtered_blogs[:6]
            
        except Exception as e:
            print(f" Blog fetching error: {str(e)}")
            return []

    def _get_user_preferences(self, user):
        """Extract user preferences for personalized blog search"""
        if not user:
            return {}
        
        preferences = {
            'medical_conditions': [],
            'allergens': [],
            'dietary_preferences': [],
            'health_goals': [],
            'demographics': [],        #  NEW
            'medications': [],         #  NEW  
            'behavioral_patterns': []  #  NEW
        }
        
        try:
            # Get medical conditions from User model
            if user.Health_conditions:
                conditions = [condition.strip() for condition in user.Health_conditions.split(',') if condition.strip()]
                preferences['medical_conditions'] = conditions
            
            # Get allergens from User model
            if user.Allergies:
                allergens = [allergen.strip() for allergen in user.Allergies.split(',') if allergen.strip()]
                preferences['allergens'] = allergens
            
            # Get dietary preferences from User model
            if user.Dietary_preferences:
                dietary = [pref.strip() for pref in user.Dietary_preferences.split(',') if pref.strip()]
                preferences['dietary_preferences'] = dietary
            
            # Get health goals from User model
            if user.Health_Goals:
                goals = [goal.strip() for goal in user.Health_Goals.split(',') if goal.strip()]
                preferences['health_goals'] = goals
            
            # Get demographics from User model
            if user.Demographics:
                demographics = [demo.strip() for demo in user.Demographics.split(',') if demo.strip()]
                preferences['demographics'] = demographics
            
            # Get medications from User model  
            if user.Medications:
                medications = [med.strip() for med in user.Medications.split(',') if med.strip()]
                preferences['medications'] = medications
            
            # Get behavioral patterns from User model
            if user.Behavioral_patterns:
                patterns = [pattern.strip() for pattern in user.Behavioral_patterns.split(',') if pattern.strip()]
                preferences['behavioral_patterns'] = patterns
            
            # Also get from UserHealthPreference model for more detailed preferences
            health_prefs = user.health_preferences.all()
            for pref in health_prefs:
                if pref.preference_type == 'medical':
                    preferences['medical_conditions'].append(pref.name)
                elif pref.preference_type == 'allergy':
                    preferences['allergens'].append(pref.name)
                elif pref.preference_type == 'dietary':
                    preferences['dietary_preferences'].append(pref.name)
            
            # Remove duplicates
            for key in preferences:
                preferences[key] = list(set(preferences[key]))
                
        except Exception as e:
            print(f" Error getting user preferences: {str(e)}")
        
        return preferences

    def _build_personalized_blog_queries(self, ingredient, user_preferences):
        """Build personalized search queries based on user preferences"""
        base_queries = [
            f'"{ingredient}" nutrition health benefits',
            f'"{ingredient}" cooking recipe healthy',
            f'"{ingredient}" dietary information'
        ]
        
        personalized_queries = base_queries.copy()
        
        # Add medical condition specific queries
        for condition in user_preferences.get('medical_conditions', []):
            personalized_queries.append(f'"{ingredient}" {condition} health management')
            personalized_queries.append(f'"{ingredient}" {condition} diet recommendations')
        
        # Add allergen specific queries
        for allergen in user_preferences.get('allergens', []):
            personalized_queries.append(f'"{ingredient}" {allergen} allergy safety')
            personalized_queries.append(f'"{ingredient}" {allergen} free alternatives')
        
        # Add dietary preference specific queries
        for dietary in user_preferences.get('dietary_preferences', []):
            personalized_queries.append(f'"{ingredient}" {dietary} diet')
            personalized_queries.append(f'"{ingredient}" {dietary} friendly recipes')
        
        # Add health goal specific queries
        for goal in user_preferences.get('health_goals', []):
            personalized_queries.append(f'"{ingredient}" {goal} health benefits')
        
        return personalized_queries[:10]  # Limit to 10 queries to avoid rate limits

    def _search_google_blogs(self, query):
        """Search Google for blog posts using Custom Search API"""
        try:
            # Google Custom Search API configuration
            # You'll need to set these in your Django settings
            api_key = getattr(settings, 'GOOGLE_CUSTOM_SEARCH_API_KEY', 'a2e3976c052734bb6')
            search_engine_id = getattr(settings, 'GOOGLE_CUSTOM_SEARCH_ENGINE_ID', 'AIzaSyA1CElXL4vN8KxaPgEw0NGqWJGzuWZecm4')
            
            if not api_key or not search_engine_id:
                print(" Google Custom Search API credentials not configured")
                return []
            
            # Search for blogs specifically
            url = f"https://www.googleapis.com/customsearch/v1"
            params = {
                'key': api_key,
                'cx': search_engine_id,
                'q': f'{query} site:blogspot.com OR site:wordpress.com OR site:medium.com OR site:healthline.com OR site:webmd.com OR site:mayoclinic.org',
                'num': 3,  # Limit results per query
                'safe': 'medium',
                'lr': 'lang_en'
            }
            
            response = requests.get(url, params=params, timeout=8)
            
            if response.status_code == 200:
                data = response.json()
                blogs = []
                
                for item in data.get('items', []):
                    blog = {
                        'title': item.get('title', ''),
                        'url': item.get('link', ''),
                        'excerpt': item.get('snippet', ''),
                        'date': item.get('pagemap', {}).get('metatags', [{}])[0].get('article:published_time', ''),
                        'image_url': None,
                        'source': {
                            'name': self._extract_domain_name(item.get('link', '')),
                            'url': item.get('link', '')
                        }
                    }
                    
                    # Try to get image from pagemap
                    pagemap = item.get('pagemap', {})
                    if 'cse_image' in pagemap and pagemap['cse_image']:
                        blog['image_url'] = pagemap['cse_image'][0].get('src')
                    
                    blogs.append(blog)
                
                return blogs
            else:
                print(f" Google Custom Search API error: {response.status_code}")
                return []
                
        except Exception as e:
            print(f" Error searching Google blogs: {str(e)}")
            return []

    def _extract_domain_name(self, url):
        """Extract domain name from URL"""
        try:
            from urllib.parse import urlparse
            parsed = urlparse(url)
            domain = parsed.netloc
            # Remove www. prefix
            if domain.startswith('www.'):
                domain = domain[4:]
            return domain
        except:
            return 'Unknown'

    def _filter_blogs_by_user_preferences(self, blogs, user_preferences):
        """Filter blogs based on user preferences for relevance"""
        if not user_preferences or not any(user_preferences.values()):
            return blogs
        
        filtered_blogs = []
        
        for blog in blogs:
            relevance_score = 0
            content = f"{blog.get('title', '')} {blog.get('excerpt', '')}".lower()
            
            # Check for medical conditions
            for condition in user_preferences.get('medical_conditions', []):
                if condition.lower() in content:
                    relevance_score += 3
            
            # Check for allergens
            for allergen in user_preferences.get('allergens', []):
                if allergen.lower() in content:
                    relevance_score += 2
            
            # Check for dietary preferences
            for dietary in user_preferences.get('dietary_preferences', []):
                if dietary.lower() in content:
                    relevance_score += 2
            
            # Check for health goals
            for goal in user_preferences.get('health_goals', []):
                if goal.lower() in content:
                    relevance_score += 1
            
            # Only include blogs with some relevance to user preferences
            if relevance_score > 0:
                blog['relevance_score'] = relevance_score
                filtered_blogs.append(blog)
        
        # Sort by relevance score
        filtered_blogs.sort(key=lambda x: x.get('relevance_score', 0), reverse=True)
        
        # If no personalized blogs found, return original blogs
        return filtered_blogs if filtered_blogs else blogs

    def _get_personalized_videos_fast(self, ingredient, user=None):
        """Get personalized videos based on ingredient and user preferences"""
        try:
            print(f" Starting video search for ingredient: {ingredient}")
            
            # Get user preferences for personalized video search
            user_preferences = self._get_user_preferences(user) if user else {}
            print(f" User preferences: {user_preferences}")
            
            # Build personalized search queries for videos
            video_queries = self._build_personalized_video_queries(ingredient, user_preferences)
            print(f" Video queries: {video_queries}")
            
            all_videos = []
            
            for query in video_queries:
                try:
                    print(f" Searching for query: {query}")
                    # Search for videos from multiple sources
                    videos = self._search_videos_from_sources(query)
                    print(f" Found {len(videos)} videos for query: {query}")
                    all_videos.extend(videos)
                except Exception as e:
                    print(f" Error searching videos for query '{query}': {str(e)}")
                    continue
            
            print(f" Total videos found: {len(all_videos)}")
            
            # Remove duplicates and filter based on user preferences
            unique_videos = self._remove_duplicate_videos(all_videos)
            print(f" After removing duplicates: {len(unique_videos)}")
            
            filtered_videos = self._filter_videos_by_user_preferences(unique_videos, user_preferences)
            print(f" After filtering by preferences: {len(filtered_videos)}")
            
            # Rank videos by source authority and relevance
            ranked_videos = self._rank_videos_by_authority(filtered_videos)
            print(f" Final ranked videos: {len(ranked_videos)}")
            
            return ranked_videos[:5]  # Return top 5 videos
            
        except Exception as e:
            print(f" Video fetching error: {str(e)}")
            import traceback
            traceback.print_exc()
            return []

    def _build_personalized_video_queries(self, ingredient, user_preferences):
        """Build personalized video search queries based on user preferences"""
        base_queries = [
            f'"{ingredient}" nutrition health benefits video',
            f'"{ingredient}" cooking recipe healthy video',
            f'"{ingredient}" dietary information video'
        ]
        
        personalized_queries = base_queries.copy()
        
        # Add medical condition specific queries
        for condition in user_preferences.get('medical_conditions', []):
            personalized_queries.append(f'"{ingredient}" {condition} health management video')
            personalized_queries.append(f'"{ingredient}" {condition} diet recommendations video')
        
        # Add allergen specific queries
        for allergen in user_preferences.get('allergens', []):
            personalized_queries.append(f'"{ingredient}" {allergen} allergy safety video')
            personalized_queries.append(f'"{ingredient}" {allergen} free alternatives video')
        
        # Add dietary preference specific queries
        for dietary in user_preferences.get('dietary_preferences', []):
            personalized_queries.append(f'"{ingredient}" {dietary} diet video')
            personalized_queries.append(f'"{ingredient}" {dietary} friendly recipes video')
        
        return personalized_queries[:8]  # Limit to 8 queries

    def _search_videos_from_sources(self, query):
        """Search for videos from multiple authoritative sources"""
        videos = []
        
        # Search YouTube for videos from reputable channels
        youtube_videos = self._search_youtube_videos(query)
        videos.extend(youtube_videos)
        
        # Search NIH VideoCasting
        nih_videos = self._search_nih_videos(query)
        videos.extend(nih_videos)
        
        # Search CDC videos
        cdc_videos = self._search_cdc_videos(query)
        videos.extend(cdc_videos)
        
        return videos

    def _search_youtube_videos(self, query):
        """Search YouTube for videos from reputable health channels"""
        try:
            # YouTube Data API configuration
            api_key = getattr(settings, 'YOUTUBE_API_KEY', 'AIzaSyA1CElXL4vN8KxaPgEw0NGqWJGzuWZecm4')
            
            if not api_key:
                print(" YouTube API key not configured")
                return []
            
            print(f" Searching YouTube for: {query}")
            
            # Search for videos from reputable health channels
            url = "https://www.googleapis.com/youtube/v3/search"
            params = {
                'part': 'snippet',
                'q': f'{query} health nutrition medical',
                'type': 'video',
                'maxResults': 10,  # Increased to get more results for filtering
                'key': api_key,
                'order': 'relevance',
                'videoDuration': 'medium',  # 4-20 minutes
                'videoDefinition': 'high'
            }
            
            print(f" Making YouTube API request with params: {params}")
            response = requests.get(url, params=params, timeout=8)
            
            print(f" YouTube API response status: {response.status_code}")
            
            if response.status_code == 200:
                data = response.json()
                print(f" YouTube API returned {len(data.get('items', []))} items")
                
                videos = []
                all_channels = set()
                
                for item in data.get('items', []):
                    channel_title = item['snippet'].get('channelTitle', '').lower()
                    all_channels.add(channel_title)
                    
                    print(f" Found video from channel: {channel_title}")
                    
                    # Filter for reputable health channels
                    if self._is_reputable_health_channel(channel_title):
                        print(f" Channel {channel_title} is reputable")
                        video = {
                            'title': item['snippet'].get('title', ''),
                            'description': item['snippet'].get('description', ''),
                            'video_id': item['id'].get('videoId', ''),
                            'thumbnail': item['snippet'].get('thumbnails', {}).get('high', {}).get('url', ''),
                            'channel_title': item['snippet'].get('channelTitle', ''),
                            'published_at': item['snippet'].get('publishedAt', ''),
                            'source': 'YouTube',
                            'source_authority': self._get_channel_authority(channel_title),
                            'embed_url': f"https://www.youtube.com/embed/{item['id'].get('videoId', '')}",
                            'watch_url': f"https://www.youtube.com/watch?v={item['id'].get('videoId', '')}"
                        }
                        videos.append(video)
                    else:
                        print(f" Channel {channel_title} not in reputable list")
                
                print(f" All channels found: {list(all_channels)}")
                print(f" Returning {len(videos)} reputable videos")
                
                # If no reputable videos found, include some general health videos with lower authority
                if len(videos) == 0:
                    print(" No reputable videos found, including general health videos")
                    for item in data.get('items', [])[:3]:  # Take first 3 videos
                        channel_title = item['snippet'].get('channelTitle', '').lower()
                        video = {
                            'title': item['snippet'].get('title', ''),
                            'description': item['snippet'].get('description', ''),
                            'video_id': item['id'].get('videoId', ''),
                            'thumbnail': item['snippet'].get('thumbnails', {}).get('high', {}).get('url', ''),
                            'channel_title': item['snippet'].get('channelTitle', ''),
                            'published_at': item['snippet'].get('publishedAt', ''),
                            'source': 'YouTube',
                            'source_authority': 3,  # Lower authority for general videos
                            'embed_url': f"https://www.youtube.com/embed/{item['id'].get('videoId', '')}",
                            'watch_url': f"https://www.youtube.com/watch?v={item['id'].get('videoId', '')}"
                        }
                        videos.append(video)
                
                return videos
            else:
                print(f" YouTube API error: {response.status_code}")
                print(f" Response content: {response.text}")
                return []
                
        except Exception as e:
            print(f" Error searching YouTube videos: {str(e)}")
            return []

    def _is_reputable_health_channel(self, channel_title):
        """Check if channel is from a reputable health source"""
        reputable_channels = [
            'nih', 'cdc', 'mayo clinic', 'cleveland clinic', 'johns hopkins',
            'harvard health', 'stanford health', 'webmd', 'healthline',
            'medical news today', 'medlineplus', 'fda', 'who', 'myplate',
            'academy of nutrition', 'american heart association', 'american diabetes',
            'jama', 'new england journal', 'bmj', 'lancet'
        ]
        
        return any(reputable in channel_title for reputable in reputable_channels)

    def _get_channel_authority(self, channel_title):
        """Get authority score for channel"""
        authority_scores = {
            'nih': 10, 'cdc': 10, 'fda': 10, 'who': 10,
            'mayo clinic': 9, 'cleveland clinic': 9, 'johns hopkins': 9,
            'harvard health': 8, 'stanford health': 8,
            'jama': 9, 'new england journal': 9, 'bmj': 9, 'lancet': 9,
            'webmd': 7, 'healthline': 7, 'medical news today': 7,
            'medlineplus': 8, 'myplate': 7
        }
        
        for source, score in authority_scores.items():
            if source in channel_title.lower():
                return score
        
        return 5  # Default score for other channels

    def _search_nih_videos(self, query):
        """Search NIH VideoCasting for medical videos"""
        try:
            # NIH VideoCasting API (if available) or web scraping
            # For now, return empty list - would need NIH API access
            return []
        except Exception as e:
            print(f" Error searching NIH videos: {str(e)}")
            return []

    def _search_cdc_videos(self, query):
        """Search CDC for public health videos"""
        try:
            # CDC API or web scraping
            # For now, return empty list - would need CDC API access
            return []
        except Exception as e:
            print(f" Error searching CDC videos: {str(e)}")
            return []

    def _remove_duplicate_videos(self, videos):
        """Remove duplicate videos based on video_id"""
        seen_ids = set()
        unique_videos = []
        
        for video in videos:
            video_id = video.get('video_id', '')
            if video_id and video_id not in seen_ids:
                seen_ids.add(video_id)
                unique_videos.append(video)
        
        return unique_videos

    def _filter_videos_by_user_preferences(self, videos, user_preferences):
        """Filter videos based on user preferences for relevance"""
        if not user_preferences or not any(user_preferences.values()):
            return videos
        
        filtered_videos = []
        
        for video in videos:
            relevance_score = 0
            content = f"{video.get('title', '')} {video.get('description', '')}".lower()
            
            # Check for medical conditions
            for condition in user_preferences.get('medical_conditions', []):
                if condition.lower() in content:
                    relevance_score += 3
            
            # Check for allergens
            for allergen in user_preferences.get('allergens', []):
                if allergen.lower() in content:
                    relevance_score += 2
            
            # Check for dietary preferences
            for dietary in user_preferences.get('dietary_preferences', []):
                if dietary.lower() in content:
                    relevance_score += 2
            
            # Check for health goals
            for goal in user_preferences.get('health_goals', []):
                if goal.lower() in content:
                    relevance_score += 1
            
            # Only include videos with some relevance to user preferences
            if relevance_score > 0:
                video['relevance_score'] = relevance_score
                filtered_videos.append(video)
        
        # Sort by relevance score
        filtered_videos.sort(key=lambda x: x.get('relevance_score', 0), reverse=True)
        
        # If no personalized videos found, return original videos
        return filtered_videos if filtered_videos else videos

    def _rank_videos_by_authority(self, videos):
        """Rank videos by source authority and relevance"""
        for video in videos:
            authority_score = video.get('source_authority', 5)
            relevance_score = video.get('relevance_score', 0)
            
            # Combined score: authority (70%) + relevance (30%)
            combined_score = (authority_score * 0.7) + (relevance_score * 0.3)
            video['combined_score'] = combined_score
        
        # Sort by combined score
        videos.sort(key=lambda x: x.get('combined_score', 0), reverse=True)
        
        return videos

    def _is_food_related_article(self, article, ingredient):
        """Check if article is actually about food/nutrition"""
        try:
            title = article.get('title', '').lower()
            description = article.get('description', '').lower()
            content = f"{title} {description}"
            
            # Food-related keywords
            food_keywords = [
                'food', 'nutrition', 'health', 'recipe', 'cooking', 'diet', 'dietary',
                'vitamin', 'mineral', 'protein', 'fiber', 'calorie', 'allergy', 'allergen',
                'benefits', 'risks', 'preparation', 'culinary', 'ingredient', 'meal',
                'snack', 'breakfast', 'lunch', 'dinner', 'organic', 'natural'
            ]
            
            # Non-food keywords to exclude
            non_food_keywords = [
                'costs peanuts', 'for peanuts', 'cheap', 'price', 'deal', 'sale',
                'discount', 'offer', 'bargain', 'tech', 'gaming', 'computer',
                'software', 'hardware', 'phone', 'laptop', 'monitor', 'speaker',
                'ssd', 'hard drive', 'storage', 'amazon', 'ebay', 'shopping'
            ]
            
            # Check if it contains food keywords
            has_food_keywords = any(keyword in content for keyword in food_keywords)
            
            # Check if it contains non-food keywords
            has_non_food_keywords = any(keyword in content for keyword in non_food_keywords)
            
            # Return True if it has food keywords and doesn't have non-food keywords
            return has_food_keywords and not has_non_food_keywords
            
        except Exception as e:
            return False

    def _remove_duplicate_blogs(self, blogs):
        """Remove duplicate blogs based on URL"""
        seen_urls = set()
        unique_blogs = []
        
        for blog in blogs:
            if blog.get('url') and blog['url'] not in seen_urls:
                seen_urls.add(blog['url'])
                unique_blogs.append(blog)
        
        return unique_blogs


    def _get_open_food_facts_data_fast(self, query):
        """Fast OpenFDA data fetch"""
        try:
            url = f"https://api.fda.gov/food/enforcement.json?search=product_description:{query}&limit=1"
            response = requests.get(url, timeout=6)
            return response.json() if response.status_code == 200 else {}
        except Exception as e:
            return {}

    def _build_response_data(self, ingredient, results, user):
        """Build the final response data with the new structured format"""
        # Determine summary from actual API data
        medline_result = results.get('medline')
        pubchem_summary = results.get('pubchem')
        
        if isinstance(medline_result, str):
            summary = medline_result
            summary_source = "MedlinePlus"
        elif isinstance(medline_result, dict) and (medline_result.get("title") or medline_result.get("url")):
            summary = f"See MedlinePlus topic: {medline_result.get('title', '')} ({medline_result.get('url', '')})"
            summary_source = "MedlinePlus (link only)"
        elif pubchem_summary:
            summary = pubchem_summary
            summary_source = "PubChem (TOXNET)"
        else:
            # Fallback summary
            summary = f"{ingredient} is a common food ingredient. For specific health information, consult healthcare providers or food safety databases."
            summary_source = "General knowledge"

        # Combine regulatory data from multiple sources
        regulatory_data = self._combine_regulatory_data(results)
        
        # Determine Go/No-Go badge and snapshot text
        badge_info = self._determine_badge_and_snapshot(ingredient, regulatory_data, results, user)
        
        # Build regulatory compliance feedback
        compliance_feedback = self._build_compliance_feedback(regulatory_data, ingredient)
        
        # Build risk analysis
        risk_analysis = self._build_risk_analysis(ingredient, results, regulatory_data, user)
        
        # Build nutritional information
        nutritional_info = self._build_nutritional_info(results)
        
        # Build recall information
        recall_info = self._build_recall_info(ingredient, results)
        
        # Build related blogs and videos separately
        related_blogs = self._build_related_blogs(results)
        related_videos = self._build_related_videos(results)
        
        return {
            # Header Section
            'header': {
                'ingredient_name': ingredient.capitalize(),
                'alternative_names': regulatory_data.get('additional_info', {}).get('alternative_names', []),
                'go_no_go_badge': badge_info['badge'],
                'snapshot_text': badge_info['snapshot'],
                'reasoning': badge_info.get('reasoning', ''),
                'specific_concerns': badge_info.get('specific_concerns', []),
                'recommendations': badge_info.get('recommendations', [])
            },
            
            # 1. Overview Section
            'overview': {
                'description': summary,
                'expand_link': f"ingredient-deep-dive/{ingredient.lower().replace(' ', '-')}",
                'citations': [
                    {
                        'source': summary_source,
                        'url': medline_result.get('url') if isinstance(medline_result, dict) else None
                    }
                ]
            },
            
            # 2. Regulatory Compliance Feedback (Quick Flags)
            'regulatory_compliance_feedback': compliance_feedback,
            
            # 3. Regulatory Compliance (Deep Dive)
            'regulatory_compliance_deep_dive': self._build_regulatory_deep_dive(ingredient),
            
            # 4. AI-Powered Risk Analysis & Safety
            'risk_analysis': risk_analysis,
            
            # 5. Nutritional Information (USDA)
            'nutritional_information': nutritional_info,
            
            # 6. Recall Information
            'recall_information': recall_info,
            
            # 7. Related Blogs
            'related_blogs': related_blogs,
            
            # 8. Related Videos
            'related_videos': related_videos,
            
            # Legacy fields for backward compatibility
            'ingredient': ingredient.capitalize(),
            'summary': summary,
            'summary_source': summary_source,
            'pubchem_summary': pubchem_summary,
            'image_url': results.get('image'),
            'regulatory_feedback': regulatory_data.get('regulatory_feedback', {
                'GRAS': [],
                'Restricted': {},
                'Non_Compliant': "None"
            }),
            'market_warnings': {
                'US': "Safe but limited in dietary guidelines.",
                'EU': "Allowed; subject to labeling rules.",
                'Mexico': "High-sugar warning required.",
                'India': "Max limits in processed foods."
            },
            'regulatory_sources': ["FDA", "EFSA", "WHO", "Health Canada", "FSANZ", "Codex"],
            'detailed_regulatory': {
                'Safe': regulatory_data.get('regulatory_feedback', {}).get('GRAS', []),
                'Approved_In': regulatory_data.get('regulatory_feedback', {}).get('GRAS', []),
                'Restrictions': regulatory_data.get('Restrictions', {}),
                'Violations': regulatory_data.get('Violations', "None"),
                'Why_Restricted': regulatory_data.get('Why_Restricted', "None"),
                'Alternatives': regulatory_data.get('Alternatives', "None"),
                'Non_Compliant': regulatory_data.get('regulatory_feedback', {}).get('Non_Compliant', "None")
            },
            'additional_info': regulatory_data.get('additional_info', {}),
            'usda_data': results.get('edamam', []),
            'open_food_facts': results.get('off', {}),
            'related_blogs': results.get('blogs', [])
        }

    def _combine_regulatory_data(self, results):
        """Combine regulatory data from multiple sources with comprehensive fallbacks"""
        combined_data = {
            'regulatory_feedback': {
                'GRAS': [],
                'Restricted': {},
                'Non_Compliant': "None"
            },
            'Restrictions': {},
            'Violations': "None",
            'Why_Restricted': "None",
            'Alternatives': "None",
            'additional_info': {
                'alternative_names': [],
                'risk_safety_insight': "No regulatory data available",
                'dishes': [],
                'history': "No regulatory history available"
            }
        }
        
        # Process FDA data
        fda_data = results.get('fda')
        if fda_data and isinstance(fda_data, dict):
            fda_reg = fda_data.get('regulatory_feedback', {})
            combined_data['regulatory_feedback']['GRAS'].extend(fda_reg.get('GRAS', []))
            combined_data['regulatory_feedback']['Restricted'].update(fda_reg.get('Restricted', {}))
            if fda_reg.get('Non_Compliant') != "None":
                combined_data['regulatory_feedback']['Non_Compliant'] = fda_reg.get('Non_Compliant')
            
            combined_data['Restrictions'].update(fda_data.get('Restrictions', {}))
            if fda_data.get('Violations') != "None":
                combined_data['Violations'] = fda_data.get('Violations')
            if fda_data.get('Why_Restricted') != "None":
                combined_data['Why_Restricted'] = fda_data.get('Why_Restricted')
            if fda_data.get('Alternatives') != "None":
                combined_data['Alternatives'] = fda_data.get('Alternatives')
            
            fda_info = fda_data.get('additional_info', {})
            combined_data['additional_info']['alternative_names'].extend(fda_info.get('alternative_names', []))
            if fda_info.get('risk_safety_insight') != "No regulatory data available":
                combined_data['additional_info']['risk_safety_insight'] = fda_info.get('risk_safety_insight')
            combined_data['additional_info']['dishes'].extend(fda_info.get('dishes', []))
            if fda_info.get('history') != "No regulatory history available":
                combined_data['additional_info']['history'] = fda_info.get('history')
        
        # Process EFSA data
        efsa_data = results.get('efsa')
        if efsa_data and isinstance(efsa_data, dict):
            efsa_reg = efsa_data.get('regulatory_feedback', {})
            combined_data['regulatory_feedback']['GRAS'].extend(efsa_reg.get('GRAS', []))
            combined_data['regulatory_feedback']['Restricted'].update(efsa_reg.get('Restricted', {}))
            if efsa_reg.get('Non_Compliant') != "None":
                combined_data['regulatory_feedback']['Non_Compliant'] = efsa_reg.get('Non_Compliant')
            
            combined_data['Restrictions'].update(efsa_data.get('Restrictions', {}))
            if efsa_data.get('Violations') != "None":
                combined_data['Violations'] = efsa_data.get('Violations')
            if efsa_data.get('Why_Restricted') != "None":
                combined_data['Why_Restricted'] = efsa_data.get('Why_Restricted')
            if efsa_data.get('Alternatives') != "None":
                combined_data['Alternatives'] = efsa_data.get('Alternatives')
            
            efsa_info = efsa_data.get('additional_info', {})
            combined_data['additional_info']['alternative_names'].extend(efsa_info.get('alternative_names', []))
            if efsa_info.get('risk_safety_insight') != "No regulatory data available":
                combined_data['additional_info']['risk_safety_insight'] = efsa_info.get('risk_safety_insight')
            combined_data['additional_info']['dishes'].extend(efsa_info.get('dishes', []))
            if efsa_info.get('history') != "No regulatory history available":
                combined_data['additional_info']['history'] = efsa_info.get('history')
        
        # Process WHO data
        who_data = results.get('who')
        if who_data and isinstance(who_data, dict):
            who_reg = who_data.get('regulatory_feedback', {})
            combined_data['regulatory_feedback']['GRAS'].extend(who_reg.get('GRAS', []))
            combined_data['regulatory_feedback']['Restricted'].update(who_reg.get('Restricted', {}))
            if who_reg.get('Non_Compliant') != "None":
                combined_data['regulatory_feedback']['Non_Compliant'] = who_reg.get('Non_Compliant')
            
            combined_data['Restrictions'].update(who_data.get('Restrictions', {}))
            if who_data.get('Violations') != "None":
                combined_data['Violations'] = who_data.get('Violations')
            if who_data.get('Why_Restricted') != "None":
                combined_data['Why_Restricted'] = who_data.get('Why_Restricted')
            if who_data.get('Alternatives') != "None":
                combined_data['Alternatives'] = who_data.get('Alternatives')
            
            who_info = who_data.get('additional_info', {})
            combined_data['additional_info']['alternative_names'].extend(who_info.get('alternative_names', []))
            if who_info.get('risk_safety_insight') != "No regulatory data available":
                combined_data['additional_info']['risk_safety_insight'] = who_info.get('risk_safety_insight')
            combined_data['additional_info']['dishes'].extend(who_info.get('dishes', []))
            if who_info.get('history') != "No regulatory history available":
                combined_data['additional_info']['history'] = who_info.get('history')
        
        # Remove duplicates from lists
        combined_data['regulatory_feedback']['GRAS'] = list(set(combined_data['regulatory_feedback']['GRAS']))
        combined_data['additional_info']['alternative_names'] = list(set(combined_data['additional_info']['alternative_names']))
        combined_data['additional_info']['dishes'] = list(set(combined_data['additional_info']['dishes']))
        
        return combined_data

    def _determine_badge_and_snapshot(self, ingredient, regulatory_data, results, user):
        """Determine Go/No-Go badge and personalized snapshot text using OpenAI analysis"""
        try:
            # Get user profile information
            user_profile = {
                'allergies': user.Allergies or '',
                'medical_conditions': user.Health_conditions or '',
                'dietary_preferences': user.Dietary_preferences or '',
                'health_goals': user.Health_Goals or ''
            }
            
            # Prepare regulatory information for analysis
            regulatory_info = {
                'violations': regulatory_data.get('Violations', "None"),
                'restrictions': regulatory_data.get('Restrictions', {}),
                'gras_status': regulatory_data.get('regulatory_feedback', {}).get('GRAS', [])
            }
            
            # Create OpenAI prompt for safety analysis
            prompt = f"""
            Analyze the safety of the ingredient "{ingredient}" for a user with the following profile:
            
            User Profile:
            - Allergies: {user_profile['allergies']}
            - Medical Conditions: {user_profile['medical_conditions']}
            - Dietary Preferences: {user_profile['dietary_preferences']}
            - Health Goals: {user_profile['health_goals']}
            
            Regulatory Information:
            - Violations: {regulatory_info['violations']}
            - Restrictions: {regulatory_info['restrictions']}
            - GRAS Status: {regulatory_info['gras_status']}
            
            Please provide a safety assessment in the following JSON format:
            {{
                "safety_level": "safe|caution|unsafe",
                "badge_color": "green|yellow|red",
                "badge_text": "Go|Caution|No-Go",
                "badge_icon": "||",
                "snapshot_text": "Personalized safety message explaining the decision",
                "reasoning": "Brief explanation of why this safety level was assigned",
                "specific_concerns": ["List of specific concerns for this user"],
                "recommendations": ["List of recommendations for this user"]
            }}
            
            Consider:
            1. Allergic reactions based on user's known allergies
            2. Medical condition interactions (diabetes, hypertension, etc.)
            3. Dietary preference conflicts (vegan, keto, etc.)
            4. Regulatory violations or restrictions
            5. General safety profile of the ingredient
            
            Be specific and personalized to the user's profile. If the user has no allergies or medical conditions listed, consider it generally safe unless there are regulatory concerns.
            """
            
            # Call OpenAI API
            from django.conf import settings
            client = openai.OpenAI(api_key=getattr(settings, 'OPENAI_API_KEY', 'OPENAI_API_KEY_REMOVED'))
            
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "You are a food safety expert who analyzes ingredients for personalized safety recommendations. Always respond with valid JSON."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=500,
                temperature=0.3
            )
            
            # Parse OpenAI response
            analysis_text = response.choices[0].message.content.strip()
            
            # Try to extract JSON from response
            import json
            try:
                # Remove any markdown formatting if present
                if analysis_text.startswith('```json'):
                    analysis_text = analysis_text[7:-3]
                elif analysis_text.startswith('```'):
                    analysis_text = analysis_text[3:-3]
                
                analysis = json.loads(analysis_text)
                
                badge = {
                    'color': analysis.get('badge_color', 'green'),
                    'text': analysis.get('badge_text', 'Go'),
                    'icon': analysis.get('badge_icon', '')
                }
                
                snapshot = analysis.get('snapshot_text', f"Safe for your profile - {ingredient} is generally recognized as safe")
                
                return {
                    'badge': badge, 
                    'snapshot': snapshot,
                    'reasoning': analysis.get('reasoning', ''),
                    'specific_concerns': analysis.get('specific_concerns', []),
                    'recommendations': analysis.get('recommendations', [])
                }
                
            except json.JSONDecodeError:
                # Fallback if JSON parsing fails
                return self._fallback_badge_analysis(ingredient, user_profile, regulatory_data)
                
        except Exception as e:
            print(f" OpenAI analysis error: {str(e)}")
            # Fallback to static analysis
            return self._fallback_badge_analysis(ingredient, user_profile, regulatory_data)
    
    def _fallback_badge_analysis(self, ingredient, user_profile, regulatory_data):
        """Fallback badge analysis when OpenAI is unavailable"""
        ingredient_lower = ingredient.lower()
        
        # Check for violations or restrictions
        has_violations = regulatory_data.get('Violations', "None") != "None"
        has_restrictions = bool(regulatory_data.get('Restrictions', {}))
        
        # Basic allergen check (fallback)
        user_allergies = user_profile.get('allergies', '').lower()
        if user_allergies and any(allergen in ingredient_lower for allergen in user_allergies.split(',')):
            badge = {'color': 'red', 'text': 'No-Go', 'icon': ''}
            snapshot = f"Caution: {ingredient} may contain allergens you're sensitive to"
        elif has_violations or has_restrictions:
            badge = {'color': 'yellow', 'text': 'Caution', 'icon': ''}
            snapshot = f"Caution: {ingredient} has regulatory restrictions"
        else:
            badge = {'color': 'green', 'text': 'Go', 'icon': ''}
            snapshot = f"Safe for your profile - {ingredient} is generally recognized as safe"
        
        return {
            'badge': badge, 
            'snapshot': snapshot,
            'reasoning': 'Fallback analysis used',
            'specific_concerns': [],
            'recommendations': []
        }

    def _build_compliance_feedback(self, regulatory_data, ingredient):
        """Build regulatory compliance feedback with real-time data from free APIs"""
        chips = []
        
        # Get real-time FDA data
        fda_data = self._get_real_fda_data(ingredient)
        chips.append({
            'label': 'FDA Status',
            'color': 'green' if fda_data['status'] == 'approved' else 'red' if fda_data['status'] == 'violation' else 'gray',
            'tooltip': fda_data['description']
        })
        
        # Get real-time USDA data
        usda_data = self._get_real_usda_data(ingredient)
        chips.append({
            'label': 'USDA Status',
            'color': 'green' if usda_data['status'] == 'found' else 'gray',
            'tooltip': usda_data['description']
        })
        
        # Get real-time Open Food Facts data
        off_data = self._get_real_off_data(ingredient)
        chips.append({
            'label': 'Global Status',
            'color': 'green' if off_data['status'] == 'found' else 'gray',
            'tooltip': off_data['description']
        })
        
        return {
            'chips': chips,
            'tooltip_text': 'Tap badge for detail',
            'last_updated': self._get_current_timestamp()
        }

    def _format_regulatory_detail(self, agency, gras_list):
        """Format regulatory detail for specific agency"""
        if any(agency in approval for approval in gras_list):
            return {
                'status': 'approved',
                'description': f'Approved by {agency}',
                'details': f'Generally recognized as safe by {agency}'
            }
        else:
            return {
                'status': 'not_evaluated',
                'description': f'Not specifically evaluated by {agency}',
                'details': f'No specific {agency} evaluation found'
            }

    def _build_regulatory_citations(self, regulatory_data):
        """Build citations list for regulatory information"""
        citations = []
        
        gras_list = regulatory_data.get('regulatory_feedback', {}).get('GRAS', [])
        for approval in gras_list:
            citations.append({
                'source': approval,
                'url': f'https://www.fda.gov/food/food-additives-petitions/food-additive-status-list' if 'FDA' in approval else None
            })
        
        return citations

    def _build_risk_analysis(self, ingredient, results, regulatory_data, user):
        """Build AI-powered risk analysis and safety information personalized to user profile"""
        try:
            # Get user profile information
            user_profile = {
                'allergies': user.Allergies or '',
                'medical_conditions': user.Health_conditions or '',
                'dietary_preferences': user.Dietary_preferences or '',
                'health_goals': user.Health_Goals or ''
            }
            
            # Create OpenAI prompt for personalized risk analysis
            prompt = f"""
            Analyze the health risks of the ingredient "{ingredient}" for a user with the following profile:
            
            User Profile:
            - Allergies: {user_profile['allergies']}
            - Medical Conditions: {user_profile['medical_conditions']}
            - Dietary Preferences: {user_profile['dietary_preferences']}
            - Health Goals: {user_profile['health_goals']}
            
            Regulatory Information:
            - Violations: {regulatory_data.get('Violations', "None")}
            - Restrictions: {regulatory_data.get('Restrictions', {})}
            
            Please provide a risk analysis in the following JSON format:
            {{
                "risk_level": "low|moderate|high",
                "risk_percentage": 25|60|90,
                "risk_color": "green|yellow|red",
                "personalized_overlay": "Specific risk message for this user",
                "risk_factors": ["List of specific risk factors for this user"],
                "medical_concerns": ["Medical condition interactions"],
                "dietary_conflicts": ["Dietary preference conflicts"],
                "recommendations": ["Personalized recommendations"]
            }}
            
            Consider:
            1. Allergic reactions based on user's known allergies
            2. Medical condition interactions (diabetes, hypertension, heart disease, etc.)
            3. Dietary preference conflicts (vegan, keto, low-sodium, etc.)
            4. Health goal alignment (weight loss, muscle gain, etc.)
            5. Regulatory violations or restrictions
            
            Be specific and personalized. If no specific risks are identified for this user, mark as low risk.
            """
            
            # Call OpenAI API
            from django.conf import settings
            client = openai.OpenAI(api_key=getattr(settings, 'OPENAI_API_KEY', 'OPENAI_API_KEY_REMOVED'))
            
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "You are a medical nutritionist who analyzes ingredient risks for personalized health recommendations. Always respond with valid JSON."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=400,
                temperature=0.3
            )
            
            # Parse OpenAI response
            analysis_text = response.choices[0].message.content.strip()
            
            # Try to extract JSON from response
            import json
            try:
                # Remove any markdown formatting if present
                if analysis_text.startswith('```json'):
                    analysis_text = analysis_text[7:-3]
                elif analysis_text.startswith('```'):
                    analysis_text = analysis_text[3:-3]
                
                analysis = json.loads(analysis_text)
                
                # Build risk level bar
                risk_bar = {
                    'level': analysis.get('risk_level', 'low'),
                    'percentage': analysis.get('risk_percentage', 25),
                    'color': analysis.get('risk_color', 'green')
                }
                
                # Get general risks from PubChem or other sources
                general_risks = []
                pubchem_summary = results.get('pubchem')
                if pubchem_summary:
                    general_risks.append({
                        'source': 'PubChem Toxicology',
                        'description': pubchem_summary[:200] + '...' if len(pubchem_summary) > 200 else pubchem_summary
                    })
                
                return {
                    'risk_level_bar': risk_bar,
                    'personalized_overlay': analysis.get('personalized_overlay', 'No specific risks identified for your profile'),
                    'risk_factors': analysis.get('risk_factors', []),
                    'medical_concerns': analysis.get('medical_concerns', []),
                    'dietary_conflicts': analysis.get('dietary_conflicts', []),
                    'recommendations': analysis.get('recommendations', []),
                    'general_risks': general_risks,
                    'clinical_trials_button': {
                        'text': 'See Related Clinical Trials ',
                        'url': f'https://clinicaltrials.gov/search?term={ingredient}'
                    },
                    'citations': [
                        {'source': 'PubMed', 'url': f'https://pubmed.ncbi.nlm.nih.gov/?term={ingredient}'},
                        {'source': 'ClinicalTrials.gov', 'url': f'https://clinicaltrials.gov/search?term={ingredient}'}
                    ]
                }
                
            except json.JSONDecodeError:
                # Fallback if JSON parsing fails
                return self._fallback_risk_analysis(ingredient, user_profile, regulatory_data, results)
                
        except Exception as e:
            print(f" OpenAI risk analysis error: {str(e)}")
            # Fallback to static analysis
            return self._fallback_risk_analysis(ingredient, user_profile, regulatory_data, results)
    
    def _fallback_risk_analysis(self, ingredient, user_profile, regulatory_data, results):
        """Fallback risk analysis when OpenAI is unavailable"""
        ingredient_lower = ingredient.lower()
        
        # Determine risk level
        risk_level = 'low'
        risk_factors = []
        
        # Check user's medical conditions
        medical_conditions = user_profile.get('medical_conditions', '').lower()
        if 'diabetes' in medical_conditions and 'sugar' in ingredient_lower:
            risk_level = 'moderate'
            risk_factors.append('High sugar content may affect blood glucose levels')
        
        if 'hypertension' in medical_conditions and ('sodium' in ingredient_lower or 'salt' in ingredient_lower):
            risk_level = 'moderate'
            risk_factors.append('High sodium may elevate blood pressure (ICD-10: I10)')
        
        # Check user's allergies
        user_allergies = user_profile.get('allergies', '').lower()
        if user_allergies and any(allergen in ingredient_lower for allergen in user_allergies.split(',')):
            risk_level = 'high'
            risk_factors.append('Contains allergens you are sensitive to')
        
        # Check for violations
        if regulatory_data.get('Violations', "None") != "None":
            risk_level = 'high'
            risk_factors.append('Has regulatory violations or enforcement actions')
        
        # Build risk level bar
        risk_bar = {
            'level': risk_level,
            'percentage': {'low': 25, 'moderate': 60, 'high': 90}[risk_level],
            'color': {'low': 'green', 'moderate': 'yellow', 'high': 'red'}[risk_level]
        }
        
        # Get general risks from PubChem or other sources
        general_risks = []
        pubchem_summary = results.get('pubchem')
        if pubchem_summary:
            general_risks.append({
                'source': 'PubChem Toxicology',
                'description': pubchem_summary[:200] + '...' if len(pubchem_summary) > 200 else pubchem_summary
            })
        
        return {
            'risk_level_bar': risk_bar,
            'personalized_overlay': risk_factors[0] if risk_factors else 'No specific risks identified for your profile',
            'risk_factors': risk_factors,
            'medical_concerns': [],
            'dietary_conflicts': [],
            'recommendations': [],
            'general_risks': general_risks,
            'clinical_trials_button': {
                'text': 'See Related Clinical Trials ',
                'url': f'https://clinicaltrials.gov/search?term={ingredient}'
            },
            'citations': [
                {'source': 'PubMed', 'url': f'https://pubmed.ncbi.nlm.nih.gov/?term={ingredient}'},
                {'source': 'ClinicalTrials.gov', 'url': f'https://clinicaltrials.gov/search?term={ingredient}'}
            ]
        }

    def _build_nutritional_info(self, results):
        """Build nutritional information from USDA data"""
        usda_data = results.get('edamam', [])
        
        if not usda_data:
            return {
                'table': [],
                'usda_link': {
                    'text': 'View USDA FoodData Central ',
                    'url': 'https://fdc.nal.usda.gov/'
                }
            }
        
        # Extract nutritional data from first USDA result
        first_item = usda_data[0] if usda_data else {}
        nutrients = first_item.get('nutrients', [])
        
        nutritional_table = []
        for nutrient in nutrients:
            name = nutrient.get('name', '')
            amount = nutrient.get('amount', 0)
            unit = nutrient.get('unit', '')
            
            # Calculate personalized daily value (simplified)
            daily_value = self._calculate_daily_value(name, amount, unit)
            
            nutritional_table.append({
                'nutrient': name,
                'amount': f"{amount} {unit}",
                'daily_value': daily_value
            })
        
        return {
            'table': nutritional_table,
            'usda_link': {
                'text': 'View USDA FoodData Central ',
                'url': 'https://fdc.nal.usda.gov/'
            }
        }

    def _calculate_daily_value(self, nutrient_name, amount, unit):
        """Calculate personalized daily value percentage"""
        # Simplified daily value calculations
        daily_values = {
            'Sodium': {'amount': 2300, 'unit': 'mg'},
            'Sugar': {'amount': 50, 'unit': 'g'},
            'Protein': {'amount': 50, 'unit': 'g'},
            'Total lipid (fat)': {'amount': 65, 'unit': 'g'},
            'Carbohydrate': {'amount': 300, 'unit': 'g'}
        }
        
        if nutrient_name in daily_values:
            dv_amount = daily_values[nutrient_name]['amount']
            percentage = (amount / dv_amount) * 100
            
            # Add personalized flags
            if nutrient_name == 'Sodium' and percentage > 20:
                return f"{percentage:.0f}% (High for your profile)"
            elif nutrient_name == 'Sugar' and percentage > 40:
                return f"{percentage:.0f}% (Diabetes flag)"
            else:
                return f"{percentage:.0f}%"
        
        return "N/A"

    def _build_recall_info(self, ingredient, results):
        """Build recall information"""
        # Check for active recalls (simplified - in real implementation, this would query FDA recall database)
        has_active_recall = False
        recall_details = None
        
        # Example recall check (in real implementation, this would be more sophisticated)
        if 'salmonella' in ingredient.lower() or 'listeria' in ingredient.lower():
            has_active_recall = True
            recall_details = {
                'alert': 'Recall: FDA flagged this brand for Salmonella in March 2025',
                'link': {
                    'text': 'View FDA Recall Notice ',
                    'url': 'https://www.fda.gov/food/recalls-outbreaks-emergencies/recalls-enforcement-reports'
                }
            }
        
        return {
            'active_recall': has_active_recall,
            'recall_details': recall_details,
            'past_recalls': []  # Would be populated with historical recall data
        }

    def _build_related_blogs(self, results):
        """Build related blogs section"""
        blogs = results.get('blogs', [])
        
        blog_cards = []
        for blog in blogs[:5]:  # Show up to 5 blogs
            # Handle both old and new blog formats
            excerpt = blog.get('excerpt', blog.get('description', ''))
            source_name = blog.get('source', {}).get('name', '') if isinstance(blog.get('source'), dict) else blog.get('source', '')
            published_at = blog.get('date', blog.get('publishedAt', ''))
            
            blog_cards.append({
                'title': blog.get('title', ''),
                'excerpt': excerpt[:200] + '...' if len(excerpt) > 200 else excerpt,
                'source': source_name,
                'url': blog.get('url', ''),
                'published_at': published_at,
                'image_url': blog.get('image_url'),
                'relevance_score': blog.get('relevance_score', 0)
            })
        
        # Add personalized suggestions based on available blogs
        personalized_suggestions = []
        if blogs:
            # Extract topics from blog titles for suggestions
            topics = set()
            for blog in blogs:
                title = blog.get('title', '').lower()
                if 'diabetes' in title or 'diabetic' in title:
                    topics.add('Diabetes Management')
                if 'heart' in title or 'cardiac' in title:
                    topics.add('Heart Health')
                if 'allergy' in title or 'allergen' in title:
                    topics.add('Allergy Management')
                if 'diet' in title or 'nutrition' in title:
                    topics.add('Nutritional Guidance')
                if 'recipe' in title or 'cooking' in title:
                    topics.add('Healthy Cooking')
            
            personalized_suggestions = list(topics)[:3]
        
        # Fallback suggestions if no topics found
        if not personalized_suggestions:
            personalized_suggestions = [
                'Nutritional Information',
                'Health Benefits',
                'Cooking Tips'
            ]
        
        return {
            'blog_cards': blog_cards,
            'personalized_suggestions': personalized_suggestions,
            'total_blogs': len(blogs)
        }

    def _build_related_videos(self, results):
        """Build related videos section"""
        videos = results.get('videos', [])
        
        video_cards = []
        for video in videos[:6]:  # Show up to 6 videos
            video_cards.append({
                'title': video.get('title', ''),
                'description': video.get('description', '')[:200] + '...' if len(video.get('description', '')) > 200 else video.get('description', ''),
                'source': video.get('channel_title', ''),
                'thumbnail': video.get('thumbnail', ''),
                'embed_url': video.get('embed_url', ''),
                'watch_url': video.get('watch_url', ''),
                'published_at': video.get('published_at', ''),
                'source_authority': video.get('source_authority', 5),
                'relevance_score': video.get('relevance_score', 0),
                'combined_score': video.get('combined_score', 0)
            })
        
        # Add personalized suggestions based on available videos
        personalized_suggestions = []
        if videos:
            # Extract topics from video titles for suggestions
            topics = set()
            for video in videos:
                title = video.get('title', '').lower()
                if 'diabetes' in title or 'diabetic' in title:
                    topics.add('Diabetes Management Videos')
                if 'heart' in title or 'cardiac' in title:
                    topics.add('Heart Health Videos')
                if 'allergy' in title or 'allergen' in title:
                    topics.add('Allergy Management Videos')
                if 'diet' in title or 'nutrition' in title:
                    topics.add('Nutritional Guidance Videos')
                if 'recipe' in title or 'cooking' in title:
                    topics.add('Healthy Cooking Videos')
                if 'medical' in title or 'health' in title:
                    topics.add('Medical Education Videos')
            
            personalized_suggestions = list(topics)[:3]
        
        # Fallback suggestions if no topics found
        if not personalized_suggestions:
            personalized_suggestions = [
                'Health Education Videos',
                'Nutritional Guidance',
                'Medical Information'
            ]
        
        return {
            'video_cards': video_cards,
            'personalized_suggestions': personalized_suggestions,
            'total_videos': len(videos)
        }

    def _get_real_fda_data(self, ingredient):
        """Get real-time FDA data using free API"""
        try:
            # FDA GRAS Database (Free API)
            gras_url = f"https://api.fda.gov/food/gras.json?search=substance_name:{ingredient}&limit=5"
            response = requests.get(gras_url, timeout=5)  # Increased timeout for FDA API reliability
            
            if response.status_code == 200:
                data = response.json()
                results = data.get('results', [])
                
                if results:
                    return {
                        "status": "approved",
                        "description": "Generally Recognized as Safe by FDA",
                        "details": f"Found in FDA GRAS database: {results[0].get('substance_name', ingredient)}",
                        "fda_id": results[0].get('id'),
                        "last_updated": results[0].get('last_updated'),
                        "source": "FDA GRAS Database (Free API)"
                    }
            
            # FDA Enforcement Database (Free API)
            enforcement_url = f"https://api.fda.gov/food/enforcement.json?search=product_description:{ingredient}&limit=3"
            enforcement_response = requests.get(enforcement_url, timeout=5)  # Increased timeout for FDA API reliability
            
            if enforcement_response.status_code == 200:
                enforcement_data = enforcement_response.json()
                violations = enforcement_data.get('results', [])
                
                if violations:
                    return {
                        "status": "violation",
                        "description": "FDA enforcement actions found",
                        "details": f"FDA enforcement actions: {len(violations)} cases",
                        "violations": violations,
                        "source": "FDA Enforcement Database (Free API)"
                    }
            
            return {
                "status": "not_evaluated",
                "description": "Not specifically evaluated by FDA",
                "details": "No specific FDA evaluation found",
                "source": "FDA API (Free)"
            }
            
        except Exception as e:
            print(f"FDA API error: {str(e)}")
            return {
                "status": "error", 
                "description": "FDA data unavailable",
                "details": "Unable to fetch FDA data",
                "source": "FDA API (Free)"
            }

    def _get_real_usda_data(self, ingredient):
        """Get real-time USDA data using free API"""
        try:
            # USDA FoodData Central API (Free with API key)
            # You can get a free API key from: https://fdc.nal.usda.gov/api-guide.html
            from django.conf import settings
            usda_api_key = getattr(settings, 'USDA_API_KEY', 'GjEtyGT6fOVQ5Z9iSaEAHkQSxfHEYgbyIF7jdbh8')  # DEMO_KEY has limited requests
            
            usda_url = f"https://api.nal.usda.gov/fdc/v1/foods/search?query={ingredient}&api_key={usda_api_key}&pageSize=3"
            response = requests.get(usda_url, timeout=3)  # Reduced timeout for faster response
            
            if response.status_code == 200:
                data = response.json()
                foods = data.get('foods', [])
                
                if foods:
                    # Extract detailed food information
                    food_items = []
                    for food in foods[:3]:  # Limit to 3 items
                        # Safely handle foodCategory which might be string or dict
                        food_category = food.get('foodCategory', {})
                        if isinstance(food_category, dict):
                            category_description = food_category.get('description', 'N/A')
                        else:
                            category_description = str(food_category) if food_category else 'N/A'
                        
                        food_item = {
                            "fdc_id": food.get('fdcId'),
                            "description": food.get('description', 'N/A'),
                            "brand_owner": food.get('brandOwner', 'N/A'),
                            "ingredients": food.get('ingredients', 'N/A'),
                            "food_category": category_description,
                            "nutrients": []
                        }
                        
                        # Extract key nutrients with comprehensive handling
                        nutrients = food.get('foodNutrients', [])
                        
                        # Extract nutrients from USDA API response
                        
                        for nutrient in nutrients[:5]:  # Top 5 nutrients
                            if isinstance(nutrient, dict):
                                # Try different possible structures
                                nutrient_name = 'N/A'
                                nutrient_amount = 0
                                nutrient_unit = 'N/A'
                                
                                # Check if nutrient info is nested
                                if 'nutrient' in nutrient and isinstance(nutrient['nutrient'], dict):
                                    nutrient_info = nutrient['nutrient']
                                    nutrient_name = nutrient_info.get('name', 'N/A')
                                    nutrient_unit = nutrient_info.get('unitName', 'N/A')
                                    nutrient_amount = nutrient.get('amount', 0)
                                # Check if nutrient info is at top level with 'name'
                                elif 'name' in nutrient:
                                    nutrient_name = nutrient.get('name', 'N/A')
                                    nutrient_amount = nutrient.get('amount', 0)
                                    nutrient_unit = nutrient.get('unitName', 'N/A')
                                # Check for USDA API format with 'nutrientName' and 'value'
                                elif 'nutrientName' in nutrient:
                                    nutrient_name = nutrient.get('nutrientName', 'N/A')
                                    nutrient_amount = nutrient.get('value', 0)  # USDA uses 'value' not 'amount'
                                    nutrient_unit = nutrient.get('unitName', 'N/A')
                                
                                # Only add if we have meaningful data
                                if nutrient_name != 'N/A' and nutrient_amount is not None and nutrient_amount != 0:
                                    food_item['nutrients'].append({
                                        "name": nutrient_name,
                                        "amount": nutrient_amount,
                                        "unit": nutrient_unit
                                    })
                        
                        # If no nutrients found, try alternative approach
                        if not food_item['nutrients']:
                            # Try to get basic nutritional info from other fields
                            if 'energy' in food:
                                food_item['nutrients'].append({
                                    "name": "Energy",
                                    "amount": food.get('energy', 0),
                                    "unit": "kcal"
                                })
                            if 'protein' in food:
                                food_item['nutrients'].append({
                                    "name": "Protein",
                                    "amount": food.get('protein', 0),
                                    "unit": "g"
                                })
                        
                        food_items.append(food_item)
                    
                    return {
                        "status": "found",
                        "description": "Found in USDA FoodData Central",
                        "details": f"Found {len(foods)} food items in USDA database",
                        "food_count": len(foods),
                        "food_items": food_items,
                        "source": "USDA FoodData Central (Free API)"
                    }
            
            return {
                "status": "not_found",
                "description": "Not found in USDA database",
                "details": "No USDA data available for this ingredient",
                "source": "USDA API (Free)"
            }
            
        except Exception as e:
            print(f"USDA API error: {str(e)}")
            return {
                "status": "error", 
                "description": "USDA data unavailable",
                "details": "Unable to fetch USDA data",
                "source": "USDA API (Free)"
            }

    def _get_real_off_data(self, ingredient):
        """Get real-time Open Food Facts data using free API"""
        try:
            # Open Food Facts API (Completely Free)
            off_url = f"https://world.openfoodfacts.org/cgi/search.pl?search_terms={ingredient}&search_simple=1&action=process&json=1"
            response = requests.get(off_url, timeout=2)  # Further reduced timeout for Open Food Facts
            
            if response.status_code == 200:
                data = response.json()
                products = data.get('products', [])
                
                if products:
                    # Extract detailed product information
                    product_items = []
                    for product in products[:5]:  # Limit to 5 products
                        product_item = {
                            "product_name": product.get('product_name', 'N/A'),
                            "brands": product.get('brands', 'N/A'),
                            "categories": product.get('categories', 'N/A'),
                            "ingredients_text": product.get('ingredients_text', 'N/A'),
                            "nutrition_grade": product.get('nutrition_grade_fr', 'N/A'),
                            "nova_group": product.get('nova_group', 'N/A'),
                            "ecoscore_grade": product.get('ecoscore_grade', 'N/A'),
                            "countries": product.get('countries', 'N/A'),
                            "image_url": product.get('image_url', 'N/A'),
                            "nutrients": {}
                        }
                        
                        # Extract key nutrients
                        nutriments = product.get('nutriments', {})
                        key_nutrients = ['energy-kcal_100g', 'fat_100g', 'carbohydrates_100g', 'proteins_100g', 'sugars_100g']
                        for nutrient in key_nutrients:
                            if nutrient in nutriments:
                                product_item['nutrients'][nutrient.replace('_100g', '').replace('-', '_')] = nutriments[nutrient]
                        
                        product_items.append(product_item)
                    
                    return {
                        "status": "found",
                        "description": "Found in Open Food Facts",
                        "details": f"Found {len(products)} products in global database",
                        "product_count": len(products),
                        "products": product_items,
                        "source": "Open Food Facts (Free API)"
                    }
            
            return {
                "status": "not_found",
                "description": "Not found in Open Food Facts",
                "details": "No global product data available",
                "source": "Open Food Facts (Free API)"
            }
            
        except Exception as e:
            print(f"Open Food Facts API error: {str(e)}")
            return {
                "status": "error", 
                "description": "Open Food Facts data unavailable",
                "details": "Unable to fetch global product data",
                "source": "Open Food Facts (Free API)"
            }

    def _build_regulatory_deep_dive(self, ingredient):
        """Build comprehensive regulatory compliance deep dive with real-time data using concurrent API calls"""
        from concurrent.futures import ThreadPoolExecutor, as_completed
        import time
        
        # Simple cache key for regulatory data
        cache_key = f"regulatory_{ingredient.lower()}"
        
        # Check cache first (cache for 5 minutes)
        if hasattr(self, '_regulatory_cache'):
            cached_data = self._regulatory_cache.get(cache_key)
            if cached_data and time.time() - cached_data.get('timestamp', 0) < 300:  # 5 minutes
                print(f" Using cached regulatory data for {ingredient}")
                return cached_data['data']
        
        start_time = time.time()
        
        # Use ThreadPoolExecutor for concurrent API calls
        with ThreadPoolExecutor(max_workers=3) as executor:
            # Submit all API calls concurrently
            future_fda = executor.submit(self._get_real_fda_data, ingredient)
            future_usda = executor.submit(self._get_real_usda_data, ingredient)
            future_global = executor.submit(self._get_real_off_data, ingredient)
            
            # Collect results as they complete
            fda_data = future_fda.result()
            usda_data = future_usda.result()
            global_data = future_global.result()
        
        end_time = time.time()
        print(f" Regulatory APIs completed in {end_time - start_time:.2f} seconds")
        
        result = {
            'fda': fda_data,
            'usda': usda_data,
            'global': global_data,
            'citations': self._build_real_citations(ingredient),
            'last_updated': self._get_current_timestamp()
        }
        
        # Cache the result
        if not hasattr(self, '_regulatory_cache'):
            self._regulatory_cache = {}
        self._regulatory_cache[cache_key] = {
            'data': result,
            'timestamp': time.time()
        }
        
        return result

    def _build_real_citations(self, ingredient):
        """Build citations with real API sources"""
        citations = []
        
        # FDA citations
        fda_data = self._get_real_fda_data(ingredient)
        if fda_data['status'] != 'error':
            citations.append({
                'source': 'FDA GRAS Database',
                'url': 'https://www.fda.gov/food/food-additives-petitions/food-additive-status-list',
                'status': fda_data['status']
            })
        
        # USDA citations
        usda_data = self._get_real_usda_data(ingredient)
        if usda_data['status'] != 'error':
            citations.append({
                'source': 'USDA FoodData Central',
                'url': 'https://fdc.nal.usda.gov/',
                'status': usda_data['status']
            })
        
        # Open Food Facts citations
        off_data = self._get_real_off_data(ingredient)
        if off_data['status'] != 'error':
            citations.append({
                'source': 'Open Food Facts',
                'url': 'https://world.openfoodfacts.org/',
                'status': off_data['status']
            })
        
        return citations

    def _get_current_timestamp(self):
        """Get current timestamp in ISO format"""
        from datetime import datetime
        return datetime.now().isoformat()

    # Remove the old methods that are no longer needed
    # def query_full_llm(self, ingredient):
    # def safe_future_result(self, future, key):
    # def get_unsplash_image(self, query):
    # def get_edamam_data(self, query):
    # def get_open_food_facts_data(self, query):
    # def get_related_blogs(self, query):

class SubscribeUserView(APIView):
    permission_classes = [IsAuthenticated]

    def _can_use_premium_features(self, user_subscription):
        """
        Helper method to determine if user can still use premium features
        even when downgrading or canceling
        """
        if not user_subscription:
            return False
        
        # User can use premium features if:
        # 1. Currently active premium subscription
        # 2. Canceled but still within paid period
        # 3. Downgraded but still within paid period
        
        if user_subscription.plan_name == "premium" and user_subscription.status == "active":
            return True
        
        if user_subscription.status == "canceled_at_period_end" and user_subscription.current_period_end:
            # Check if current time is before period end
            from datetime import datetime
            now = datetime.now(timezone.utc)
            return now < user_subscription.current_period_end
        
        return False

    def _get_subscription_status_summary(self, user_subscription):
        """
        Helper method to get comprehensive subscription status information
        """
        if not user_subscription:
            return {
                "has_subscription": False,
                "can_use_premium_features": False,
                "feature_access": "none",
                "grace_period": False,
                "days_remaining": None
            }
        
        can_use_premium = self._can_use_premium_features(user_subscription)
        
        # Calculate days remaining for premium access
        days_remaining = None
        if user_subscription.current_period_end:
            from datetime import datetime
            now = datetime.now(timezone.utc)
            if now < user_subscription.current_period_end:
                days_remaining = (user_subscription.current_period_end - now).days
        
        return {
            "has_subscription": True,
            "plan_name": user_subscription.plan_name,
            "premium_type": user_subscription.premium_type,
            "status": user_subscription.status,
            "can_use_premium_features": can_use_premium,
            "feature_access": "premium_until_period_end" if can_use_premium and user_subscription.status == "canceled_at_period_end" else "premium_active" if can_use_premium else "freemium_only",
            "grace_period": user_subscription.status == "canceled_at_period_end" and can_use_premium,
            "days_remaining": days_remaining,
            "current_period_end": user_subscription.current_period_end.isoformat() if user_subscription.current_period_end else None,
            "started_at": user_subscription.started_at.isoformat() if user_subscription.started_at else None
        }

    def post(self, request):
        user = request.user
        plan = request.data.get("plan_id")  # 'freemium', 'monthly', or 'yearly'
        payment_method_id = request.data.get("payment_method_id")

        if not plan:
            return Response({"error": "Plan ID is required."}, status=400)

        if plan == "freemium":
            from datetime import datetime
            
            # Check if user has an active premium subscription
            try:
                existing_subscription = UserSubscription.objects.get(user=user)
                
                # If user has an active premium subscription OR is in grace period, handle appropriately
                if existing_subscription.plan_name == "premium" and (existing_subscription.status == "active" or existing_subscription.status == "canceled_at_period_end"):
                    
                    # If already in grace period, return current status
                    if existing_subscription.status == "canceled_at_period_end":
                        from datetime import datetime
                        days_remaining = (existing_subscription.current_period_end - datetime.now(timezone.utc)).days if existing_subscription.current_period_end else None
                        
                        return Response({
                            "message": "Your premium subscription is already scheduled to end. You'll continue to have premium access until the end of your billing period.",
                            "current_plan": "premium",
                            "downgrade_scheduled": True,
                            "billing_period_end": existing_subscription.current_period_end.isoformat() if existing_subscription.current_period_end else None,
                            "premium_access_until": existing_subscription.current_period_end.isoformat() if existing_subscription.current_period_end else None,
                            "plan_type": existing_subscription.premium_type,
                            "plan_name": f"{existing_subscription.premium_type.capitalize()} Premium",
                            "status": "canceled_at_period_end",
                            "days_remaining": days_remaining,
                            "can_use_premium_features": True,
                            "feature_access": "premium_until_period_end",
                            "subscription_id": existing_subscription.stripe_subscription_id,
                            "next_billing_date": existing_subscription.current_period_end.isoformat() if existing_subscription.current_period_end else None,
                            "downgrade_effective_date": existing_subscription.current_period_end.isoformat() if existing_subscription.current_period_end else None,
                            "refund_eligible": False,
                            "grace_period": True,
                            "already_scheduled": True
                        }, status=200)
                    
                    # Check if there's a Stripe subscription to cancel
                    if existing_subscription.stripe_subscription_id:
                        try:
                            # Cancel the subscription at period end (don't cancel immediately)
                            stripe.Subscription.modify(
                                existing_subscription.stripe_subscription_id,
                                cancel_at_period_end=True
                            )
                            
                            # Update local subscription status
                            existing_subscription.status = "canceled_at_period_end"
                            existing_subscription.save()
                            
                            return Response({
                                "message": "Premium subscription will be canceled at the end of current billing period. You'll continue to have premium access until then.",
                                "current_plan": "premium",
                                "downgrade_scheduled": True,
                                "billing_period_end": existing_subscription.current_period_end.isoformat() if existing_subscription.current_period_end else None,
                                "premium_access_until": existing_subscription.current_period_end.isoformat() if existing_subscription.current_period_end else None,
                                "plan_type": existing_subscription.premium_type,
                                "plan_name": f"{existing_subscription.premium_type.capitalize()} Premium",
                                "status": "canceled_at_period_end",
                                "days_remaining": (existing_subscription.current_period_end - datetime.now(timezone.utc)).days if existing_subscription.current_period_end else None,
                                "can_use_premium_features": True,
                                "feature_access": "premium_until_period_end",
                                "subscription_id": existing_subscription.stripe_subscription_id,
                                "next_billing_date": existing_subscription.current_period_end.isoformat() if existing_subscription.current_period_end else None,
                                "downgrade_effective_date": existing_subscription.current_period_end.isoformat() if existing_subscription.current_period_end else None,
                                "refund_eligible": False,
                                "grace_period": True
                            }, status=200)
                            
                        except stripe.error.StripeError as e:
                            return Response({"error": f"Failed to cancel subscription: {str(e)}"}, status=400)
                    else:
                        # No Stripe subscription, can switch immediately
                        subscription_start = datetime.now(timezone.utc)
                        existing_subscription.plan_name = "freemium"
                        existing_subscription.premium_type = None
                        existing_subscription.status = "active"
                        existing_subscription.stripe_subscription_id = None
                        existing_subscription.started_at = subscription_start
                        existing_subscription.current_period_end = None
                        existing_subscription.save()
                        
                        return Response({
                            "message": "Switched to freemium plan immediately.",
                            "subscription_start_date": subscription_start.isoformat(),
                            "subscription_end_date": None,
                            "plan_type": "freemium",
                            "plan_name": "Freemium",
                            "status": "active",
                            "can_use_premium_features": False,
                            "feature_access": "freemium_only",
                            "downgrade_effective_date": subscription_start.isoformat(),
                            "grace_period": False,
                            "refund_eligible": False,
                            "plan_change_type": "immediate_downgrade"
                        }, status=200)
                
                else:
                    # User doesn't have active premium, can switch to freemium immediately
                    subscription_start = datetime.now(timezone.utc)
                    existing_subscription.plan_name = "freemium"
                    existing_subscription.premium_type = None
                    existing_subscription.status = "active"
                    existing_subscription.stripe_subscription_id = None
                    existing_subscription.started_at = subscription_start
                    existing_subscription.current_period_end = None
                    existing_subscription.save()
                    
                    return Response({
                        "message": "Switched to freemium plan.",
                        "subscription_start_date": subscription_start.isoformat(),
                        "subscription_end_date": None,
                        "plan_type": "freemium",
                        "plan_name": "Freemium",
                        "status": "active",
                        "can_use_premium_features": False,
                        "feature_access": "freemium_only",
                        "downgrade_effective_date": subscription_start.isoformat(),
                        "grace_period": False,
                        "refund_eligible": False,
                        "plan_change_type": "immediate_downgrade"
                    }, status=200)
                    
            except UserSubscription.DoesNotExist:
                # User has no subscription, create new freemium
                subscription_start = datetime.now(timezone.utc)
                
                UserSubscription.objects.create(
                    user=user,
                    plan_name="freemium",
                    premium_type=None,
                    status="active",
                    stripe_subscription_id=None,
                    started_at=subscription_start,
                    current_period_end=None,  # Freemium has no expiry
                )
                
                return Response({
                    "message": "Freemium plan activated.",
                    "subscription_start_date": subscription_start.isoformat(),
                    "subscription_end_date": None,
                    "plan_type": "freemium",
                    "plan_name": "Freemium",
                    "status": "active",
                    "can_use_premium_features": False,
                    "feature_access": "freemium_only",
                    "downgrade_effective_date": subscription_start.isoformat(),
                    "grace_period": False,
                    "refund_eligible": False,
                    "plan_change_type": "new_freemium"
                }, status=200)

        elif plan == "cancel_downgrade":
            # Allow users to cancel their scheduled downgrade and keep premium
            try:
                existing_subscription = UserSubscription.objects.get(user=user)
                
                if existing_subscription.status == "canceled_at_period_end" and existing_subscription.stripe_subscription_id:
                    try:
                        # Reactivate the subscription by removing cancel_at_period_end
                        stripe.Subscription.modify(
                            existing_subscription.stripe_subscription_id,
                            cancel_at_period_end=False
                        )
                        
                        # Update local subscription status back to active
                        existing_subscription.status = "active"
                        existing_subscription.save()
                        
                        return Response({
                            "message": "Premium subscription reactivated! Your downgrade has been canceled.",
                            "current_plan": "premium",
                            "downgrade_scheduled": False,
                            "status": "active",
                            "plan_type": existing_subscription.premium_type,
                            "plan_name": f"{existing_subscription.premium_type.capitalize()} Premium",
                            "can_use_premium_features": True,
                            "feature_access": "premium_active",
                            "subscription_id": existing_subscription.stripe_subscription_id,
                            "reactivation_successful": True
                        }, status=200)
                        
                    except stripe.error.StripeError as e:
                        return Response({"error": f"Failed to reactivate subscription: {str(e)}"}, status=400)
                else:
                    return Response({"error": "No scheduled downgrade found to cancel."}, status=400)
                    
            except UserSubscription.DoesNotExist:
                return Response({"error": "No subscription found."}, status=400)
                
        elif plan in ["monthly", "yearly"]:
            if not payment_method_id:
                return Response({"error": "Payment method ID is required for premium plan."}, status=400)

            # Get or create Stripe Customer
            stripe_customer, created = StripeCustomer.objects.get_or_create(user=user)
            if created or not stripe_customer.stripe_customer_id:
                customer = stripe.Customer.create(email=user.email)
                stripe_customer.stripe_customer_id = customer.id
                stripe_customer.save()

            # Attach Payment Method
            try:
                stripe.PaymentMethod.attach(
                    payment_method_id,
                    customer=stripe_customer.stripe_customer_id,
                )
                stripe.Customer.modify(
                    stripe_customer.stripe_customer_id,
                    invoice_settings={"default_payment_method": payment_method_id},
                )
            except stripe.error.StripeError as e:
                return Response({"error": str(e)}, status=400)

            # Choose price ID with tiered discount logic
            days_since_signup = (timezone.now() - user.date_joined).days
            discount_applied = False
            
            if plan == "monthly":
                # Monthly subscriptions have no discount - always use regular price
                price_id = settings.STRIPE_MONTHLY_PRICE_ID
                discount_applied = False
            elif plan == "yearly":
                # Yearly discount available for first 7 days only
                if days_since_signup <= 7:
                    price_id = settings.STRIPE_YEARLY_DISCOUNTED_PRICE_ID
                    discount_applied = True
                else:
                    price_id = settings.STRIPE_YEARLY_PRICE_ID
                    discount_applied = False

            # Create Subscription
            try:
                subscription = stripe.Subscription.create(
                customer=stripe_customer.stripe_customer_id,
                items=[{"price": price_id}],
                expand=["latest_invoice"]  #  Fix here
            )

                # Calculate subscription dates
                from datetime import datetime
                import time
                
                # Get subscription start date (current time)
                subscription_start = datetime.now(timezone.utc)
                
                # Get subscription end date from Stripe
                subscription_end = None
                if hasattr(subscription, 'current_period_end') and subscription.current_period_end:
                    subscription_end = datetime.fromtimestamp(subscription.current_period_end, tz=timezone.utc)
                else:
                    # Fallback: calculate based on plan type
                    if plan == "monthly":
                        from datetime import timedelta
                        subscription_end = subscription_start + timedelta(days=30)
                    elif plan == "yearly":
                        from datetime import timedelta
                        subscription_end = subscription_start + timedelta(days=365)

                UserSubscription.objects.update_or_create(
                    user=user,
                    defaults={
                        "plan_name": "premium",  # Always set to 'premium' for any paid plan
                        "premium_type": plan,     # Set to 'monthly' or 'yearly'
                        "stripe_subscription_id": subscription.id,
                        "status": subscription.status,
                        "started_at": subscription_start,
                        "current_period_end": subscription_end,
                    }
                )

                # Send subscription notification
                from .tasks import send_subscription_notification_task_celery, safe_execute_task
                safe_execute_task(
                    send_subscription_notification_task_celery,
                    user.id, 
                    'subscription_purchased',
                    plan_type=f"{plan.capitalize()} Premium"
                )

                response_message = f"{plan.capitalize()} subscription started."
                if discount_applied:
                    if plan == "yearly":
                        response_message += "  58.3% early bird discount applied for yearly subscription!"
                    else:
                        response_message += "  58.3% new user discount applied for monthly subscription!"
                else:
                    if plan == "yearly":
                        response_message += " Regular yearly pricing applied."
                    else:
                        response_message += " Regular monthly pricing applied."
                
                return Response({
                    "message": response_message,
                    "subscription_id": subscription.id,
                    "status": subscription.status,
                    "discount_applied": discount_applied,
                    "discount_type": "early_bird" if plan == "yearly" and discount_applied else "new_user" if discount_applied else None,
                    "days_since_signup": days_since_signup,
                    "subscription_start_date": subscription_start.isoformat(),
                    "subscription_end_date": subscription_end.isoformat() if subscription_end else None,
                    "plan_type": plan,
                    "plan_name": f"{plan.capitalize()} Premium",
                })

            except stripe.error.StripeError as e:
                return Response({"error": str(e)}, status=500)

        return Response({"error": "Invalid plan type."}, status=400)

    def get(self, request):
        """
        GET API to retrieve comprehensive subscription information for frontend subscription screen.
        Returns detailed subscription status, plan details, pricing, and user information.
        """
        user = request.user
        
        try:
            # Get user's subscription
            user_subscription = UserSubscription.objects.get(user=user)
            
            # Get Stripe customer info if exists
            stripe_customer = None
            try:
                stripe_customer = StripeCustomer.objects.get(user=user)
            except StripeCustomer.DoesNotExist:
                pass
            
            # Get detailed Stripe subscription info if exists
            stripe_subscription_details = None
            if user_subscription.stripe_subscription_id:
                try:
                    stripe_subscription_details = stripe.Subscription.retrieve(
                        user_subscription.stripe_subscription_id
                    )
                except stripe.error.StripeError as e:
                    print(f"Stripe error retrieving subscription: {e}")
                except Exception as e:
                    print(f"Unexpected error retrieving subscription: {e}")
            
            # Get Stripe price details for available plans
            monthly_price_details = None
            yearly_price_details = None
            
            try:
                if settings.STRIPE_MONTHLY_PRICE_ID:
                    monthly_price_details = stripe.Price.retrieve(settings.STRIPE_MONTHLY_PRICE_ID)
            except stripe.error.StripeError as e:
                print(f"Stripe error retrieving monthly price: {e}")
            except Exception as e:
                print(f"Unexpected error retrieving monthly price: {e}")
            
            try:
                if settings.STRIPE_YEARLY_PRICE_ID:
                    yearly_price_details = stripe.Price.retrieve(settings.STRIPE_YEARLY_PRICE_ID)
            except stripe.error.StripeError as e:
                print(f"Stripe error retrieving yearly price: {e}")
            except Exception as e:
                print(f"Unexpected error retrieving yearly price: {e}")
            
            # Calculate subscription benefits
            is_premium = user_subscription.is_premium
            is_active = user_subscription.status in ['active', 'trialing']
            
            # Handle canceled_at_period_end status - user still has premium access until period end
            if user_subscription.status == 'canceled_at_period_end':
                is_active = True  # User still has premium access
                is_premium = True  # User still has premium features
            
            # Determine current plan details
            current_plan = {
                "plan_id": user_subscription.plan_name,
                "plan_name": user_subscription.plan_name.capitalize(),
                "premium_type": user_subscription.premium_type,
                "status": user_subscription.status,
                "is_active": is_active,
                "is_premium": is_premium,
                "started_at": user_subscription.started_at.isoformat() if user_subscription.started_at else None,
                "subscription_start_date": user_subscription.started_at.isoformat() if user_subscription.started_at else None,
                "subscription_end_date": user_subscription.current_period_end.isoformat() if user_subscription.current_period_end else None,
                "plan_type": user_subscription.premium_type if user_subscription.premium_type else user_subscription.plan_name,
            }
            
            # Add special message for canceled subscriptions
            if user_subscription.status == 'canceled_at_period_end':
                current_plan["downgrade_scheduled"] = True
                current_plan["downgrade_message"] = f"Your premium subscription will end on {user_subscription.current_period_end.strftime('%B %d, %Y') if user_subscription.current_period_end else 'the end of your billing period'}. You'll continue to have premium access until then."
            else:
                current_plan["downgrade_scheduled"] = False
                current_plan["downgrade_message"] = None
            
            # Add Stripe-specific details if available
            if stripe_subscription_details:
                stripe_details = {
                    "stripe_subscription_id": user_subscription.stripe_subscription_id,
                }
                
                # Safely access Stripe subscription attributes using dict-style access
                try:
                    if 'current_period_start' in stripe_subscription_details and stripe_subscription_details['current_period_start']:
                        stripe_details["current_period_start"] = stripe_subscription_details['current_period_start']
                except (AttributeError, KeyError, TypeError):
                    pass
                
                try:
                    if 'current_period_end' in stripe_subscription_details and stripe_subscription_details['current_period_end']:
                        stripe_details["current_period_end"] = stripe_subscription_details['current_period_end']
                except (AttributeError, KeyError, TypeError):
                    pass
                
                try:
                    if 'cancel_at_period_end' in stripe_subscription_details:
                        stripe_details["cancel_at_period_end"] = stripe_subscription_details['cancel_at_period_end']
                except (AttributeError, KeyError, TypeError):
                    pass
                
                try:
                    if 'trial_end' in stripe_subscription_details and stripe_subscription_details['trial_end']:
                        stripe_details["trial_end"] = stripe_subscription_details['trial_end']
                except (AttributeError, KeyError, TypeError):
                    pass
                
                current_plan.update(stripe_details)
            
            # Available plans for subscription
            available_plans = {
                "freemium": {
                    "plan_id": "freemium",
                    "plan_name": "Freemium",
                    "price": 0,
                    "currency": "USD",
                    "billing_cycle": None,
                    "features": [
                        "5 free premium scans per month",
                        "Basic nutrition analysis",
                        "Ingredient safety check",
                        "Basic health insights"
                    ],
                    "limitations": [
                        "Limited to 6 scans per month",
                        "No advanced AI insights",
                        "No priority support"
                    ]
                }
            }
            
            # Add premium plans if price details are available
            if monthly_price_details:
                # Monthly subscriptions have no discount - always use regular price
                available_plans["monthly"] = {
                    "plan_id": "monthly",
                    "plan_name": "Premium Monthly",
                    "price": monthly_price_details.unit_amount / 100,
                    "original_price": None,
                    "currency": monthly_price_details.currency.upper(),
                    "billing_cycle": "monthly",
                    "stripe_price_id": monthly_price_details.id,
                    "discount_eligible": False,
                    "discount_percentage": 0,
                    "days_remaining_for_discount": 0,
                    "discount_message": "Regular pricing - No discount available",
                    "features": [
                        "Unlimited premium scans",
                        "Advanced AI health insights",
                        "Expert nutrition advice",
                        "Priority customer support",
                        "Detailed ingredient analysis",
                        "Health condition recommendations",
                        "Dietary preference tracking",
                        "Allergen alerts"
                    ],
                    "savings": None
                }
            
            if yearly_price_details:
                # Get comprehensive discount information for the user
                comprehensive_discount_info = get_comprehensive_discount_info(user)
                
                # Get discounted price details if available
                discounted_yearly_price_details = None
                if comprehensive_discount_info['yearly_discount']['eligible'] and settings.STRIPE_YEARLY_DISCOUNTED_PRICE_ID:
                    try:
                        discounted_yearly_price_details = stripe.Price.retrieve(settings.STRIPE_YEARLY_DISCOUNTED_PRICE_ID)
                    except stripe.error.StripeError:
                        pass  # Fall back to regular price if discounted price not found
                
                # Determine which price to show
                if comprehensive_discount_info['yearly_discount']['eligible'] and discounted_yearly_price_details:
                    display_yearly_price = discounted_yearly_price_details.unit_amount / 100
                    original_yearly_price = yearly_price_details.unit_amount / 100
                    yearly_price_id_to_use = settings.STRIPE_YEARLY_DISCOUNTED_PRICE_ID
                    yearly_discount_message = f" 58.3% OFF - Early bird yearly offer! ({comprehensive_discount_info['yearly_discount']['days_remaining']} days left)"
                else:
                    display_yearly_price = yearly_price_details.unit_amount / 100
                    original_yearly_price = None
                    yearly_price_id_to_use = yearly_price_details.id
                    yearly_discount_message = "Regular pricing - No discount available"
                
                yearly_price = display_yearly_price
                monthly_equivalent = yearly_price / 12
                monthly_savings = 0
                
                if monthly_price_details:
                    monthly_price = monthly_price_details.unit_amount / 100
                    monthly_savings = ((monthly_price * 12) - yearly_price) / (monthly_price * 12) * 100
                
                available_plans["yearly"] = {
                    "plan_id": "yearly",
                    "plan_name": "Premium Yearly",
                    "price": yearly_price,
                    "original_price": original_yearly_price,
                    "currency": yearly_price_details.currency.upper(),
                    "billing_cycle": "yearly",
                    "stripe_price_id": yearly_price_id_to_use,
                    "monthly_equivalent": round(monthly_equivalent, 2),
                    "savings_percentage": round(monthly_savings, 1) if monthly_savings > 0 else None,
                    "features": [
                        "Unlimited premium scans",
                        "Advanced AI health insights",
                        "Expert nutrition advice",
                        "Priority customer support",
                        "Detailed ingredient analysis",
                        "Health condition recommendations",
                        "Dietary preference tracking",
                        "Allergen alerts",
                        # "Save up to 20% compared to monthly"
                    ],
                    "discount_eligible": comprehensive_discount_info['yearly_discount']['eligible'],
                    "discount_percentage": comprehensive_discount_info['yearly_discount']['discount_percentage'],
                    "days_remaining_for_discount": comprehensive_discount_info['yearly_discount']['days_remaining'],
                    "days_since_signup": comprehensive_discount_info['days_since_signup'],
                    "signup_date": comprehensive_discount_info['signup_date'],
                    "discount_message": yearly_discount_message
                }
            
            # User information
            user_info = {
                "user_id": user.id,
                "email": user.email,
                "full_name": user.full_name,
                "has_stripe_customer": stripe_customer is not None,
                "stripe_customer_id": stripe_customer.stripe_customer_id if stripe_customer else None
            }
            
            # Subscription usage information
            usage_info = {
                "scans_used": 0,  # This would need to be calculated from scan history
                "scans_limit": 6 if not is_premium else "unlimited",
                "can_scan": is_premium or True,  # This would need proper logic
                "days_remaining": None,  # This would need calculation for trial periods
                "feature_access": "freemium_only" if not is_premium else "premium_active" if user_subscription.status == "active" else "premium_until_period_end",
                "can_use_ai_insights": is_premium,
                "can_use_priority_support": is_premium,
                "can_use_advanced_features": is_premium,
                "grace_period_active": user_subscription.status == "canceled_at_period_end",
                "downgrade_scheduled": user_subscription.status == "canceled_at_period_end"
            }
            
            # Add days remaining for canceled subscriptions
            if user_subscription.status == 'canceled_at_period_end' and user_subscription.current_period_end:
                from datetime import datetime
                now = datetime.now(timezone.utc)
                days_remaining = (user_subscription.current_period_end - now).days
                usage_info["days_remaining"] = max(0, days_remaining)
                usage_info["premium_access_until"] = user_subscription.current_period_end.isoformat()
                usage_info["grace_period_message"] = f"You have {days_remaining} days of premium access remaining"
            
            # If user has active subscription, calculate usage
            if is_active:
                try:
                    # Count scans in current period (this is a simplified version)
                    from datetime import datetime, timedelta
                    if stripe_subscription_details:
                        try:
                            if 'current_period_start' in stripe_subscription_details and stripe_subscription_details['current_period_start']:
                                period_start = datetime.fromtimestamp(stripe_subscription_details['current_period_start'])
                                scans_in_period = FoodLabelScan.objects.filter(
                                    user=user,
                                    scanned_at__gte=period_start
                                ).count()
                                usage_info["scans_used"] = scans_in_period
                        except (AttributeError, KeyError, TypeError) as e:
                            print(f"Error accessing current_period_start: {e}")
                            # Fallback: count scans from last 30 days
                            try:
                                period_start = datetime.now() - timedelta(days=30)
                                scans_in_period = FoodLabelScan.objects.filter(
                                    user=user,
                                    scanned_at__gte=period_start
                                ).count()
                                usage_info["scans_used"] = scans_in_period
                            except Exception as fallback_error:
                                print(f"Error in fallback usage calculation: {fallback_error}")
                                usage_info["scans_used"] = 0
                except Exception as e:
                    print(f"Error calculating usage: {e}")
            
            response_data = {
                "current_subscription": current_plan,
                "available_plans": available_plans,
                "user_info": user_info,
                "usage_info": usage_info,
                "effective_plan_status": {
                    "current_effective_plan": "premium" if is_premium else "freemium",
                    "features_available": "premium" if is_premium else "freemium",
                    "scan_limit_effective": "unlimited" if is_premium else 20,
                    "ai_insights_available": is_premium,
                    "priority_support_available": is_premium,
                    "advanced_features_available": is_premium,
                    "grace_period_info": {
                        "is_in_grace_period": user_subscription.status == "canceled_at_period_end",
                        "grace_period_end": user_subscription.current_period_end.isoformat() if user_subscription.current_period_end else None,
                        "days_remaining_in_grace_period": usage_info.get("days_remaining"),
                        "grace_period_message": usage_info.get("grace_period_message")
                    }
                },
                "stripe_config": {
                    "publishable_key": getattr(settings, 'STRIPE_PUBLISHABLE_KEY', None),
                    "monthly_price_id": settings.STRIPE_MONTHLY_PRICE_ID,
                    "yearly_price_id": settings.STRIPE_YEARLY_PRICE_ID,
                    "yearly_discounted_price_id": settings.STRIPE_YEARLY_DISCOUNTED_PRICE_ID,
                },
                "discount_info": get_comprehensive_discount_info(user),
                "subscription_benefits": {
                    "freemium": {
                        "scan_limit": 6,
                        "ai_insights": False,
                        "priority_support": False,
                        "advanced_features": False
                    },
                    "premium": {
                        "scan_limit": "unlimited",
                        "ai_insights": True,
                        "priority_support": True,
                        "advanced_features": True
                    }
                }
            }
            
            return Response(response_data, status=status.HTTP_200_OK)
            
        except UserSubscription.DoesNotExist:
            # User has no subscription record, treat as freemium
            current_plan = {
                "plan_id": "freemium",
                "plan_name": "Freemium",
                "premium_type": "free",
                "status": "active",
                "is_active": True,
                "is_premium": False,
                "started_at": None,
            }
            
            # Available plans (same as above)
            available_plans = {
                "freemium": {
                    "plan_id": "freemium",
                    "plan_name": "Freemium",
                    "price": 0,
                    "currency": "USD",
                    "billing_cycle": None,
                    "features": [
                        "5 free premium scans per month",
                        "Basic nutrition analysis",
                        "Ingredient safety check",
                        "Basic health insights"
                    ],
                    "limitations": [
                        "Limited to 5 premium scans per month",
                        "No advanced AI insights",
                        "No priority support"
                    ]
                }
            }
            
            # Get Stripe price details for available plans
            monthly_price_details = None
            yearly_price_details = None
            
            try:
                if settings.STRIPE_MONTHLY_PRICE_ID:
                    monthly_price_details = stripe.Price.retrieve(settings.STRIPE_MONTHLY_PRICE_ID)
            except stripe.error.StripeError as e:
                print(f"Stripe error retrieving monthly price: {e}")
            except Exception as e:
                print(f"Unexpected error retrieving monthly price: {e}")
            
            try:
                if settings.STRIPE_YEARLY_PRICE_ID:
                    yearly_price_details = stripe.Price.retrieve(settings.STRIPE_YEARLY_PRICE_ID)
            except stripe.error.StripeError as e:
                print(f"Stripe error retrieving yearly price: {e}")
            except Exception as e:
                print(f"Unexpected error retrieving yearly price: {e}")
            
            if monthly_price_details:
                # Monthly subscriptions have no discount - always use regular price
                available_plans["monthly"] = {
                    "plan_id": "monthly",
                    "plan_name": "Premium Monthly",
                    "original_price": None,
                    "price": monthly_price_details.unit_amount / 100,
                    "currency": monthly_price_details.currency.upper(),
                    "billing_cycle": "monthly",
                    "stripe_price_id": monthly_price_details.id,
                    "discount_eligible": False,
                    "discount_percentage": 0,
                    "days_remaining_for_discount": 0,
                    "discount_message": "Regular pricing - No discount available",
                    "features": [
                        "Unlimited premium scans",
                        "Advanced AI health insights",
                        "Expert nutrition advice",
                        "Priority customer support",
                        "Detailed ingredient analysis",
                        "Health condition recommendations",
                        "Dietary preference tracking",
                        "Allergen alerts"
                    ],
                    "savings": None
                }
            
            if yearly_price_details:
                # Get comprehensive discount information for yearly plan
                comprehensive_discount_info = get_comprehensive_discount_info(user)
                
                # Get discounted yearly price details if available
                yearly_discounted_price_details = None
                if comprehensive_discount_info['yearly_discount']['eligible'] and settings.STRIPE_YEARLY_DISCOUNTED_PRICE_ID:
                    try:
                        yearly_discounted_price_details = stripe.Price.retrieve(settings.STRIPE_YEARLY_DISCOUNTED_PRICE_ID)
                        print(f"Successfully retrieved yearly discounted price: {yearly_discounted_price_details.unit_amount / 100}")
                    except stripe.error.StripeError as e:
                        print(f"Error retrieving yearly discounted price: {e}")
                        pass  # Fall back to regular price if discounted price not found
                
                # Determine which price to show for yearly
                if comprehensive_discount_info['yearly_discount']['eligible'] and yearly_discounted_price_details:
                    display_yearly_price = yearly_discounted_price_details.unit_amount / 100
                    original_yearly_price = yearly_price_details.unit_amount / 100
                    yearly_price_id_to_use = settings.STRIPE_YEARLY_DISCOUNTED_PRICE_ID
                    yearly_discount_message = f" 58.3% OFF - Early bird yearly offer! ({comprehensive_discount_info['yearly_discount']['days_remaining']} days left)"
                else:
                    display_yearly_price = yearly_price_details.unit_amount / 100
                    original_yearly_price = None
                    yearly_price_id_to_use = yearly_price_details.id
                    yearly_discount_message = "Regular pricing - No discount available"
                
                monthly_equivalent = display_yearly_price / 12
                monthly_savings = 0
                
                if monthly_price_details:
                    monthly_price = monthly_price_details.unit_amount / 100
                    monthly_savings = ((monthly_price * 12) - display_yearly_price) / (monthly_price * 12) * 100
                
                available_plans["yearly"] = {
                    "plan_id": "yearly",
                    "plan_name": "Premium Yearly",
                    "original_price": original_yearly_price,
                    "price": display_yearly_price,
                    "currency": yearly_price_details.currency.upper(),
                    "billing_cycle": "yearly",
                    "stripe_price_id": yearly_price_id_to_use,
                    "monthly_equivalent": round(monthly_equivalent, 2),
                    "savings_percentage": round(monthly_savings, 1) if monthly_savings > 0 else None,
                    "features": [
                        "Unlimited premium scans",
                        "Advanced AI health insights",
                        "Expert nutrition advice",
                        "Priority customer support",
                        "Detailed ingredient analysis",
                        "Health condition recommendations",
                        "Dietary preference tracking",
                        "Allergen alerts",
                        # "Save up to 20% compared to monthly"
                    ],
                    "discount_eligible": get_comprehensive_discount_info(user)['yearly_discount']['eligible'],
                    "discount_percentage": get_comprehensive_discount_info(user)['yearly_discount']['discount_percentage'],
                    "days_remaining_for_discount": get_comprehensive_discount_info(user)['yearly_discount']['days_remaining'],
                    "discount_message": f" 58.3% OFF - Early bird yearly offer! ({get_comprehensive_discount_info(user)['yearly_discount']['days_remaining']} days left)" if get_comprehensive_discount_info(user)['yearly_discount']['eligible'] else "Regular pricing - No discount available"
                }
            
            user_info = {
                "user_id": user.id,
                "email": user.email,
                "full_name": user.full_name,
                "has_stripe_customer": False,
                "stripe_customer_id": None
            }
            
            usage_info = {
                "scans_used": 0,
                "scans_limit": 6,
                "can_scan": True,
                "days_remaining": None
            }
            
            response_data = {
                "current_subscription": current_plan,
                "available_plans": available_plans,
                "user_info": user_info,
                "usage_info": usage_info,
                "stripe_config": {
                    # "publishable_key": getattr(settings, 'STRIPE_PUBLISHABLE_KEY', None),
                    "monthly_price_id": settings.STRIPE_MONTHLY_PRICE_ID,
                    "yearly_price_id": settings.STRIPE_YEARLY_PRICE_ID,
                    "yearly_discounted_price_id": settings.STRIPE_YEARLY_DISCOUNTED_PRICE_ID,
                },
                "discount_info": get_comprehensive_discount_info(user),
                "subscription_benefits": {
                    "freemium": {
                        "scan_limit": 6,
                        "ai_insights": False,
                        "priority_support": False,
                        "advanced_features": False
                    },
                    "premium": {
                        "scan_limit": "unlimited",
                        "ai_insights": True,
                        "priority_support": True,
                        "advanced_features": True
                    }
                }
            }
            
            return Response(response_data, status=status.HTTP_200_OK)


@csrf_exempt
def stripe_webhook_view(request):
    payload = request.body
    sig_header = request.META.get('HTTP_STRIPE_SIGNATURE')
    endpoint_secret = settings.STRIPE_WEBHOOK_SECRET  # Add this in your settings

    try:
        event = stripe.Webhook.construct_event(payload, sig_header, endpoint_secret)
    except (ValueError, stripe.error.SignatureVerificationError):
        return HttpResponse(status=400)

    event_type = event["type"]
    data_object = event["data"]["object"]

    if event_type in ["customer.subscription.updated", "customer.subscription.deleted"]:
        customer_id = data_object.get("customer")
        status = data_object.get("status")

        try:
            stripe_customer = StripeCustomer.objects.get(stripe_customer_id=customer_id)
            user_subscription = UserSubscription.objects.get(user=stripe_customer.user)

            if event_type == "customer.subscription.updated":
                old_status = user_subscription.status
                user_subscription.status = status
                
                # Update subscription dates from Stripe data
                from datetime import datetime
                
                if 'current_period_start' in data_object and data_object['current_period_start']:
                    user_subscription.started_at = datetime.fromtimestamp(data_object['current_period_start'], tz=timezone.utc)
                
                if 'current_period_end' in data_object and data_object['current_period_end']:
                    user_subscription.current_period_end = datetime.fromtimestamp(data_object['current_period_end'], tz=timezone.utc)
                
                # Send notification based on status change
                from .tasks import send_subscription_notification_task_celery, safe_execute_task
                
                # Only send notification for renewals, not for initial subscription creation
                # Initial subscription notifications are sent from the API response
                if status == "active" and old_status != "active" and old_status != "incomplete":
                    # This is a renewal, not a new subscription
                    safe_execute_task(
                        send_subscription_notification_task_celery,
                        stripe_customer.user.id,
                        'subscription_renewed',
                        plan_type=f"{user_subscription.premium_type.capitalize()} Premium" if user_subscription.premium_type else "Premium"
                    )
                elif status in ["canceled", "unpaid", "past_due"] and old_status == "active":
                    safe_execute_task(
                        send_subscription_notification_task_celery,
                        stripe_customer.user.id,
                        'subscription_expired',
                        plan_type=f"{user_subscription.premium_type.capitalize()} Premium" if user_subscription.premium_type else "Premium"
                    )
                    
            elif event_type == "customer.subscription.deleted":
                # If subscription was canceled_at_period_end, now it's actually canceled
                if user_subscription.status == "canceled_at_period_end":
                    # Switch to freemium plan
                    user_subscription.plan_name = "freemium"
                    user_subscription.premium_type = None
                    user_subscription.status = "canceled"
                    user_subscription.stripe_subscription_id = None
                    user_subscription.current_period_end = None
                    
                    # Send downgrade notification
                    from .tasks import send_subscription_notification_task_celery, safe_execute_task
                    safe_execute_task(
                        send_subscription_notification_task_celery,
                        stripe_customer.user.id,
                        'subscription_downgraded',
                        plan_type="Freemium"
                    )
                else:
                    user_subscription.status = "canceled"
                    
                    # Send cancellation notification
                    from .tasks import send_subscription_notification_task_celery, safe_execute_task
                    safe_execute_task(
                        send_subscription_notification_task_celery,
                        stripe_customer.user.id,
                        'subscription_expired',
                        plan_type=f"{user_subscription.premium_type.capitalize()} Premium" if user_subscription.premium_type else "Premium"
                    )

            user_subscription.save()
        except (StripeCustomer.DoesNotExist, UserSubscription.DoesNotExist):
            pass

    return HttpResponse(status=200)

openai.api_key = "OPENAI_API_KEY_REMOVED"

# class IngredientLLMView(APIView):
#     def get(self, request):
#         ingredient = request.query_params.get('ingredient')
#         if not ingredient:
#             return Response({'error': 'Missing "ingredient" query parameter.'}, status=status.HTTP_400_BAD_REQUEST)
        
#         data = fetch_llm_insight(ingredient)
#         return Response(data)
    
class IngredientLLMView(APIView):
    # Add class-level caching for better performance
    _cache = {}
    _cache_ttl = 3600  # 1 hour cache
    
    def get(self, request):
        ingredient = request.query_params.get('ingredient')
        if not ingredient:
            return Response({'error': 'Missing "ingredient" query parameter.'}, status=status.HTTP_400_BAD_REQUEST)
        
        # Check cache first
        cache_key = f"ingredient_llm_{ingredient.lower().strip()}"
        cached_result = self._get_cached_result(cache_key)
        if cached_result:
            return Response(cached_result, status=status.HTTP_200_OK)
        
        try:
            # Get comprehensive regulatory data using the same system as IngredientFullDataView
            regulatory_data = self._get_comprehensive_regulatory_data(ingredient)
            
            # Cache the result
            self._cache_result(cache_key, regulatory_data)
            
            return Response(regulatory_data, status=status.HTTP_200_OK)
            
        except Exception as e:
            print(f"Error in IngredientLLMView: {e}")
            return Response({
                'error': 'Failed to fetch ingredient data',
                'details': str(e)
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
    
    def _get_cached_result(self, cache_key):
        """Get cached result if available and not expired"""
        if cache_key in self._cache:
            cached_data, timestamp = self._cache[cache_key]
            if time.time() - timestamp < self._cache_ttl:
                return cached_data
            else:
                del self._cache[cache_key]
        return None
    
    def _cache_result(self, cache_key, data):
        """Cache the result with timestamp"""
        self._cache[cache_key] = (data, time.time())
    
    def _get_comprehensive_regulatory_data(self, ingredient):
        """Get comprehensive regulatory data for ingredient"""
        try:
            # Use ThreadPoolExecutor for parallel API calls
            with ThreadPoolExecutor(max_workers=6) as executor:
                futures = {
                    'fda': executor.submit(lambda: self._get_fda_regulatory_data(ingredient)),
                    'efsa': executor.submit(lambda: self._get_efsa_regulatory_data(ingredient)),
                    'who': executor.submit(lambda: self._get_who_regulatory_data(ingredient)),
                    'llm': executor.submit(lambda: self._get_llm_insight_enhanced(ingredient)),
                    'image': executor.submit(lambda: self._get_unsplash_image_fast(ingredient)),
                    'enforcement': executor.submit(lambda: self._get_fda_enforcement_data(ingredient))
                }
                
                # Wait for all futures with timeout
                results = {}
                for key, future in futures.items():
                    try:
                        results[key] = future.result(timeout=8)
                    except Exception as e:
                        print(f"Error fetching {key} data: {e}")
                        results[key] = None
                
                # Combine all regulatory data
                combined_data = self._combine_regulatory_data(ingredient, results)
                return combined_data
                
        except Exception as e:
            print(f"Error in comprehensive regulatory data fetch: {e}")
            # Fallback to basic LLM insight
            return self._get_fallback_data(ingredient)
    
    def _get_fda_regulatory_data(self, ingredient):
        """Get FDA regulatory data for ingredient"""
        try:
            # First check if it's a common food ingredient that's generally safe
            common_safe_foods = [
                'peanuts', 'almonds', 'walnuts', 'cashews', 'hazelnuts', 'pecans', 'pistachios',
                'milk', 'eggs', 'wheat', 'soy', 'fish', 'shellfish', 'chicken', 'beef', 'pork',
                'rice', 'corn', 'potatoes', 'tomatoes', 'onions', 'garlic', 'salt', 'sugar',
                'olive oil', 'coconut oil', 'butter', 'cheese', 'yogurt', 'bread', 'pasta'
            ]
            
            ingredient_lower = ingredient.lower().strip()
            if ingredient_lower in common_safe_foods:
                return {
                    "regulatory_feedback": {
                        "GRAS": ["United States (FDA)"],
                        "Restricted": {},
                        "Non_Compliant": "None"
                    },
                    "Restrictions": {},
                    "Violations": "None",
                    "Why_Restricted": "None",
                    "Alternatives": "None",
                    "additional_info": {
                        "alternative_names": [ingredient],
                        "risk_safety_insight": "Generally Recognized as Safe by FDA - common food ingredient",
                        "dishes": ["Various food products"],
                        "history": "Approved for use in food by FDA"
                    }
                }
            
            # FDA GRAS database search for other ingredients
            url = f"https://api.fda.gov/food/gras.json?search=substance_name:{ingredient}&limit=10"
            response = requests.get(url, timeout=5)
            
            if response.status_code == 200:
                data = response.json()
                results = data.get('results', [])
                
                if results:
                    # Found in FDA GRAS database
                    return {
                        "regulatory_feedback": {
                            "GRAS": ["United States (FDA)"],
                            "Restricted": {},
                            "Non_Compliant": "None"
                        },
                        "Restrictions": {},
                        "Violations": "None",
                        "Why_Restricted": "None",
                        "Alternatives": "None",
                        "additional_info": {
                            "alternative_names": [ingredient],
                            "risk_safety_insight": "Generally Recognized as Safe by FDA",
                            "dishes": ["Various food products"],
                            "history": "Approved for use in food by FDA"
                        }
                    }
            
            return None
            
        except Exception as e:
            print(f"FDA API error: {e}")
            return None
    
    def _get_fda_enforcement_data(self, ingredient):
        """Get FDA enforcement data for ingredient - only for actual violations"""
        try:
            # Skip enforcement check for common safe foods
            common_safe_foods = [
                'peanuts', 'almonds', 'walnuts', 'cashews', 'hazelnuts', 'pecans', 'pistachios',
                'milk', 'eggs', 'wheat', 'soy', 'fish', 'shellfish', 'chicken', 'beef', 'pork',
                'rice', 'corn', 'potatoes', 'tomatoes', 'onions', 'garlic', 'salt', 'sugar',
                'olive oil', 'coconut oil', 'butter', 'cheese', 'yogurt', 'bread', 'pasta'
            ]
            
            ingredient_lower = ingredient.lower().strip()
            if ingredient_lower in common_safe_foods:
                return None  # Skip enforcement check for common safe foods
            
            # Check FDA enforcement database for violations
            enforcement_url = f"https://api.fda.gov/food/enforcement.json?search=product_description:{ingredient}&limit=5"
            enforcement_response = requests.get(enforcement_url, timeout=5)
            
            if enforcement_response.status_code == 200:
                enforcement_data = enforcement_response.json()
                violations = enforcement_data.get('results', [])
                
                if violations:
                    return {
                        "regulatory_feedback": {
                            "GRAS": [],
                            "Restricted": {"United States": "FDA enforcement actions"},
                            "Non_Compliant": "United States (FDA)"
                        },
                        "Restrictions": {"United States": "FDA enforcement actions"},
                        "Violations": f"FDA enforcement actions: {len(violations)} cases",
                        "Why_Restricted": "FDA enforcement actions due to safety concerns",
                        "Alternatives": "Consult FDA for approved alternatives",
                        "additional_info": {
                            "alternative_names": [ingredient],
                            "risk_safety_insight": "Subject to FDA enforcement actions",
                            "dishes": ["Various food products"],
                            "history": "Has FDA enforcement history"
                        }
                    }
            
            return None
            
        except Exception as e:
            print(f"FDA Enforcement API error: {e}")
            return None
    
    def _get_efsa_regulatory_data(self, ingredient):
        """Get EFSA regulatory data for ingredient"""
        try:
            # Check if it's a common food ingredient
            common_safe_foods = [
                'peanuts', 'almonds', 'walnuts', 'cashews', 'hazelnuts', 'pecans', 'pistachios',
                'milk', 'eggs', 'wheat', 'soy', 'fish', 'shellfish', 'chicken', 'beef', 'pork',
                'rice', 'corn', 'potatoes', 'tomatoes', 'onions', 'garlic', 'salt', 'sugar',
                'olive oil', 'coconut oil', 'butter', 'cheese', 'yogurt', 'bread', 'pasta'
            ]
            
            ingredient_lower = ingredient.lower().strip()
            if ingredient_lower in common_safe_foods:
                return {
                    "regulatory_feedback": {
                        "GRAS": ["European Union (EFSA)"],
                        "Restricted": {},
                        "Non_Compliant": "None"
                    },
                    "Restrictions": {},
                    "Violations": "None",
                    "Why_Restricted": "None",
                    "Alternatives": "None",
                    "additional_info": {
                        "alternative_names": [ingredient],
                        "risk_safety_insight": "Approved by European Food Safety Authority - common food ingredient",
                        "dishes": ["Various food products"],
                        "history": "Approved for use in food by EFSA"
                    }
                }
            
            # Try EFSA API for other ingredients
            efsa_data = fetch_efsa_openfoodtox_data(ingredient)
            if efsa_data and efsa_data.get('found'):
                return {
                    "regulatory_feedback": {
                        "GRAS": ["European Union (EFSA)"],
                        "Restricted": {},
                        "Non_Compliant": "None"
                    },
                    "Restrictions": {},
                    "Violations": "None",
                    "Why_Restricted": "None",
                    "Alternatives": "None",
                    "additional_info": {
                        "alternative_names": [ingredient],
                        "risk_safety_insight": "Approved by European Food Safety Authority",
                        "dishes": ["Various food products"],
                        "history": "Approved for use in food by EFSA"
                    }
                }
            return None
            
        except Exception as e:
            print(f"EFSA API error: {e}")
            return None
    
    def _get_who_regulatory_data(self, ingredient):
        """Get WHO regulatory data for ingredient"""
        try:
            # Check if it's a common food ingredient
            common_safe_foods = [
                'peanuts', 'almonds', 'walnuts', 'cashews', 'hazelnuts', 'pecans', 'pistachios',
                'milk', 'eggs', 'wheat', 'soy', 'fish', 'shellfish', 'chicken', 'beef', 'pork',
                'rice', 'corn', 'potatoes', 'tomatoes', 'onions', 'garlic', 'salt', 'sugar',
                'olive oil', 'coconut oil', 'butter', 'cheese', 'yogurt', 'bread', 'pasta'
            ]
            
            ingredient_lower = ingredient.lower().strip()
            if ingredient_lower in common_safe_foods:
                return {
                    "regulatory_feedback": {
                        "GRAS": ["Global (WHO)"],
                        "Restricted": {},
                        "Non_Compliant": "None"
                    },
                    "Restrictions": {},
                    "Violations": "None",
                    "Why_Restricted": "None",
                    "Alternatives": "None",
                    "additional_info": {
                        "alternative_names": [ingredient],
                        "risk_safety_insight": "Generally recognized as safe by WHO - common food ingredient",
                        "dishes": ["Various food products"],
                        "history": "Recognized as safe by WHO"
                    }
                }
            
            # For other ingredients, return basic WHO recognition
            return {
                "regulatory_feedback": {
                    "GRAS": ["Global (WHO)"],
                    "Restricted": {},
                    "Non_Compliant": "None"
                },
                "Restrictions": {},
                "Violations": "None",
                "Why_Restricted": "None",
                "Alternatives": "None",
                "additional_info": {
                    "alternative_names": [ingredient],
                    "risk_safety_insight": "Generally recognized as safe by WHO",
                    "dishes": ["Various food products"],
                    "history": "Recognized as safe by WHO"
                }
            }
            
        except Exception as e:
            print(f"WHO data error: {e}")
            return None
    
    def _get_llm_insight_enhanced(self, ingredient):
        """Get enhanced LLM insight with regulatory focus"""
        try:
            prompt = f"""
            You are a certified food scientist and global food regulation expert.

            Return ONLY valid JSON. Do NOT leave any field empty. Use double quotes.

            For the ingredient "{ingredient}", return structured JSON in the following format:

            {{
              "regulatory_feedback": {{
                "GRAS": ["countries or organizations where Generally Recognized as Safe or 'None'"],
                "Restricted": {{
                  "Country Name": "Reason for restriction or 'None'"
                }},
                "Non_Compliant": "Countries or regulations it doesn't comply with or 'None'"
              }},
              "Restrictions": {{
                "Country Name": "Restriction reason or 'None'"
              }},
              "Violations": "Mention past violations or write 'None'",
              "Why_Restricted": "Reason it is restricted or 'None'",
              "Alternatives": "Safe substitutes or 'None'",
              "additional_info": {{
                "alternative_names": ["List of synonyms or 'Unknown'"],
                "risk_safety_insight": "Health and safety summary or 'Unknown'",
                "dishes": ["Popular dishes or 'Unknown'"],
                "history": "Short history or 'Unknown'",
                "common_uses": ["Common uses in food products"]
              }}
            }}

            IMPORTANT: 
            - For common food ingredients like peanuts, almonds, milk, eggs, etc., they are generally GRAS
            - Only report actual restrictions or violations, not general food safety guidelines
            - Focus on providing accurate, up-to-date regulatory information from FDA, EFSA, WHO, Health Canada, FSANZ, and Codex
            - Be conservative - when in doubt, mark as GRAS rather than restricted
            Respond only with JSON.
            """

            response = openai.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3
            )
            content = response.choices[0].message.content.strip()

            try:
                parsed_json = json.loads(content)
                return parsed_json
            except json.JSONDecodeError:
                return {
                    "error": "Failed to parse JSON response from OpenAI",
                    "raw_output": content
                }

        except Exception as e:
            print(f"LLM insight error: {e}")
            return None
    
    def _get_unsplash_image_fast(self, ingredient):
        """Get image from Unsplash with timeout"""
        try:
            unsplash_url = f"https://api.unsplash.com/search/photos?query={ingredient}&client_id={UNSPLASH_ACCESS_KEY}"
            image_resp = requests.get(unsplash_url, timeout=3)

            if image_resp.status_code == 200:
                data = image_resp.json()
                if data["results"]:
                    return data["results"][0]["urls"]["regular"]
            return None
            
        except Exception as e:
            print(f"Unsplash API error: {e}")
            return None
    
    def _combine_regulatory_data(self, ingredient, results):
        """Combine all regulatory data sources into comprehensive response"""
        # Initialize combined data structure
        combined_data = {
            "ingredient": ingredient,
            "regulatory_feedback": {
                "GRAS": [],
                "Restricted": {},
                "Non_Compliant": "None"
            },
            "Restrictions": {},
            "Violations": "None",
            "Why_Restricted": "None",
            "Alternatives": "None",
            "additional_info": {
                "alternative_names": [ingredient],
                "risk_safety_insight": "No regulatory data available",
                "dishes": ["Unknown"],
                "history": "No regulatory history available",
                "common_uses": ["Various food products"]
            },
            "regulatory_sources": ["FDA", "EFSA", "WHO", "Health Canada", "FSANZ", "Codex"],
            "image_url": None,
            "overview": "No regulatory data available",
            "regulatory_compliance": {
                "Safe": [],
                "Approved_In": [],
                "Caution": [],
                "Regulated_In": [],
                "Regulation_Violations": "None",
                "Why_Restricted": "None"
            }
        }
        
        # Process FDA data
        fda_data = results.get('fda')
        if fda_data and isinstance(fda_data, dict):
            fda_reg = fda_data.get('regulatory_feedback', {})
            combined_data['regulatory_feedback']['GRAS'].extend(fda_reg.get('GRAS', []))
            combined_data['regulatory_feedback']['Restricted'].update(fda_reg.get('Restricted', {}))
            if fda_reg.get('Non_Compliant') != "None":
                combined_data['regulatory_feedback']['Non_Compliant'] = fda_reg.get('Non_Compliant')
            
            combined_data['Restrictions'].update(fda_data.get('Restrictions', {}))
            if fda_data.get('Violations') != "None":
                combined_data['Violations'] = fda_data.get('Violations')
            if fda_data.get('Why_Restricted') != "None":
                combined_data['Why_Restricted'] = fda_data.get('Why_Restricted')
            if fda_data.get('Alternatives') != "None":
                combined_data['Alternatives'] = fda_data.get('Alternatives')
            
            fda_info = fda_data.get('additional_info', {})
            combined_data['additional_info']['alternative_names'].extend(fda_info.get('alternative_names', []))
            if fda_info.get('risk_safety_insight') != "No regulatory data available":
                combined_data['additional_info']['risk_safety_insight'] = fda_info.get('risk_safety_insight')
            combined_data['additional_info']['dishes'].extend(fda_info.get('dishes', []))
            if fda_info.get('history') != "No regulatory history available":
                combined_data['additional_info']['history'] = fda_info.get('history')
        
        # Process FDA enforcement data (only if it exists and is not overridden by GRAS status)
        enforcement_data = results.get('enforcement')
        if enforcement_data and isinstance(enforcement_data, dict) and not combined_data['regulatory_feedback']['GRAS']:
            enforcement_reg = enforcement_data.get('regulatory_feedback', {})
            combined_data['regulatory_feedback']['GRAS'].extend(enforcement_reg.get('GRAS', []))
            combined_data['regulatory_feedback']['Restricted'].update(enforcement_reg.get('Restricted', {}))
            if enforcement_reg.get('Non_Compliant') != "None":
                combined_data['regulatory_feedback']['Non_Compliant'] = enforcement_reg.get('Non_Compliant')
            
            combined_data['Restrictions'].update(enforcement_data.get('Restrictions', {}))
            if enforcement_data.get('Violations') != "None":
                combined_data['Violations'] = enforcement_data.get('Violations')
            if enforcement_data.get('Why_Restricted') != "None":
                combined_data['Why_Restricted'] = enforcement_data.get('Why_Restricted')
            if enforcement_data.get('Alternatives') != "None":
                combined_data['Alternatives'] = enforcement_data.get('Alternatives')
            
            enforcement_info = enforcement_data.get('additional_info', {})
            if enforcement_info.get('risk_safety_insight') != "No regulatory data available":
                combined_data['additional_info']['risk_safety_insight'] = enforcement_info.get('risk_safety_insight')
            if enforcement_info.get('history') != "No regulatory history available":
                combined_data['additional_info']['history'] = enforcement_info.get('history')
        
        # Process EFSA data
        efsa_data = results.get('efsa')
        if efsa_data and isinstance(efsa_data, dict):
            efsa_reg = efsa_data.get('regulatory_feedback', {})
            combined_data['regulatory_feedback']['GRAS'].extend(efsa_reg.get('GRAS', []))
            combined_data['regulatory_feedback']['Restricted'].update(efsa_reg.get('Restricted', {}))
            if efsa_reg.get('Non_Compliant') != "None":
                combined_data['regulatory_feedback']['Non_Compliant'] = efsa_reg.get('Non_Compliant')
            
            combined_data['Restrictions'].update(efsa_data.get('Restrictions', {}))
            if efsa_data.get('Violations') != "None":
                combined_data['Violations'] = efsa_data.get('Violations')
            if efsa_data.get('Why_Restricted') != "None":
                combined_data['Why_Restricted'] = efsa_data.get('Why_Restricted')
            if efsa_data.get('Alternatives') != "None":
                combined_data['Alternatives'] = efsa_data.get('Alternatives')
            
            efsa_info = efsa_data.get('additional_info', {})
            combined_data['additional_info']['alternative_names'].extend(efsa_info.get('alternative_names', []))
            if efsa_info.get('risk_safety_insight') != "No regulatory data available":
                combined_data['additional_info']['risk_safety_insight'] = efsa_info.get('risk_safety_insight')
            combined_data['additional_info']['dishes'].extend(efsa_info.get('dishes', []))
            if efsa_info.get('history') != "No regulatory history available":
                combined_data['additional_info']['history'] = efsa_info.get('history')
        
        # Process WHO data
        who_data = results.get('who')
        if who_data and isinstance(who_data, dict):
            who_reg = who_data.get('regulatory_feedback', {})
            combined_data['regulatory_feedback']['GRAS'].extend(who_reg.get('GRAS', []))
            combined_data['regulatory_feedback']['Restricted'].update(who_reg.get('Restricted', {}))
            if who_reg.get('Non_Compliant') != "None":
                combined_data['regulatory_feedback']['Non_Compliant'] = who_reg.get('Non_Compliant')
            
            combined_data['Restrictions'].update(who_data.get('Restrictions', {}))
            if who_data.get('Violations') != "None":
                combined_data['Violations'] = who_data.get('Violations')
            if who_data.get('Why_Restricted') != "None":
                combined_data['Why_Restricted'] = who_data.get('Why_Restricted')
            if who_data.get('Alternatives') != "None":
                combined_data['Alternatives'] = who_data.get('Alternatives')
            
            who_info = who_data.get('additional_info', {})
            combined_data['additional_info']['alternative_names'].extend(who_info.get('alternative_names', []))
            if who_info.get('risk_safety_insight') != "No regulatory data available":
                combined_data['additional_info']['risk_safety_insight'] = who_info.get('risk_safety_insight')
            combined_data['additional_info']['dishes'].extend(who_info.get('dishes', []))
            if who_info.get('history') != "No regulatory history available":
                combined_data['additional_info']['history'] = who_info.get('history')
        
        # Process LLM data
        llm_data = results.get('llm')
        if llm_data and isinstance(llm_data, dict) and 'error' not in llm_data:
            llm_reg = llm_data.get('regulatory_feedback', {})
            combined_data['regulatory_feedback']['GRAS'].extend(llm_reg.get('GRAS', []))
            combined_data['regulatory_feedback']['Restricted'].update(llm_reg.get('Restricted', {}))
            if llm_reg.get('Non_Compliant') != "None":
                combined_data['regulatory_feedback']['Non_Compliant'] = llm_reg.get('Non_Compliant')
            
            combined_data['Restrictions'].update(llm_data.get('Restrictions', {}))
            if llm_data.get('Violations') != "None":
                combined_data['Violations'] = llm_data.get('Violations')
            if llm_data.get('Why_Restricted') != "None":
                combined_data['Why_Restricted'] = llm_data.get('Why_Restricted')
            if llm_data.get('Alternatives') != "None":
                combined_data['Alternatives'] = llm_data.get('Alternatives')
            
            llm_info = llm_data.get('additional_info', {})
            combined_data['additional_info']['alternative_names'].extend(llm_info.get('alternative_names', []))
            if llm_info.get('risk_safety_insight') != "Unknown":
                combined_data['additional_info']['risk_safety_insight'] = llm_info.get('risk_safety_insight')
            combined_data['additional_info']['dishes'].extend(llm_info.get('dishes', []))
            if llm_info.get('history') != "Unknown":
                combined_data['additional_info']['history'] = llm_info.get('history')
            if llm_info.get('common_uses'):
                combined_data['additional_info']['common_uses'] = llm_info.get('common_uses')
        
        # Add image URL
        if results.get('image'):
            combined_data['image_url'] = results.get('image')
        
        # Clean up and deduplicate data
        combined_data['regulatory_feedback']['GRAS'] = list(set(combined_data['regulatory_feedback']['GRAS']))
        combined_data['additional_info']['alternative_names'] = list(set(combined_data['additional_info']['alternative_names']))
        combined_data['additional_info']['dishes'] = list(set(combined_data['additional_info']['dishes']))
        
        # Generate overview
        if combined_data['regulatory_feedback']['GRAS']:
            combined_data['overview'] = "Generally Recognized as Safe (GRAS) in multiple jurisdictions"
        elif combined_data['regulatory_feedback']['Restricted']:
            combined_data['overview'] = "Has usage restrictions in some jurisdictions"
        elif combined_data['Violations'] != "None":
            combined_data['overview'] = "Has FDA enforcement history"
        else:
            combined_data['overview'] = "Limited regulatory data available"
        
        # Populate regulatory compliance section
        combined_data['regulatory_compliance'] = {
            'Safe': combined_data['regulatory_feedback']['GRAS'],
            'Approved_In': combined_data['regulatory_feedback']['GRAS'],
            'Caution': list(combined_data['regulatory_feedback']['Restricted'].keys()) if combined_data['regulatory_feedback']['Restricted'] else [],
            'Regulated_In': list(combined_data['regulatory_feedback']['Restricted'].keys()) if combined_data['regulatory_feedback']['Restricted'] else [],
            'Regulation_Violations': combined_data['Violations'],
            'Why_Restricted': combined_data['Why_Restricted']
        }
        
        return combined_data
    
    def _get_fallback_data(self, ingredient):
        """Get fallback data when comprehensive fetch fails"""
        return {
            "ingredient": ingredient,
            "regulatory_feedback": {
                "GRAS": [],
                "Restricted": {},
                "Non_Compliant": "None"
            },
            "Restrictions": {},
            "Violations": "None",
            "Why_Restricted": "None",
            "Alternatives": "None",
            "additional_info": {
                "alternative_names": [ingredient],
                "risk_safety_insight": "Limited regulatory data available",
                "dishes": ["Various food products"],
                "history": "Limited regulatory history available",
                "common_uses": ["Various food products"]
            },
            "regulatory_sources": ["FDA", "EFSA", "WHO", "Health Canada", "FSANZ", "Codex"],
            "image_url": None,
            "overview": "Limited regulatory data available",
            "regulatory_compliance": {
                "Safe": [],
                "Approved_In": [],
                "Caution": [],
                "Regulated_In": [],
                "Regulation_Violations": "None",
                "Why_Restricted": "None"
            },
            "error": "Comprehensive regulatory data unavailable, showing limited information"
        }
class SettingsView(APIView):
    permission_classes = [IsAuthenticated]

    def get(self, request):
        serializer = UserSettingsSerializer(request.user)
        
        # Get accurate scan count that automatically syncs with actual FoodLabelScan objects
        accurate_scan_count = get_accurate_scan_count(request.user)
        
        # Calculate remaining scans based on accurate count
        subscription = None
        try:
            subscription = UserSubscription.objects.get(user=request.user)
        except UserSubscription.DoesNotExist:
            pass
        
        remaining_scans = None
        if not subscription or subscription.plan_name.strip().lower() == "freemium":
            remaining_scans = max(0, 20 - accurate_scan_count)
        
        data = serializer.data
        data['scan_count'] = accurate_scan_count
        data['remaining_scans'] = remaining_scans
        
        # Add comprehensive discount eligibility information
        comprehensive_discount_info = get_comprehensive_discount_info(request.user)
        data['discount_eligibility'] = comprehensive_discount_info
        
        return Response(data)


class SubscriptionPricesView(APIView):
    """
    API endpoint to get all subscription plan prices from Stripe.
    """
    permission_classes = [IsAuthenticated]

    def get(self, request):
        """
        Get all available subscription plans with their current prices from Stripe.
        """
        try:
            # Get all subscription prices
            prices = get_subscription_prices(user=request.user)
            
            # Add comprehensive discount eligibility info
            comprehensive_discount_info = get_comprehensive_discount_info(request.user)
            
            return Response({
                'success': True,
                'prices': prices,
                'discount_eligibility': comprehensive_discount_info,
                'available_plans': list(prices.keys()),
                'stripe_config': {
                    'publishable_key': getattr(settings, 'STRIPE_PUBLISHABLE_KEY', None),
                    'monthly_price_id': settings.STRIPE_MONTHLY_PRICE_ID,
                    'yearly_price_id': settings.STRIPE_YEARLY_PRICE_ID,
                    'yearly_discounted_price_id': settings.STRIPE_YEARLY_DISCOUNTED_PRICE_ID,
                }
            }, status=status.HTTP_200_OK)
            
        except Exception as e:
            return Response({
                'error': f'Failed to get subscription prices: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class DiscountEligibilityView(APIView):
    """
    API endpoint to check if a user is eligible for the new user discount.
    """
    permission_classes = [IsAuthenticated]

    def get(self, request):
        user = request.user
        comprehensive_discount_info = get_comprehensive_discount_info(user)
        
        return Response({
            "user_id": user.id,
            "email": user.email,
            "signup_date": user.date_joined.isoformat(),
            "discount_eligibility": comprehensive_discount_info,
            "message": comprehensive_discount_info['primary_message']
        }, status=status.HTTP_200_OK)


class SyncScanCountsView(APIView):
    """
    API endpoint to sync all users' scan counts with their actual FoodLabelScan objects.
    This should be called after deleting scans from admin panel.
    """
    permission_classes = [IsAuthenticated, IsAdminUser]

    def post(self, request):
        try:
            synced_count = sync_all_user_scan_counts()
            return Response({
                "message": f"Successfully synced scan counts for {synced_count} users",
                "synced_users": synced_count
            }, status=status.HTTP_200_OK)
        except Exception as e:
            return Response({
                "error": f"Failed to sync scan counts: {str(e)}"
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    def put(self, request):
        serializer = UserSettingsSerializer(request.user, data=request.data, partial=True)
        if serializer.is_valid():
            serializer.save()
            return Response({"status": "updated", "data": serializer.data})
        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

class ProductComparisonView(APIView):
    permission_classes = [IsAuthenticated]
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        try:
            aws_access_key = settings.AWS_ACCESS_KEY_ID
            aws_secret_key = settings.AWS_SECRET_ACCESS_KEY
            aws_region = settings.AWS_S3_REGION_NAME or 'us-east-1'
            if not aws_access_key or not aws_secret_key:
                logging.error("AWS credentials not found in settings")
                self.textract_client = None
                return
            self.textract_client = boto3.client(
                'textract',
                aws_access_key_id=aws_access_key,
                aws_secret_access_key=aws_secret_key,
                region_name=aws_region
            )
            print("AWS Textract client initialized successfully for ProductComparisonView")
        except Exception as e:
            logging.error(f"Failed to initialize AWS Textract client: {e}")
            self.textract_client = None

    def post(self, request):
        # Get the two products to compare
        product1_id = request.data.get('product1_id')  # From history
        product2_id = request.data.get('product2_id')  # From history or None for new scan
        new_product_image = request.data.get('new_product_image')  # If product2 is a new scan

        if not product1_id:
            return Response({"error": "Product 1 ID is required"}, status=status.HTTP_400_BAD_REQUEST)

        try:
            # Get first product from history
            product1 = FoodLabelScan.objects.get(id=product1_id, user=request.user)
            
            # Handle second product
            if product2_id:
                # Get second product from history
                product2 = FoodLabelScan.objects.get(id=product2_id, user=request.user)
            elif new_product_image:
                # Process new product scan
                serializer = AllergenDietaryCheckSerializer(data={'image': new_product_image})
                if not serializer.is_valid():
                    return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)
                
                # Save image
                image_content = new_product_image.read()
                image_name = f"food_labels/{uuid.uuid4()}.jpg"
                image_path = default_storage.save(image_name, ContentFile(image_content))
                image_url = default_storage.url(image_path)
                # Clean up the URL if needed
                if isinstance(image_url, str):
                    image_url = image_url.replace("https//", "")

                # Try barcode scanning first
                with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as temp_file:
                    temp_file.write(image_content)
                    temp_file_path = temp_file.name

                try:
                    # Barcode detection
                    image_cv = cv2.imread(temp_file_path)
                    if image_cv is not None:
                        gray = cv2.cvtColor(image_cv, cv2.COLOR_BGR2GRAY)
                        blur = cv2.GaussianBlur(gray, (5, 5), 0)
                        thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]

                        barcode_detector = cv2.barcode_BarcodeDetector()
                        ok, decoded_info, decoded_type = barcode_detector.detectAndDecode(thresh)

                        if not ok or decoded_info is None or len(decoded_info) == 0:
                            # Try with original image if thresholded image fails
                            ok, decoded_info, decoded_type = barcode_detector.detectAndDecode(image_cv)

                        if ok and decoded_info and len(decoded_info) > 0:
                            # Barcode found, fetch product info from OpenFoodFacts
                            barcode = decoded_info[0]
                            response = requests.get(f"https://world.openfoodfacts.org/api/v0/product/{ok}.json")
                            
                            if response.status_code == 200:
                                product = response.json()
                                if product.get("product") and product["product"].get("product_name"):
                                    product_data = product["product"]
                                    extracted_text = product_data.get('ingredients_text', '')
                                    raw_nutrition_data = product_data.get('nutriments', {})
                                    product_name = product_data.get('product_name', 'Unknown')
                                    product_image_url = product_data.get('image_url', '')
                                    
                                    # Validate product safety
                                    safety_status, go_ingredients, caution_ingredients, no_go_ingredients = asyncio.run(
                                        self.validate_product_safety(request.user, extracted_text)
                                    )

                                    # Get AI insights
                                    ai_results = self.run_in_thread_pool(
                                        self.get_ai_health_insight_and_expert_advice_fast,
                                        request.user,
                                        raw_nutrition_data,
                                        no_go_ingredients
                                    )

                                    # Create product2 object with barcode data
                                    product2 = type('Product', (), {
                                        'image_url': image_url,
                                        'extracted_text': extracted_text,
                                        'nutrition_data': raw_nutrition_data,
                                        'safety_status': safety_status,
                                        'flagged_ingredients': no_go_ingredients,
                                        'product_name': product_name,
                                        'product_image_url': product_image_url
                                    })
                                else:
                                    # Fall back to OCR if product not found
                                    product2 = self.process_image_with_ocr(image_content, image_url, request.user)
                            else:
                                # Fall back to OCR if API call fails
                                product2 = self.process_image_with_ocr(image_content, image_url, request.user)
                        else:
                            # No barcode found, use OCR
                            product2 = self.process_image_with_ocr(image_content, image_url, request.user)
                    else:
                        # Image reading failed, use OCR
                        product2 = self.process_image_with_ocr(image_content, image_url, request.user)

                finally:
                    if os.path.exists(temp_file_path):
                        os.unlink(temp_file_path)
            else:
                return Response({"error": "Either product2_id or new_product_image is required"}, 
                              status=status.HTTP_400_BAD_REQUEST)

            # Compare the products
            comparison = self.compare_products(product1, product2, request.user)

            return Response(comparison, status=status.HTTP_200_OK)

        except FoodLabelScan.DoesNotExist:
            return Response({"error": "Product not found in history"}, status=status.HTTP_404_NOT_FOUND)
        except Exception as e:
            return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    def process_image_with_ocr(self, image_content, image_url, user):
        # Process image and extract data using AWS Textract
        try:
            if not self.textract_client:
                logging.error("AWS Textract client not initialized")
                return None
                
            # Extract text using AWS Textract
            extracted_text = self.run_ocr(image_content)
            
            # Try to extract ingredients using Query feature first
            query_ingredients = self.extract_ingredients_with_textract_query(image_content)
            
            # Try to extract nutrition using Query feature first
            query_nutrition = self.extract_nutrition_with_textract_query(image_content)
            
            # Process nutrition data (use query results if available, otherwise fallback to text parsing)
            if query_nutrition:
                nutrition_data = self.process_query_nutrition_data(query_nutrition)
            else:
                nutrition_data = self.extract_nutrition_info_fallback(extracted_text)
            
            # Process ingredients data (use query results if available, otherwise fallback to text parsing)
            if query_ingredients:
                actual_ingredients = self.process_query_ingredients(query_ingredients)
            else:
                actual_ingredients = self.extract_ingredients_from_text_fallback(extracted_text)
            
            # Validate product safety
            safety_status, go_ingredients, caution_ingredients, no_go_ingredients = asyncio.run(
                self.validate_product_safety(user, actual_ingredients)
            )

            # Create temporary product2 object
            return type('Product', (), {
                'image_url': image_url,
                'extracted_text': extracted_text,
                'nutrition_data': nutrition_data,
                'safety_status': safety_status,
                'flagged_ingredients': no_go_ingredients
            })
        except Exception as e:
            logging.error(f"Error processing image with AWS Textract: {e}")
            return None

    def preprocess_image(self, image):
        image = image.convert('L')
        image = image.resize((1000, 1000)) if image.size[0] < 1000 or image.size[1] < 1000 else image
        return image

    def run_ocr(self, image_content):
        """
        Run OCR using AWS Textract with fallback to simple text extraction.
        """
        try:
            if not self.textract_client:
                logging.error("AWS Textract client not initialized")
                return ''
            
            # Try Textract Query first for better accuracy
            extracted_text = self.extract_text_with_textract_query(image_content)
            if extracted_text:
                logging.info(f"Extracted text from AWS Textract Query: {extracted_text}")
                return extracted_text
            
            # Fallback to general Textract
            extracted_text = self.extract_text_with_textract(image_content)
            if extracted_text:
                logging.info(f"Extracted text from AWS Textract: {extracted_text}")
                return extracted_text
            
            logging.error("AWS Textract failed to extract text")
            return ''
        except Exception as e:
            logging.error(f"AWS Textract OCR error: {e}", exc_info=True)
            return ''

    def extract_text_with_textract_query(self, image_content):
        """
        Extract text using AWS Textract Query feature with ultra-fast processing.
        """
        try:
            if not self.textract_client:
                return ''
            
            # Quick size check
            if len(image_content) > 3 * 1024 * 1024:  # 3MB limit for speed
                logging.warning("Image too large for fast processing")
                return ''
            
            # Use simple detect_document_text instead of Query for speed
            response = self.textract_client.detect_document_text(
                Document={'Bytes': image_content}
            )
            
            # Fast text extraction
            extracted_text = ""
            for block in response.get('Blocks', []):
                if block['BlockType'] == 'LINE':
                    extracted_text += block['Text'] + "\n"
                if len(extracted_text) > 1000:  # Limit text length for speed
                    break
            
            return extracted_text.strip()
        except Exception as e:
            logging.error(f"Textract extraction error: {e}")
            return ''

    def extract_text_with_textract(self, image_content):
        """
        Extract text using AWS Textract general features.
        """
        try:
            if not self.textract_client:
                return ''
            
            # Try analyze_document with TABLES, FORMS, LINES
            response = self.textract_client.analyze_document(
                Document={'Bytes': image_content},
                FeatureTypes=['TABLES', 'FORMS', 'LINES']
            )
            
            # Extract text from blocks
            extracted_text = ""
            for block in response.get('Blocks', []):
                if block['BlockType'] == 'LINE':
                    extracted_text += block['Text'] + "\n"
            
            if extracted_text.strip():
                return extracted_text.strip()
            
            # Fallback to detect_document_text
            response = self.textract_client.detect_document_text(
                Document={'Bytes': image_content}
            )
            
            extracted_text = ""
            for block in response.get('Blocks', []):
                if block['BlockType'] == 'LINE':
                    extracted_text += block['Text'] + "\n"
            
            return extracted_text.strip()
        except Exception as e:
            logging.error(f"Textract extraction error: {e}")
            return ''

    def extract_ingredients_with_textract_query(self, image_content):
        """
        Extract ingredients using AWS Textract - simplified for speed.
        """
        try:
            if not self.textract_client:
                return []
            
            # Use simple text extraction and parse ingredients from text
            response = self.textract_client.detect_document_text(
                Document={'Bytes': image_content}
            )
            
            # Extract all text first
            full_text = ""
            for block in response.get('Blocks', []):
                if block['BlockType'] == 'LINE':
                    full_text += block['Text'] + "\n"
            
            # Parse ingredients from text
            return self.extract_ingredients_from_text_fallback(full_text)
        except Exception as e:
            logging.error(f"Textract ingredients extraction error: {e}")
            return []

    def extract_nutrition_with_textract_query(self, image_content):
        """
        Extract nutrition data using AWS Textract - simplified for speed.
        """
        try:
            if not self.textract_client:
                return {}
            
            # Quick size check
            if len(image_content) > 3 * 1024 * 1024:
                return {}
            
            # Use simple text extraction and parse nutrition from text
            response = self.textract_client.detect_document_text(
                Document={'Bytes': image_content}
            )
            
            # Extract all text first
            full_text = ""
            for block in response.get('Blocks', []):
                if block['BlockType'] == 'LINE':
                    full_text += block['Text'] + "\n"
            
            # Parse nutrition from text
            return self.extract_nutrition_info_fallback(full_text)
        except Exception as e:
            logging.error(f"Textract nutrition extraction error: {e}")
            return {}

    def process_query_nutrition_data(self, query_nutrition):
        """
        Process nutrition data from Textract Query results.
        """
        nutrition_data = {}
        
        # Map query aliases to nutrition field names
        field_mapping = {
            'energy': 'Energy',
            'total_fat': 'Total Fat',
            'saturated_fat': 'Saturated Fat',
            'cholesterol': 'Cholesterol',
            'sodium': 'Sodium',
            'carbohydrate': 'Carbohydrate',
            'total_sugars': 'Total Sugars',
            'dietary_fibre': 'Dietary Fibre',
            'protein': 'Protein'
        }
        
        for alias, value in query_nutrition.items():
            if alias in field_mapping and value:
                field_name = field_mapping[alias]
                # Try to extract numeric value and unit
                import re
                match = re.search(r'(\d+(?:\.\d+)?)\s*(kcal|g|mg|mcg|%)', value, re.IGNORECASE)
                if match:
                    num_value, unit = match.groups()
                    # Standardize units
                    if unit.lower() in ['kj', 'cal']:
                        unit = 'kcal'
                    elif field_name == 'Energy':
                        unit = 'kcal'
                    elif field_name in ['Sodium', 'Cholesterol']:
                        unit = 'mg'
                    else:
                        unit = 'g'
                    nutrition_data[field_name] = f"{num_value} {unit}"
                else:
                    # If no unit found, try to infer
                    num_match = re.search(r'(\d+(?:\.\d+)?)', value)
                    if num_match:
                        num_value = num_match.group(1)
                        if field_name == 'Energy':
                            nutrition_data[field_name] = f"{num_value} kcal"
                        elif field_name in ['Sodium', 'Cholesterol']:
                            nutrition_data[field_name] = f"{num_value} mg"
                        else:
                            nutrition_data[field_name] = f"{num_value} g"
        
        return nutrition_data

    def process_query_ingredients(self, query_ingredients):
        """
        Process ingredients from Textract Query results.
        """
        if not query_ingredients:
            return []
        
        # Join all ingredient responses and clean them up
        ingredients_text = " ".join(query_ingredients)
        
        # Clean up the ingredients text - preserve important characters
        import re
        ingredients_text = re.sub(r'[^\w\s,()%.&-]', ' ', ingredients_text)
        ingredients_text = re.sub(r'\s+', ' ', ingredients_text)
        
        # Split ingredients by common separators
        ingredients = []
        parts = re.split(r',\s*(?![^()]*\))', ingredients_text)
        
        if len(parts) <= 1:
            parts = re.split(r',\s*', ingredients_text)
        
        for part in parts:
            ingredient = part.strip()
            if ingredient and len(ingredient) > 2:
                ingredient = self.clean_ingredient_text(ingredient)
                if (ingredient and len(ingredient) > 2 and 
                    not re.match(r'^\d+\.?\d*%?$', ingredient) and
                    not ingredient.lower() in ['and', 'or', 'the', 'a', 'an']):
                    
                    split_ingredients = self.split_compound_ingredients(ingredient)
                    for split_ingredient in split_ingredients:
                        if split_ingredient and len(split_ingredient) > 2:
                            ingredients.append(split_ingredient)
        
        # Remove duplicates while preserving order
        seen = set()
        unique_ingredients = []
        for ingredient in ingredients:
            clean_ingredient = re.sub(r'\s+', ' ', ingredient).strip()
            if clean_ingredient.lower() not in seen:
                seen.add(clean_ingredient.lower())
                unique_ingredients.append(clean_ingredient)
        
        return unique_ingredients

    def extract_nutrition_info_fallback(self, text):
        """
        Fallback nutrition extraction using text parsing.
        """
        return self.extract_nutrition_info_from_text(text)

    def extract_ingredients_from_text_fallback(self, text):
        """
        Fallback ingredients extraction using text parsing.
        """
        return self.extract_ingredients_from_text(text)

    def clean_ingredient_text(self, ingredient):
        """
        Clean and normalize ingredient text.
        """
        import re
        
        # Remove extra whitespace
        ingredient = re.sub(r'\s+', ' ', ingredient).strip()
        
        # Remove trailing punctuation
        ingredient = re.sub(r'[.,;:]$', '', ingredient)
        
        # Remove leading numbers and percentages
        ingredient = re.sub(r'^\d+%?\s*', '', ingredient)
        
        # Remove bullet points
        ingredient = re.sub(r'^\s*[-]\s*', '', ingredient)
        
        # Fix common OCR errors
        ingredient = ingredient.replace("Flailed", "Flaked")
        ingredient = ingredient.replace("Mingo", "Mango")
        ingredient = ingredient.replace("Pomcgranate", "Pomegranate")
        ingredient = ingredient.replace("lodised", "Iodised")
        
        return ingredient.strip()

    def split_compound_ingredients(self, ingredient_text):
        """
        Split compound ingredients that contain multiple items.
        """
        import re
        
        # If it contains commas but no parentheses, split by commas
        if ',' in ingredient_text and '(' not in ingredient_text:
            parts = re.split(r',\s*', ingredient_text)
            return [part.strip() for part in parts if part.strip()]
        
        # If it contains "and" but no parentheses, split by "and"
        if ' and ' in ingredient_text.lower() and '(' not in ingredient_text:
            parts = re.split(r'\s+and\s+', ingredient_text, flags=re.IGNORECASE)
            return [part.strip() for part in parts if part.strip()]
        
        # If it contains both commas and parentheses, try to split carefully
        if ',' in ingredient_text and '(' in ingredient_text:
            parts = re.split(r',\s*(?![^()]*\))', ingredient_text)
            result = []
            for part in parts:
                part = part.strip()
                if part:
                    if ',' in part and '(' not in part:
                        sub_parts = re.split(r',\s*', part)
                        result.extend([sub_part.strip() for sub_part in sub_parts if sub_part.strip()])
                    else:
                        result.append(part)
            return result
        
        return [ingredient_text]

    def correct_ocr_errors(self, text):
        corrections = {
            "Bg": "8g", "Omg": "0mg", "lron": "Iron", "meg": "mcg"
        }
        for wrong, right in corrections.items():
            text = text.replace(wrong, right)
        return text

    def extract_nutrition_info_from_text(self, text):
        """
        Enhanced nutrition extraction that captures all nutritional data from food labels.
        """
        nutrition_data = {}
        
        # Fix common OCR errors first
        text = self.correct_ocr_errors(text)
        
        # Define comprehensive nutrient patterns with variations
        nutrient_patterns = {
            "Energy": [
                r'energy[:\s]*(\d+(?:\.\d+)?)\s*(kcal|kj|cal)',
                r'calories[:\s]*(\d+(?:\.\d+)?)\s*(kcal|kj|cal)',
                r'calorie[:\s]*(\d+(?:\.\d+)?)\s*(kcal|kj|cal)',
                r'(\d+(?:\.\d+)?)\s*(kcal|kj|cal)\s*energy',
                r'(\d+(?:\.\d+)?)\s*(kcal|kj|cal)\s*calories'
            ],
            "Total Fat": [
                r'total\s+fat[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'fat[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*total\s+fat',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*fat'
            ],
            "Saturated Fat": [
                r'saturated\s+fat[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'sat\s+fat[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*saturated\s+fat',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*sat\s+fat'
            ],
            "Trans Fat": [
                r'trans\s+fat[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*trans\s+fat'
            ],
            "Cholesterol": [
                r'cholesterol[:\s]*(\d+(?:\.\d+)?)\s*(mg|g|%)',
                r'(\d+(?:\.\d+)?)\s*(mg|g|%)\s*cholesterol'
            ],
            "Sodium": [
                r'sodium[:\s]*(\d+(?:\.\d+)?)\s*(mg|g|%)',
                r'salt[:\s]*(\d+(?:\.\d+)?)\s*(mg|g|%)',
                r'(\d+(?:\.\d+)?)\s*(mg|g|%)\s*sodium',
                r'(\d+(?:\.\d+)?)\s*(mg|g|%)\s*salt'
            ],
            "Carbohydrate": [
                r'carbohydrate[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'carbohydrates[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'carbs[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*carbohydrate',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*carbohydrates',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*carbs'
            ],
            "Total Sugars": [
                r'total\s+sugars[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'sugars[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'sugar[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*total\s+sugars',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*sugars',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*sugar'
            ],
            "Added Sugars": [
                r'added\s+sugars[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*added\s+sugars'
            ],
            "Dietary Fibre": [
                r'dietary\s+fibre[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'dietary\s+fiber[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'fibre[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'fiber[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*dietary\s+fibre',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*dietary\s+fiber',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*fibre',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*fiber'
            ],
            "Protein": [
                r'protein[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*protein'
            ]
        }
        
        # Method 1: Extract using comprehensive patterns - collect ALL matches
        for nutrient_name, patterns in nutrient_patterns.items():
            all_matches = []
            for pattern in patterns:
                matches = re.findall(pattern, text, re.IGNORECASE)
                all_matches.extend(matches)
            
            if all_matches:
                # Take the first match found (most reliable)
                value, unit = all_matches[0]
                # Standardize units
                if unit.lower() in ['kj', 'cal']:
                    unit = 'kcal'
                elif unit.lower() == '%':
                    # Keep percentage as is
                    pass
                else:
                    unit = 'g'
                    
                    nutrition_data[nutrient_name] = f"{value} {unit}".strip()
        
        # Method 2: Look for tabular format (nutrient name followed by value)
        # This method looks for nutrient names and values in a more structured way
            lines = text.split('\n')
            for i, line in enumerate(lines):
                line_lower = line.lower().strip()
                
                # Skip obvious non-nutrition lines
                if any(skip_word in line_lower for skip_word in [
                    'ingredients', 'allergen', 'manufactured', 'fssai', 'mrp', 'weight', 
                    'packaging', 'batch', 'lot', 'date', 'use by', 'sale price', 'unit',
                    'promise', 'joy', 'bite', 'artisanal', 'treats', 'delicacies', 'celebration',
                    'flavor', 'delight', 'explore', 'universe', 'indulgent', 'extravagance',
                    'unwraphappiness', 'www', 'http', 'com', 'in', 'by', 'mf', 'lic', 'no'
                ]):
                    continue
                
                # Look for nutrient names in the line
                for nutrient_name in nutrient_patterns.keys():
                    if nutrient_name.lower().replace(' ', '') in line_lower.replace(' ', ''):
                        # Extract numeric value from the same line or next line
                        value_match = re.search(r'(\d+(?:\.\d+)?)', line)
                    if value_match and nutrient_name not in nutrition_data:  # Don't overwrite existing data
                            value = value_match.group(1)
                            # Determine unit based on nutrient type
                            unit = 'g'
                            
                            nutrition_data[nutrient_name] = f"{value} {unit}".strip()
        
        # Method 3: Look for "Per 100g" format specifically
            per_100g_pattern = r'per\s+100\s*g.*?(?=\n\n|\Z)'
            per_100g_match = re.search(per_100g_pattern, text, re.IGNORECASE | re.DOTALL)
            if per_100g_match:
                per_100g_text = per_100g_match.group(0)
                # Extract all number-unit pairs from this section
                number_unit_pairs = re.findall(r'(\d+(?:\.\d+)?)\s*(kcal|g|mg|mcg|%|kj|cal)', per_100g_text, re.IGNORECASE)
                
                # Try to match with nutrient names in the same section
                for pair in number_unit_pairs:
                    value, unit = pair
                    # Look for nutrient names near this value
                    for nutrient_name in nutrient_patterns.keys():
                        if nutrient_name.lower().replace(' ', '') in per_100g_text.lower().replace(' ', ''):
                            if nutrient_name not in nutrition_data:  # Don't overwrite existing data
                                # Standardize units
                                if unit.lower() in ['kj', 'cal']:
                                    unit = 'kcal'
                                elif nutrient_name in ["Energy"]:
                                    unit = 'kcal'
                                elif nutrient_name in ["Sodium", "Cholesterol"]:
                                    unit = 'mg'
                                else:
                                    unit = 'g'
                                
                                nutrition_data[nutrient_name] = f"{value} {unit}".strip()
        
        return nutrition_data

    def extract_ingredients_from_text(self, text):
        """
        Enhanced ingredient extraction that properly separates individual ingredients.
        """
        import re
        ingredients_list = []
        
        # Try to find an ingredients section
        ingredient_section_match = re.search(
            r'(?:ingredients|contains|composed of):?\s*(.*?)(?=(?:nutrition facts|allergens|directions|amount per serving|storage|best by|manufactured by|$))',
            text, re.IGNORECASE | re.DOTALL
        )

        def clean_ingredient_text(ingredient):
            """Clean and normalize ingredient text"""
            # Remove percentages and quantities in parentheses
            ingredient = re.sub(r'\(\d+%?\)', '', ingredient)
            # Remove specific quantity patterns
            ingredient = re.sub(r'\d+%|\d+g|\d+mg|\d+mcg|\d+kcal', '', ingredient)
            # Remove "less than" and "contains" phrases
            ingredient = re.sub(r'less than \d+% of|contains \d+% of', '', ingredient, flags=re.IGNORECASE)
            # Remove nutrition facts headers
            ingredient = re.sub(
                r'^(energy|calories|total fat|saturated fat|trans fat|mufa|pufa|cholesterol|carbohydrate|total sugars|added sugars|dietary fibre|protein|sodium|vitamins|minerals|servings|approximate values)\s*',
                '', ingredient, flags=re.IGNORECASE
            )
            # Clean up extra whitespace
            ingredient = re.sub(r'\s+', ' ', ingredient).strip()
            return ingredient

        def split_ingredient_chunk(chunk):
            """Split ingredient chunk into individual ingredients"""
            # First, clean the chunk
            chunk = clean_ingredient_text(chunk)
            
            # Split by common separators, but be more careful about "and"
            # Only split by "and" if it's not part of a compound name
            parts = re.split(r',|;|\.', chunk)
            
            result = []
            for part in parts:
                part = part.strip()
                if not part or len(part) < 2:
                    continue
                
                # Handle "and" more carefully - only split if it's clearly a separator
                # Don't split if "and" is part of a compound name like "salt and pepper"
                if ' and ' in part.lower():
                    # Check if this looks like a compound name or a separator
                    and_parts = part.split(' and ')
                    if len(and_parts) == 2:
                        # If both parts are short, it might be a compound name
                        if len(and_parts[0].strip()) <= 10 and len(and_parts[1].strip()) <= 10:
                            # Keep as one ingredient if it looks like a compound name
                            result.append(part)
                        else:
                            # Split if parts are longer (likely separate ingredients)
                            for subpart in and_parts:
                                subpart = subpart.strip()
                                if subpart and len(subpart) > 2:
                                    result.append(subpart)
                    else:
                        # Multiple "and"s, split them
                        for subpart in and_parts:
                            subpart = subpart.strip()
                            if subpart and len(subpart) > 2:
                                result.append(subpart)
                else:
                    result.append(part)
            
            return result

        if ingredient_section_match:
            ingredients_raw = ingredient_section_match.group(1)
            # Split by commas, semicolons, and periods
            raw_ingredients = re.split(r'[,;.]\s*', ingredients_raw)
            
            for ingredient in raw_ingredients:
                if not ingredient.strip():
                    continue
                    
                # Process each ingredient chunk
                for sub_ing in split_ingredient_chunk(ingredient):
                    if sub_ing and len(sub_ing) > 2:
                        # Additional cleaning for individual ingredients
                        clean_ing = clean_ingredient_text(sub_ing)
                        if clean_ing and len(clean_ing) > 2:
                            ingredients_list.append(clean_ing)
        else:
            # Fallback: split the whole text, but filter out obvious junk
            raw_ingredients = re.split(r'[,;.\n]\s*', text)
            for ingredient in raw_ingredients:
                clean_ingredient = clean_ingredient_text(ingredient)
                if len(clean_ingredient) > 2 and not re.match(r'^\d+$', clean_ingredient):
                    ingredients_list.append(clean_ingredient)
        
        # Remove duplicates while preserving order
        seen = set()
        unique_ingredients = []
        for ing in ingredients_list:
            if ing not in seen:
                seen.add(ing)
                unique_ingredients.append(ing)
        
        return unique_ingredients



    async def validate_product_safety(self, user, ingredients_list):
        if USE_STATIC_INGREDIENT_SAFETY:
            # --- Instant static safety check ---
            dietary = [d.strip().lower() for d in user.Dietary_preferences.split(",") if d.strip()] if user.Dietary_preferences else []
            health = [h.strip().lower() for h in user.Health_conditions.split(",") if h.strip()] if user.Health_conditions else []
            allergies = [a.strip().lower() for a in user.Allergies.split(",") if a.strip()] if user.Allergies else []
            go_ingredients, caution_ingredients, no_go_ingredients = [], [], []
            for ingredient in ingredients_list:
                ing_lower = ingredient.lower()
                pubchem_summary = fetch_pubchem_toxicology_summary(ingredient)
                if pubchem_summary:
                    summary_lower = pubchem_summary.lower()
                    # Strong warning keywords
                    if any(w in summary_lower for w in ["toxic", "hazard", "carcinogen", "danger", "harmful", "poison", "fatal"]):
                        no_go_ingredients.append(ingredient + " (Toxicological Concern)")
                        continue # Skip other checks if toxic
                if any(a in ing_lower for a in allergies):
                    no_go_ingredients.append(ingredient + " (Allergen)")
                elif any(d not in ing_lower for d in dietary) and dietary:
                    caution_ingredients.append(ingredient + " (Dietary)")
                elif any(h in ing_lower for h in health):
                    caution_ingredients.append(ingredient + " (Health)")
                else:
                    go_ingredients.append(ingredient)
            if no_go_ingredients:
                safety_status = "UNSAFE"
            elif caution_ingredients:
                safety_status = "CAUTION"
            else:
                safety_status = "SAFE"
            return safety_status, go_ingredients, caution_ingredients, no_go_ingredients
        else:
            # --- Edamam-based safety check (original logic) ---
            dietary = [d.strip().lower() for d in user.Dietary_preferences.split(",") if d.strip()] if user.Dietary_preferences else []
            health = [h.strip().lower() for h in user.Health_conditions.split(",") if h.strip()] if user.Health_conditions else []
            allergies = [a.strip().lower() for a in user.Allergies.split(",") if a.strip()] if user.Allergies else []
            go_ingredients, caution_ingredients, no_go_ingredients = [], [], []
            async def classify(ingredient):
                info = await self.get_edamam_info(ingredient)
                if not info["healthLabels"] and not info["cautions"]:
                    if any(a in ingredient.lower() for a in allergies):
                        no_go_ingredients.append(ingredient + " (Allergen: fallback)")
                    elif any(d not in ingredient.lower() for d in dietary):
                        caution_ingredients.append(ingredient + " (Dietary: fallback)")
                    elif any(h in ingredient.lower() for h in health):
                        caution_ingredients.append(ingredient + " (Health: fallback)")
                    else:
                        go_ingredients.append(ingredient + " (No Edamam data)")
                    return
                if any(a in info["cautions"] for a in allergies):
                    no_go_ingredients.append(ingredient)
                elif any(d not in info["healthLabels"] for d in dietary):
                    caution_ingredients.append(ingredient)
                elif any(h in ingredient.lower() for h in health):
                    caution_ingredients.append(ingredient)
                else:
                    go_ingredients.append(ingredient)
            await asyncio.gather(*(classify(ing) for ing in ingredients_list))
            all_classified = set(go_ingredients + caution_ingredients + no_go_ingredients)
            for ing in ingredients_list:
                if ing not in all_classified:
                    go_ingredients.append(ing + " (Defaulted)")
            if no_go_ingredients:
                safety_status = "UNSAFE"
            elif caution_ingredients:
                safety_status = "CAUTION"
            else:
                safety_status = "SAFE"
            return safety_status, go_ingredients, caution_ingredients, no_go_ingredients

    async def get_edamam_info(self, ingredient):
        try:
            url = (
                f"https://api.edamam.com/api/food-database/v2/parser"
                f"?app_id={EDAMAM_APP_ID}&app_key={EDAMAM_APP_KEY}&ingr={ingredient}"
            )
            connector = get_ssl_connector()
            async with aiohttp.ClientSession(connector=connector) as session:
                async with session.get(url) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        parsed = data.get("parsed") or data.get("hints")
                        if parsed:
                            food = parsed[0]["food"] if "food" in parsed[0] else parsed[0].get("food", {})
                            return {
                                "healthLabels": [h.lower() for h in food.get("healthLabels", [])],
                                "cautions": [c.lower() for c in food.get("cautions", [])]
                            }
        except Exception as e:
            print(f"Edamam API error for ingredient {ingredient}: {e}")
            # Return empty result on error to prevent app crash
        return {"healthLabels": [], "cautions": []}

    def get_ai_health_insight_and_expert_advice(self, user, nutrition_data, flagged_ingredients):
        health_prompt = f"""
        You are a certified health and nutrition expert.

        User Profile:
        Diet: {user.Dietary_preferences}
        Health Conditions: {user.Health_conditions}
        Allergies: {user.Allergies}

        Product Nutrition: {nutrition_data}
        Flagged Ingredients: {flagged_ingredients}

        Give a short health insight: safety, red flags, and user-friendly advice.
        """

        expert_prompt = f"""
        You are a food science expert. Based on the nutrition data and flagged ingredients below, give a detailed expert-level opinion with technical insight.

        Nutrition Data: {nutrition_data}
        Flagged Ingredients: {flagged_ingredients}
        """

        ai_health_insight = self.call_openai(health_prompt)
        expert_advice = self.call_openai(expert_prompt)

        return {"ai_health_insight": ai_health_insight, "expert_advice": expert_advice}

    def call_openai(self, prompt):
        try:
            client = OpenAI(
                base_url="https://api.openai.com/v1",
                api_key=os.getenv("OPENAI_API_KEY"),
            )

            completion = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "You are an expert in food science and health."},
                    {"role": "user", "content": prompt},
                ],
            )
            content = completion.choices[0].message.content.strip()
            print(" Raw LLM Output:", content)

            # If the content is wrapped in markdown, extract the JSON part
            if content.startswith("```json") and content.endswith("```"):
                content = content[len("```json"): -len("```")].strip()

            # Parse content safely
            try:
                return json.loads(content)
            except json.JSONDecodeError:
                import re
                # Attempt to fix common JSON issues like trailing commas before brackets/braces
                content_clean = re.sub(r",\s*([}\]])", r"\1", content)
                try:
                    return json.loads(content_clean)
                except json.JSONDecodeError:
                    # If even after cleanup it fails, return a summary fallback
                    return {"summary": content}

        except Exception as e:
            print(f"OpenAI error: {str(e)}")  # Add error logging
            return {"error": f"OpenAI error: {str(e)}"}

    def compare_products(self, product1, product2, user):
        # Helper to get attribute or dict key
        def get(obj, key, default=None):
            if hasattr(obj, key):
                return getattr(obj, key, default)
            if isinstance(obj, dict):
                return obj.get(key, default)
            return default

        def extract_ingredient_categories(obj):
            nd = get(obj, 'nutrition_data', {})
            go = nd.get('go_ingredients') or nd.get('go') or []
            caution = nd.get('caution_ingredients') or nd.get('caution') or []
            no_go = nd.get('no_go_ingredients') or nd.get('no_go') or []
            return go, caution, no_go

        # Prepare comparison data
        p1_flagged = get(product1, 'flagged_ingredients', [])
        p2_flagged = get(product2, 'flagged_ingredients', [])
        p1_safe = get(product1, 'safety_status', '')
        p2_safe = get(product2, 'safety_status', '')
        p1_go, p1_caution, p1_no_go = extract_ingredient_categories(product1)
        p2_go, p2_caution, p2_no_go = extract_ingredient_categories(product2)

        # Calculate health scores based on user profile
        def calculate_health_score(go_count, caution_count, no_go_count, flagged_count):
            # Base score starts at 100
            score = 100
            
            # Deduct points for each category
            score -= (no_go_count * 20)  # No-go ingredients are most concerning
            score -= (caution_count * 10)  # Caution ingredients are moderately concerning
            score -= (flagged_count * 15)  # Flagged ingredients are concerning
            
            # Bonus points for go ingredients
            score += (go_count * 2)
            
            return max(0, score)  # Ensure score doesn't go below 0

        p1_score = calculate_health_score(len(p1_go), len(p1_caution), len(p1_no_go), len(p1_flagged))
        p2_score = calculate_health_score(len(p2_go), len(p2_caution), len(p2_no_go), len(p2_flagged))

        # Generate AI-powered recommendation based on user profile
        def generate_ai_recommendation(product1_data, product2_data, user_profile):
            user_health_conditions = user.Health_conditions or ""
            user_allergies = user.Allergies or ""
            user_dietary = user.Dietary_preferences or ""
            
            # Create a comprehensive comparison prompt
            comparison_prompt = f"""
            As a health and nutrition expert, analyze these two products for a user with the following profile:
            
            User Health Conditions: {user_health_conditions}
            User Allergies: {user_allergies}
            User Dietary Preferences: {user_dietary}
            
            Product 1: {product1_data['name']}
            - Go Ingredients: {len(product1_data['go_ingredients'])} items
            - Caution Ingredients: {len(product1_data['caution_ingredients'])} items
            - No-Go Ingredients: {len(product1_data['no_go_ingredients'])} items
            - Flagged Ingredients: {product1_data['flagged_ingredients']}
            - Health Score: {p1_score}/100
            
            Product 2: {product2_data['name']}
            - Go Ingredients: {len(product2_data['go_ingredients'])} items
            - Caution Ingredients: {len(product2_data['caution_ingredients'])} items
            - No-Go Ingredients: {len(product2_data['no_go_ingredients'])} items
            - Flagged Ingredients: {product2_data['flagged_ingredients']}
            - Health Score: {p2_score}/100
            
            Based on the user's health profile and the ingredient analysis, which product is healthier and why? 
            Provide a clear, personalized recommendation with specific reasons.
            """
            
            try:
                client = OpenAI(
                    base_url="https://api.openai.com/v1",
                    api_key=os.getenv("OPENAI_API_KEY"),
                )

                completion = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "You are an expert nutritionist and health advisor. Provide clear, personalized recommendations based on user health profiles and ingredient analysis."},
                        {"role": "user", "content": comparison_prompt},
                    ],
                )
                return completion.choices[0].message.content.strip()
            except Exception as e:
                print(f"OpenAI error in comparison: {str(e)}")
                # Fallback recommendation
                if p1_score > p2_score:
                    return f"{product1_data['name']} is healthier based on ingredient analysis (Health Score: {p1_score} vs {p2_score})"
                elif p2_score > p1_score:
                    return f"{product2_data['name']} is healthier based on ingredient analysis (Health Score: {p2_score} vs {p1_score})"
                else:
                    return "Both products have similar health profiles based on ingredient analysis"

        # Generate AI recommendation
        product1_data = {
            "name": get(product1, "product_name", "Product 1"),
            "go_ingredients": p1_go,
            "caution_ingredients": p1_caution,
            "no_go_ingredients": p1_no_go,
            "flagged_ingredients": p1_flagged
        }
        product2_data = {
            "name": get(product2, "product_name", "Product 2"),
            "go_ingredients": p2_go,
            "caution_ingredients": p2_caution,
            "no_go_ingredients": p2_no_go,
            "flagged_ingredients": p2_flagged
        }
        
        ai_recommendation = generate_ai_recommendation(product1_data, product2_data, user)

        # Extract health insights from nutrition_data
        def extract_health_insights(obj):
            nutrition_data = get(obj, 'nutrition_data', {})
            
            # Handle case where nutrition_data might be a string (JSON string)
            if isinstance(nutrition_data, str):
                try:
                    import json
                    nutrition_data = json.loads(nutrition_data)
                except (json.JSONDecodeError, TypeError):
                    nutrition_data = {}
            
            # Ensure nutrition_data is a dictionary
            if not isinstance(nutrition_data, dict):
                nutrition_data = {}
                
            structured_health_analysis = nutrition_data.get('structured_health_analysis', {})
            
            # Ensure structured_health_analysis is a dictionary
            if not isinstance(structured_health_analysis, dict):
                structured_health_analysis = {}
            
            # Extract health insights with fallbacks
            bluf_insight = structured_health_analysis.get('bluf_insight', '')
            main_insight = structured_health_analysis.get('main_insight', '')
            deeper_reference = structured_health_analysis.get('deeper_reference', '')
            
            # Only fallback to legacy fields if structured data is completely missing
            if not bluf_insight and not main_insight and not deeper_reference:
                ai_health_insight = nutrition_data.get('ai_health_insight', '')
                if isinstance(ai_health_insight, dict):
                    # If ai_health_insight is already structured, extract from it
                    bluf_insight = ai_health_insight.get('bluf_insight', '')
                    main_insight = ai_health_insight.get('main_insight', '')
                    deeper_reference = ai_health_insight.get('deeper_reference', '')
                else:
                    # If ai_health_insight is a string, use it as bluf_insight
                    bluf_insight = ai_health_insight
                
                if not main_insight:
                    main_insight = nutrition_data.get('expert_advice', '')
            
            # Get expert AI conclusion data
            expert_ai_conclusion = nutrition_data.get('expert_ai_conclusion', {})
            
            # Ensure expert_ai_conclusion is a dictionary
            if not isinstance(expert_ai_conclusion, dict):
                expert_ai_conclusion = {}
            
            # Return ONLY the required fields - no extra data
            return {
                "ai_health_insight": {
                    "bluf_insight": bluf_insight,
                    "main_insight": main_insight,
                    "deeper_reference": deeper_reference
                },
                "expert_ai_conclusion": {
                    "prognosis": expert_ai_conclusion.get('prognosis', ''),
                    "patient_counseling": expert_ai_conclusion.get('patient_counseling', '')
                }
            }
        
        p1_health_insights = extract_health_insights(product1)
        p2_health_insights = extract_health_insights(product2)

        # Clean nutrition_data to remove redundant fields
        def clean_nutrition_data(nutrition_data):
            if not isinstance(nutrition_data, dict):
                return nutrition_data
            
            # Create a copy to avoid modifying the original
            cleaned_data = nutrition_data.copy()
            
            # Remove redundant fields that are now at the top level
            fields_to_remove = [
                'ai_health_insight',  # Remove the simple text version
                'expert_advice',      # This is now part of structured data
                'structured_health_analysis',  # This is now extracted to top level
                'expert_ai_conclusion'  # This is now at top level
            ]
            
            for field in fields_to_remove:
                cleaned_data.pop(field, None)
            
            return cleaned_data

        return {
            "product1": {
                "name": get(product1, "product_name", "OCR Product"),
                "nutrition_data": clean_nutrition_data(get(product1, "nutrition_data", {})),
                "safety_status": p1_safe,
                "flagged_ingredients": p1_flagged,
                "go_ingredients": p1_go,
                "go_count": len(p1_go),
                "caution_ingredients": p1_caution,
                "caution_count": len(p1_caution),
                "no_go_ingredients": p1_no_go,
                "no_go_count": len(p1_no_go),
                "health_score": p1_score,
                "ai_health_insight": p1_health_insights["ai_health_insight"],
                "expert_ai_conclusion": p1_health_insights["expert_ai_conclusion"]
            },
            "product2": {
                "name": get(product2, "product_name", "OCR Product"),
                "nutrition_data": clean_nutrition_data(get(product2, "nutrition_data", {})),
                "safety_status": p2_safe,
                "flagged_ingredients": p2_flagged,
                "go_ingredients": p2_go,
                "go_count": len(p2_go),
                "caution_ingredients": p2_caution,
                "caution_count": len(p2_caution),
                "no_go_ingredients": p2_no_go,
                "no_go_count": len(p2_no_go),
                "health_score": p2_score,
                "ai_health_insight": p2_health_insights["ai_health_insight"],
                "expert_ai_conclusion": p2_health_insights["expert_ai_conclusion"]
            },
            "verdict": ai_recommendation
        }



class BarcodeView(APIView):
    permission_classes = [IsAuthenticated]
    # In-memory caches
    openfoodfacts_cache = {}
    ai_cache = {}
    safety_cache = {}
    openai_cache = {}
    efsa_cache = {}  # Add EFSA-specific cache

    def get_efsa_data_cached(self, ingredient_name):
        """Get EFSA data with caching to avoid redundant API calls"""
        if not ingredient_name:
            return {'found': False, 'error': 'No ingredient name provided', 'source': 'EFSA OpenFoodTox Database'}
        
        cache_key = ingredient_name.lower().strip()
        if cache_key in self.efsa_cache:
            return self.efsa_cache[cache_key]
        
        try:
            efsa_data = fetch_efsa_openfoodtox_data(ingredient_name)
            self.efsa_cache[cache_key] = efsa_data
            return efsa_data
        except Exception as e:
            efsa_data = {
                'found': False,
                'error': f'EFSA query failed: {str(e)}',
                'source': 'EFSA OpenFoodTox Database'
            }
            self.efsa_cache[cache_key] = efsa_data
            return efsa_data

    def _implement_enhanced_analysis_flow(self, user, ingredients_list, nutrition_data):
        """
        Implement the complete 5-step enhanced analysis flow as requested by client:
        Step 1: Parse product  Identify flagged ingredients
        Step 2: Match each flagged ingredient to specific user condition(s)
        Step 3: Apply weighted scoring (allergens > autoimmune > sensitivities)
        Step 4: Display unified No-Go + condition-specific breakdown
        Step 5: Provide links to expert insight sources (FDA, NIH, PubMed, EFSA)
        """
        # Step 1: Parse product  Identify flagged ingredients
        print(" Step 1: Parsing product and identifying flagged ingredients...")
        flagged_ingredients = []
        for ingredient in ingredients_list:
            # Basic flagging logic - in real implementation, this would use the enhanced categorization
            ingredient_lower = ingredient.lower()
            user_allergies = [a.strip().lower() for a in user.Allergies.split(",") if a.strip()] if user.Allergies else []
            user_health_conditions = [h.strip().lower() for h in user.Health_conditions.split(",") if h.strip()] if user.Health_conditions else []
            
            # Check for flags
            is_flagged = False
            for allergy in user_allergies:
                if allergy in ingredient_lower:
                    is_flagged = True
                    break
            
            for condition in user_health_conditions:
                if condition in ingredient_lower or any(cond in ingredient_lower for cond in ['sugar', 'sodium', 'fat']):
                    is_flagged = True
                    break
            
            if is_flagged:
                flagged_ingredients.append(ingredient)
        
        print(f" Step 1 Complete: Found {len(flagged_ingredients)} flagged ingredients")
        
        # Step 2: Match each flagged ingredient to specific user condition(s)
        print(" Step 2: Mapping ingredients to specific conditions...")
        condition_specific_mapping = []
        for ingredient in flagged_ingredients:
            ingredient_lower = ingredient.lower()
            flags = []
            
            # Check allergies
            if user.Allergies:
                for allergy in [a.strip().lower() for a in user.Allergies.split(",") if a.strip()]:
                    if allergy in ingredient_lower:
                        flags.append({
                            "condition": "Allergy",
                            "mapping": f"{ingredient}  {allergy.title()} Allergy Risk",
                            "severity": "CRITICAL",
                            "data_source": "FDA Allergen Database"
                        })
            
            # Check health conditions
            if user.Health_conditions:
                for condition in [h.strip().lower() for h in user.Health_conditions.split(",") if h.strip()]:
                    if condition in ingredient_lower or any(cond in ingredient_lower for cond in ['sugar', 'sodium', 'fat']):
                        flags.append({
                            "condition": condition.title(),
                            "mapping": f"{ingredient}  {condition.title()} Trigger",
                            "severity": "HIGH",
                            "data_source": "NIH Clinical Guidelines"
                        })
            
            if flags:
                condition_specific_mapping.append({
                    "ingredient": ingredient,
                    "flags": flags
                })
        
        print(f" Step 2 Complete: Mapped {len(condition_specific_mapping)} ingredients to conditions")
        
        # Step 3: Apply weighted scoring (allergens > autoimmune > sensitivities)
        print(" Step 3: Applying weighted scoring system...")
        weighted_scoring = {
            "scoring_hierarchy": {
                "CRITICAL": 100,
                "HIGH": 75,
                "MODERATE": 50,
                "LOW": 25
            },
            "ingredient_scores": [],
            "transparency": "Life-threatening allergens override other factors  No-Go, even if other conditions return Caution"
        }
        
        for ingredient in flagged_ingredients:
            # Determine priority level based on ingredient type
            if any(allergy in ingredient.lower() for allergy in ['peanut', 'tree nut', 'shellfish', 'dairy', 'egg', 'soy', 'wheat']):
                priority_level = "CRITICAL"
                weighted_score = 100
                scoring_reason = "Life-threatening allergen"
            elif any(condition in ingredient.lower() for condition in ['sugar', 'sodium', 'fat']):
                priority_level = "HIGH"
                weighted_score = 75
                scoring_reason = "Health condition trigger"
            else:
                priority_level = "LOW"
                weighted_score = 25
                scoring_reason = "General dietary concern"
            
            weighted_scoring["ingredient_scores"].append({
                "ingredient": ingredient,
                "weighted_score": weighted_score,
                "scoring_reason": scoring_reason,
                "priority_level": priority_level
            })
        
        print(f" Step 3 Complete: Applied weighted scoring to {len(weighted_scoring['ingredient_scores'])} ingredients")
        
        # Step 4: Display unified No-Go + condition-specific breakdown
        print(" Step 4: Creating unified display...")
        overall_assessment = " Safe" if len(flagged_ingredients) == 0 else " Caution" if len(flagged_ingredients) < 3 else " No-Go"
        
        unified_analysis = {
            "overall_assessment": overall_assessment,
            "condition_specific_breakdown": condition_specific_mapping,
            "weighted_scoring_breakdown": weighted_scoring,
            "scoring_transparency": "Life-threatening allergens override other factors  No-Go, even if other conditions return Caution"
        }
        
        print(f" Step 4 Complete: Unified assessment: {overall_assessment}")
        
        # Step 5: Provide links to expert insight sources
        print(" Step 5: Providing expert insight sources...")
        expert_insights = {
            "data_sources": {
                "fda_allergen_database": "https://www.fda.gov/food/food-allergensgluten-free-guidance-documents-regulatory-information/food-allergens",
                "efsa_risk_assessments": "https://www.efsa.europa.eu/en/topics/topic/food-ingredients-and-packaging",
                "pubmed_ibs_fodmap": "https://pubmed.ncbi.nlm.nih.gov/?term=ibs+fodmap",
                "nih_clinical_trials": "https://clinicaltrials.gov/ct2/results?cond=irritable+bowel+syndrome",
                "who_nutritional_guidelines": "https://www.who.int/news-room/fact-sheets/detail/healthy-diet",
                "monash_fodmap_database": "https://www.monashfodmap.com/",
                "efsa_openfoodtox": "https://www.efsa.europa.eu/en/data/data-standardisation"
            },
            "regulatory_citations": [
                "FDA 21 CFR Part 101 - Food Labeling",
                "EFSA Regulation EC 1924/2006 - Nutrition and Health Claims",
                "WHO Guidelines for Healthy Diet",
                "NIH Clinical Practice Guidelines"
            ],
            "clinical_references": [
                "PubMed IBS-FODMAP Studies",
                "Cochrane Reviews on Digestive Health",
                "JAMA Nutrition Clinical Trials",
                "Monash University FODMAP Research"
            ]
        }
        print(f" Step 5 Complete: Provided {len(expert_insights)} expert insight sources")
        
        # Combine all steps into comprehensive enhanced analysis
        enhanced_analysis_flow = {
            "step_1_parsed_ingredients": {
                "total_ingredients": len(ingredients_list),
                "flagged_ingredients": flagged_ingredients,
                "flagging_criteria": "User allergies, health conditions, and dietary preferences"
            },
            "step_2_condition_mapping": {
                "mapped_ingredients": len(condition_specific_mapping),
                "condition_specific_flags": condition_specific_mapping,
                "mapping_examples": [f"{flag['ingredient']}  {flag['flags'][0]['mapping']}" for flag in condition_specific_mapping[:3] if flag.get('flags') and len(flag['flags']) > 0]
            },
            "step_3_weighted_scoring": {
                "scoring_hierarchy": weighted_scoring['scoring_hierarchy'],
                "ingredient_scores": weighted_scoring['ingredient_scores'],
                "transparency": weighted_scoring['transparency']
            },
            "step_4_unified_display": unified_analysis,
            "step_5_expert_sources": expert_insights,
            "enhanced_analysis_summary": {
                "total_ingredients_analyzed": len(ingredients_list),
                "flagged_ingredients_count": len(flagged_ingredients),
                "condition_specific_mappings": len(condition_specific_mapping),
                "overall_assessment": overall_assessment,
                "expert_sources_available": 7,
                "analysis_confidence": "Medium"
            }
        }
        
        return enhanced_analysis_flow

    def post(self, request):
        # can_scan, scan_count = can_user_scan(request.user)
        # if not can_scan:
        #     return Response(
        #         {
        #             "error": "Scan limit reached. Please subscribe to AI IngredientIQ for unlimited scans.",
        #             "scans_used": scan_count,
        #             "max_scans": 6
        #         },
        #         status=status.HTTP_402_PAYMENT_REQUIRED
        #     )
        import time
        import logging
        from concurrent.futures import ThreadPoolExecutor
        start_time = time.time()

        barcode = request.data.get('barcode')
        if not barcode:
            return Response({'error': 'Barcode is required.'}, status=status.HTTP_400_BAD_REQUEST)

        # Timing: OpenFoodFacts fetch with retry mechanism
        off_start = time.time()
        product_data = None
        try:
            if barcode in self.openfoodfacts_cache:
                product_data = self.openfoodfacts_cache[barcode]
                logging.info(f"OpenFoodFacts cache hit for barcode {barcode}")
            else:
                # Retry mechanism for OpenFoodFacts API
                max_retries = 2
                for attempt in range(max_retries + 1):
                    try:
                        response = requests.get(f"https://world.openfoodfacts.org/api/v0/product/{barcode}.json", timeout=10)
                        if response.status_code != 200:
                            return Response({'error': 'This product is not found by barcode, you can try with OCR.'}, status=status.HTTP_404_NOT_FOUND)
                        product = response.json()
                        if not product.get("product") or not product["product"].get("product_name"):
                            return Response({'error': 'This product is not found by barcode, you can try with OCR'}, status=status.HTTP_404_NOT_FOUND)
                        product_data = product["product"]
                        self.openfoodfacts_cache[barcode] = product_data
                        break  # Success, exit retry loop
                    except requests.exceptions.Timeout:
                        if attempt < max_retries:
                            logging.warning(f"OpenFoodFacts timeout, retrying... (attempt {attempt + 1}/{max_retries + 1})")
                            time.sleep(1)  # Wait 1 second before retry
                            continue
                        else:
                            raise
                    except requests.exceptions.RequestException as e:
                        if attempt < max_retries:
                            logging.warning(f"OpenFoodFacts request error, retrying... (attempt {attempt + 1}/{max_retries + 1}): {e}")
                            time.sleep(1)
                            continue
                        else:
                            raise
        except Exception as e:
            logging.error(f"OpenFoodFacts fetch failed after retries: {e}")
            # Provide a more user-friendly error message
            return Response({
                'error': 'Unable to fetch product information from the database. Please try again or use OCR scanning as an alternative.',
                'details': 'The product database is temporarily unavailable.',
                'suggestion': 'Try scanning the product label directly with OCR instead.'
            }, status=status.HTTP_503_SERVICE_UNAVAILABLE)
        off_end = time.time()
        logging.info(f"OpenFoodFacts fetch took {off_end - off_start:.2f}s")

        # Extract fields
        extracted_text = product_data.get('ingredients_text', '')
        raw_nutrition_data = product_data.get('nutriments', {})
        product_name = product_data.get('product_name', 'Unknown')
        product_image_url = product_data.get('image_url', '')
        product_image_small_url = product_data.get('image_small_url', '')
        product_image_thumb_url = product_data.get('image_thumb_url', '')
        actual_ingredients = self.extract_ingredients_from_text(extracted_text)

        # Filter and normalize nutrition data to only include requested nutrients
        def filter_nutrition_data(raw_data):
            filtered_data = {}
            
            # Macronutrients mapping
            macronutrient_mapping = {
                'energy-kcal': 'Calories',
                'energy': 'Calories',
                'proteins': 'Protein',
                'carbohydrates': 'Carbohydrates',
                'fat': 'Fats',
                'fiber': 'Fiber',
                'sugars': 'Sugars',
                'saturated-fat': 'Saturated Fat',
                'trans-fat': 'Trans Fat',
                'added-sugars': 'Added Sugars'
            }
            
            # Micronutrients mapping
            micronutrient_mapping = {
                'sodium': 'Sodium',
                'cholesterol': 'Cholesterol',
                'potassium': 'Potassium',
                'calcium': 'Calcium',
                'iron': 'Iron',
                'vitamin-d': 'Vitamin D',
                'vitamin-c': 'Vitamin C',
                'vitamin-a': 'Vitamin A',
                'magnesium': 'Magnesium',
                'zinc': 'Zinc'
            }
            
            # Process all mappings
            all_mappings = {**macronutrient_mapping, **micronutrient_mapping}
            
            for openfoodfacts_key, normalized_name in all_mappings.items():
                # Try different variations of the key
                possible_keys = [
                    openfoodfacts_key,
                    f"{openfoodfacts_key}_100g",
                    f"{openfoodfacts_key}_value"
                ]
                
                for key in possible_keys:
                    if key in raw_data and raw_data[key] is not None:
                        value = raw_data[key]
                        unit = raw_data.get(f"{openfoodfacts_key}_unit", "")
                        
                        # Format the value with unit
                        if isinstance(value, (int, float)):
                            if unit:
                                filtered_data[normalized_name] = f"{value} {unit}"
                            else:
                                filtered_data[normalized_name] = str(value)
                        else:
                            filtered_data[normalized_name] = str(value)
                        break
            
            return filtered_data
        
        nutrition_data = filter_nutrition_data(raw_nutrition_data)

        # Skip external API calls for barcode scans to improve performance
        # These APIs are more relevant for OCR scans where we have ingredient text
        medlineplus_summary = "External API data not available for barcode scans."
        pubchem_summary = "External API data not available for barcode scans."
        pubmed_articles = []
        clinical_trials = []

        # Parallelize safety and AI checks
        safety_ai_start = time.time()
        cache_key = f"{barcode}:{str(actual_ingredients)}:{str(nutrition_data)}:{str(request.user.id)}"
        with ThreadPoolExecutor() as executor:
            # Safety cache
            if cache_key in self.safety_cache:
                safety_result = self.safety_cache[cache_key]
            else:
                safety_future = executor.submit(
                    lambda: asyncio.run(self.validate_product_safety(request.user, actual_ingredients))
                )
                safety_result = safety_future.result()
                self.safety_cache[cache_key] = safety_result
            # Handle both old and new return formats for backward compatibility
            if len(safety_result) == 4:
                safety_status, go_ingredients, caution_ingredients, no_go_ingredients = safety_result
                efsa_data_cache = {}
            else:
                safety_status, go_ingredients, caution_ingredients, no_go_ingredients, efsa_data_cache = safety_result

            # AI cache
            if cache_key in self.ai_cache:
                ai_results = self.ai_cache[cache_key]
            else:
                ai_future = executor.submit(
                    self.get_ai_health_insight_and_expert_advice_fast, request.user, nutrition_data, no_go_ingredients
                )
                ai_results = ai_future.result()
                self.ai_cache[cache_key] = ai_results
        safety_ai_end = time.time()
        logging.info(f"Safety+AI checks took {safety_ai_end - safety_ai_start:.2f}s")

        # Skip FSA hygiene rating for barcode scans to improve performance
        # This API is more relevant for restaurant/food service establishments
        fsa_data = {
            'found': False,
            'message': 'FSA hygiene rating not available for barcode scans',
            'source': 'UK FSA FHRS API'
        }
        
        # Get medical condition recommendations based on user's complete health profile
        medical_recommendations = get_medical_condition_food_recommendations(
            request.user.Health_conditions, 
            request.user.Allergies, 
            request.user.Dietary_preferences
        ) if (request.user.Health_conditions or request.user.Allergies or request.user.Dietary_preferences) else {"found": False, "message": "No health profile specified"}

        

        # Simplified ingredient processing for better performance
        def clean_ingredient_name(ingredient):
            """Clean ingredient name by removing unwanted characters and formatting"""
            if not ingredient:
                return None
            # Remove anything in parentheses (percentages, quantities)
            ingredient = re.sub(r'\([^)]*\)', '', str(ingredient))
            # Remove numbers, percent signs, and special characters except hyphens and spaces
            ingredient = re.sub(r'[^a-zA-Z\-\s]', '', ingredient)
            # Remove extra spaces
            ingredient = re.sub(r'\s+', ' ', ingredient)
            # Remove 'Defaulted' or similar tags
            ingredient = re.sub(r'\b(Defaulted|Allergen|Dietary|Health|No Edamam data)\b', '', ingredient, flags=re.IGNORECASE)
            # Strip leading/trailing whitespace
            ingredient = ingredient.strip()
            # Only keep if it's a reasonable length and not empty
            if len(ingredient) > 2:
                return ingredient
            return None

        def process_ingredient_list(ingredient_list):
            """Process ingredient list with minimal overhead"""
            processed = []
            seen = set()
            
            for ing in ingredient_list:
                if isinstance(ing, dict):
                    ingredient_name = ing.get("ingredient", "")
                else:
                    ingredient_name = str(ing)
                
                clean_name = clean_ingredient_name(ingredient_name)
                if clean_name and clean_name.lower() not in seen:
                    seen.add(clean_name.lower())
                    processed.append(clean_name)
            
            return processed

        go_ingredients_clean = process_ingredient_list(go_ingredients)
        caution_ingredients_clean = process_ingredient_list(caution_ingredients)
        no_go_ingredients_clean = process_ingredient_list(no_go_ingredients)

        conclusion_start = time.time()
        try:
            expert_conclusion_result = self.get_expert_ai_conclusion(
                user=request.user,
                nutrition_data=nutrition_data,
                no_go_ingredients=no_go_ingredients_clean,
                caution_ingredients=caution_ingredients_clean,
                safety_status=safety_status,
                medlineplus_summary=medlineplus_summary,
                pubchem_summary=pubchem_summary,
                pubmed_articles=pubmed_articles,
                clinical_trials=clinical_trials,
                efsa_data_cache=efsa_data_cache,
                fsa_data=fsa_data,
                medical_recommendations=medical_recommendations
            )
        except Exception as e:
            print(f"Expert conclusion generation error: {e}")
            expert_conclusion_result = {
                "expert_conclusion": {
                    "prognosis": "Unable to generate comprehensive prognosis. Consider consulting healthcare providers for personalized guidance.",
                    "patient_counseling": "Here are steps you can take: Review this product's ingredients against your health profile and consider safer alternatives that align with your dietary preferences.",
                    "total_words": 35,
                    "risk_level": "moderate",
                    "evidence_sources": [],
                    "note": "Service error - basic response"
                }
            }
        conclusion_end = time.time()
        logging.info(f"Expert AI Conclusion took {conclusion_end - conclusion_start:.2f}s")

        # Build comprehensive data structures first
        efsa_data_comprehensive = {
            "source": "European Food Safety Authority (EFSA) OpenFoodTox Database",
            "total_ingredients_checked": len(efsa_data_cache) if 'efsa_data_cache' in locals() else 0,
            "ingredients_with_efsa_data": len([data for data in efsa_data_cache.values() if data and data.get('found')]) if 'efsa_data_cache' in locals() else 0,
            "cache": {k: v for k, v in efsa_data_cache.items() if v is not None} if 'efsa_data_cache' in locals() else {}
        }
        
        ai_health_insight_comprehensive = {
            "bluf_insight": ai_results.get("structured_health_analysis", {}).get("bluf_insight", ai_results.get("ai_health_insight", "")),
            "main_insight": ai_results.get("structured_health_analysis", {}).get("main_insight", ai_results.get("expert_advice", "")),
            "deeper_reference": ai_results.get("structured_health_analysis", {}).get("deeper_reference", ""),
            "disclaimer": ai_results.get("structured_health_analysis", {}).get("disclaimer", "Informational, not diagnostic. Consult healthcare providers for medical advice.")
        }
        
        expert_ai_conclusion_comprehensive = {
            "prognosis": re.sub(r'^[*:\s\n]+', '', expert_conclusion_result["expert_conclusion"]["prognosis"]).strip(),
            "patient_counseling": re.sub(r'^[*:\s\n]+', '', expert_conclusion_result["expert_conclusion"]["patient_counseling"]).strip(),
            "total_words": expert_conclusion_result["expert_conclusion"]["total_words"],
            "risk_level": expert_conclusion_result["expert_conclusion"]["risk_level"],
            "evidence_sources": expert_conclusion_result["expert_conclusion"]["evidence_sources"],
            "disclaimer":"Informational, not diagnostic. Consult healthcare providers for medical advice."
        }
        
        medical_condition_recommendations_comprehensive = {
            "user_health_profile": {
                "allergies": request.user.Allergies,
                "dietary_preferences": request.user.Dietary_preferences,
                "health_conditions": request.user.Health_conditions
            },
            "recommendations": medical_recommendations,
            "source": "SNOMED CT & ICD-10 Clinical Guidelines"
        }
        
        # Create comprehensive ai_results with structured format
        comprehensive_ai_results = {
            **ai_results,
            "ai_health_insight": ai_health_insight_comprehensive,
            "expert_advice": ai_results.get("expert_advice", ""),
            "expert_ai_conclusion": expert_ai_conclusion_comprehensive
        }
        
        # Scan history will be saved later after all data is available

        total_time = time.time() - start_time
        logging.info(f"BarcodeView total time: {total_time:.2f}s")

        # Simplified ingredient formatting for better performance
        def format_ingredient_list(ingredient_list):
            formatted_list = []
            seen_ingredients = set()
            
            for ing in ingredient_list:
                if isinstance(ing, dict):
                    ingredient_name = ing.get("ingredient", "")
                    reasons = ing.get("reasons", [])
                else:
                    ingredient_str = str(ing)
                    # Extract clean ingredient name and reasons
                    if " (Allergen" in ingredient_str:
                        ingredient_name = ingredient_str.split(" (Allergen")[0]
                        reasons = ["Allergen"]
                    elif " (Dietary" in ingredient_str:
                        ingredient_name = ingredient_str.split(" (Dietary")[0]
                        reasons = ["Dietary"]
                    elif " (Health" in ingredient_str:
                        ingredient_name = ingredient_str.split(" (Health")[0]
                        reasons = ["Health"]
                    elif " (Defaulted" in ingredient_str:
                        ingredient_name = ingredient_str.split(" (Defaulted")[0]
                        reasons = ["Defaulted"]
                    else:
                        ingredient_name = ingredient_str
                        reasons = ["Safe"]
                
                clean_ingredient = clean_ingredient_name(ingredient_name)
                if not clean_ingredient or clean_ingredient.lower() in seen_ingredients:
                    continue
                
                seen_ingredients.add(clean_ingredient.lower())
                
                # Get EFSA data with caching
                efsa_data = self.get_efsa_data_cached(clean_ingredient)
                
                formatted_list.append({
                    "ingredient": clean_ingredient,
                    "reasons": reasons,
                    "efsa_data": efsa_data or {}
                })
            
            return formatted_list
        
        # Simplified global deduplication
        all_ingredients_seen = set()
        
        def format_ingredient_list_with_global_dedup(ingredient_list, category_name):
            formatted_list = []
            
            for ing in ingredient_list:
                if isinstance(ing, dict):
                    ingredient_name = ing.get("ingredient", "")
                    reasons = ing.get("reasons", [])
                else:
                    ingredient_str = str(ing)
                    # Extract clean ingredient name and reasons
                    if " (Allergen" in ingredient_str:
                        ingredient_name = ingredient_str.split(" (Allergen")[0]
                        reasons = ["Allergen"]
                    elif " (Dietary" in ingredient_str:
                        ingredient_name = ingredient_str.split(" (Dietary")[0]
                        reasons = ["Dietary"]
                    elif " (Health" in ingredient_str:
                        ingredient_name = ingredient_str.split(" (Health")[0]
                        reasons = ["Health"]
                    elif " (Defaulted" in ingredient_str:
                        ingredient_name = ingredient_str.split(" (Defaulted")[0]
                        reasons = ["Defaulted"]
                    else:
                        ingredient_name = ingredient_str
                        reasons = ["Safe"]
                
                clean_ingredient = clean_ingredient_name(ingredient_name)
                if not clean_ingredient or clean_ingredient.lower() in all_ingredients_seen:
                    continue
                
                all_ingredients_seen.add(clean_ingredient.lower())
                
                # Get EFSA data with caching
                efsa_data = self.get_efsa_data_cached(clean_ingredient)
                
                formatted_list.append({
                    "ingredient": clean_ingredient,
                    "reasons": reasons,
                    "efsa_data": efsa_data or {}
                })
            
            return formatted_list
        
        # Process in priority order: no_go first, then caution, then go
        no_go_ingredients_obj = format_ingredient_list_with_global_dedup(no_go_ingredients, "no_go")
        caution_ingredients_obj = format_ingredient_list_with_global_dedup(caution_ingredients, "caution")
        go_ingredients_obj = format_ingredient_list_with_global_dedup(go_ingredients, "go")

        # Prepare ingredients for scan history (convert back to simple format for storage)
        def extract_ingredient_names(ingredient_list):
            return [ing["ingredient"] if isinstance(ing, dict) else ing for ing in ingredient_list]
        
        no_go_names = extract_ingredient_names(no_go_ingredients)
        go_names = extract_ingredient_names(go_ingredients)
        caution_names = extract_ingredient_names(caution_ingredients)
        
        # Simplified data structures for better performance
        efsa_data_comprehensive = {
            "source": "European Food Safety Authority (EFSA) OpenFoodTox Database",
            "total_ingredients_checked": len(self.efsa_cache),
            "ingredients_with_efsa_data": len([data for data in self.efsa_cache.values() if data and data.get('found')]),
            "cache": {k: v for k, v in self.efsa_cache.items() if v is not None}
        }
        
        # Simplified expert conclusion generation
        conclusion_start = time.time()
        try:
            expert_conclusion_result = self.get_expert_ai_conclusion(
                user=request.user,
                nutrition_data=nutrition_data,
                no_go_ingredients=no_go_names,
                caution_ingredients=caution_names,
                safety_status=safety_status,
                medlineplus_summary="",  # Not available for barcode scans
                pubchem_summary="",     # Not available for barcode scans
                pubmed_articles=[],     # Not available for barcode scans
                clinical_trials=[],     # Not available for barcode scans
                efsa_data_cache=efsa_data_comprehensive.get("cache", {}),
                fsa_data=fsa_data,
                medical_recommendations=medical_condition_recommendations_comprehensive
            )
        except Exception as e:
            print(f"Expert conclusion generation error: {e}")
            expert_conclusion_result = {
                "expert_conclusion": {
                    "prognosis": "Unable to generate comprehensive prognosis. Consider consulting healthcare providers for personalized guidance.",
                    "patient_counseling": "Here are steps you can take: Review this product's ingredients against your health profile and consider safer alternatives that align with your dietary preferences.",
                    "total_words": 35,
                    "risk_level": "moderate",
                    "evidence_sources": ["General health guidelines"]
                }
            }
        conclusion_end = time.time()
        logging.info(f"Expert AI Conclusion took {conclusion_end - conclusion_start:.2f}s")
        
        expert_ai_conclusion_comprehensive = {
            "prognosis": re.sub(r'^[*:\s\n]+', '', expert_conclusion_result["expert_conclusion"]["prognosis"]).strip(),
            "patient_counseling": re.sub(r'^[*:\s\n]+', '', expert_conclusion_result["expert_conclusion"]["patient_counseling"]).strip(),
            "total_words": expert_conclusion_result["expert_conclusion"]["total_words"],
            "risk_level": expert_conclusion_result["expert_conclusion"]["risk_level"],
            "evidence_sources": expert_conclusion_result["expert_conclusion"]["evidence_sources"],
            "disclaimer": "Informational, not diagnostic. Consult healthcare providers for medical advice."
        }
        
        medical_condition_recommendations_comprehensive = {
            "user_health_profile": {
                "allergies": request.user.Allergies,
                "dietary_preferences": request.user.Dietary_preferences,
                "health_conditions": request.user.Health_conditions
            },
            "recommendations": medical_recommendations,
            "source": "SNOMED CT & ICD-10 Clinical Guidelines"
        }
        
        # Simplified comprehensive ai_results
        comprehensive_ai_results = {
            **ai_results,
            "ai_health_insight": ai_results.get("ai_health_insight", ""),
            "expert_advice": ai_results.get("expert_advice", ""),
            "expert_ai_conclusion": expert_ai_conclusion_comprehensive
        }
        
        # FSA data already set above for performance optimization

        # Save scan history efficiently
        scan = asyncio.run(self.save_scan_history(
            request.user,
            product_image_url,
            extracted_text,
            nutrition_data,
            comprehensive_ai_results,
            safety_status,
            no_go_names,
            product_name,
            product_image_url,
            product_image_small_url,
            product_image_thumb_url,
            actual_ingredients,
            go_names,
            caution_names,
            no_go_names,
            expert_ai_conclusion_comprehensive,
            ai_results.get("structured_health_analysis", {}),
            efsa_data_comprehensive,
            fsa_data,
            medical_condition_recommendations_comprehensive
        ))

        # Get current scan count for response AFTER scan is saved
        from .scan_limit import can_user_scan, get_monthly_reset_date
        _, scan_count, remaining_scans = can_user_scan(request.user)
        
        # Handle None values for premium users
        if scan_count is None:
            scan_count = 0
        if remaining_scans is None:
            remaining_scans = "unlimited"

        # Add enhanced analysis flow (5-step process)
        enhanced_analysis_flow = self._implement_enhanced_analysis_flow(
            request.user, 
            actual_ingredients, 
            nutrition_data
        )

        return Response({
            "scan_id": scan.id,
            "image_url": product_image_url,
            "product_name": product_name,
            "product_image": {
                "full": product_image_url,
            },
            "extracted_text": extracted_text,
            "nutrition_data": nutrition_data,
            "safety_status": safety_status,
            "is_favorite": scan.is_favorite,
            "scan_usage": {
                "scans_used": scan_count,
                "max_scans": 20,
                "remaining_scans": remaining_scans,
                "monthly_reset_date": get_monthly_reset_date(),
                "total_user_scans": scan_count
            },
            "user_plan": get_user_plan_info(request.user),
            "ingredients_analysis": {
                "go": {
                    "ingredients": go_ingredients_obj,
                    "count": len(go_ingredients_obj),
                    "description": "Ingredients that are safe and suitable for your health profile"
                },
                "caution": {
                    "ingredients": caution_ingredients_obj,
                    "count": len(caution_ingredients_obj),
                    "description": "Ingredients that may not be ideal for your health profile - consume at your own risk"
                },
                "no_go": {
                    "ingredients": no_go_ingredients_obj,
                    "count": len(no_go_ingredients_obj),
                    "description": "Ingredients that are harmful or not suitable for your health profile - avoid these"
                },
                "total_flagged": len(caution_ingredients_obj) + len(no_go_ingredients_obj)
            },
            "efsa_data": efsa_data_comprehensive,
            # "ai_health_insight": ai_health_insight_comprehensive,
            "expert_ai_conclusion": expert_ai_conclusion_comprehensive,
            "ai_health_insight": ai_results.get("structured_health_analysis", {}),
            "fsa_hygiene_data": fsa_data,
            "medical_condition_recommendations": medical_condition_recommendations_comprehensive,
            "enhanced_analysis_flow": enhanced_analysis_flow,
            # "timing": {
            #     "openfoodfacts": off_end - off_start,
            #     "safety+ai": safety_ai_end - safety_ai_start,
            #     "total": total_time
            # },
            # "medlineplus_summary": medlineplus_summary,
            # "pubchem_summary": pubchem_summary,
            # "pubmed_articles": pubmed_articles,
            # "clinical_trials": clinical_trials,
        }, status=status.HTTP_200_OK)

    def put(self, request):
        """
        Handle PUT requests for updating only the image of an existing barcode scan.
        This is a lightweight update that doesn't re-run analysis.
        """
        try:
            # Get the scan ID from the request
            scan_id = request.data.get('scan_id')
            if not scan_id:
                return Response(
                    {"error": "scan_id is required for PUT requests"},
                    status=status.HTTP_400_BAD_REQUEST
                )

            # Validate the image file
            serializer = AllergenDietaryCheckSerializer(data=request.data)
            if not serializer.is_valid():
                return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

            image_file = serializer.validated_data['image']
            image_content = image_file.read()

            # Get the existing scan
            from .models import FoodLabelScan
            try:
                existing_scan = FoodLabelScan.objects.get(id=scan_id, user=request.user)
            except FoodLabelScan.DoesNotExist:
                return Response(
                    {"error": "Scan not found or access denied"},
                    status=status.HTTP_404_NOT_FOUND
                )

            # Save the new image
            image_url, image_path = self.save_image(image_content)
            if not image_url:
                return Response({'error': 'Image upload failed'}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

            # Update only the image URLs in the existing scan
            existing_scan.image_url = image_url
            existing_scan.product_image_url = image_url
            
            # Update the image URL in the nutrition_data JSON field as well
            if existing_scan.nutrition_data and isinstance(existing_scan.nutrition_data, dict):
                if 'product_image' in existing_scan.nutrition_data:
                    existing_scan.nutrition_data['product_image']['full'] = image_url
                else:
                    existing_scan.nutrition_data['product_image'] = {'full': image_url}
            
            existing_scan.save()

            return Response({
                "scan_id": existing_scan.id,
                "product_name": existing_scan.product_name,
                "image_url": image_url,
                "product_image": {
                    "full": image_url,
                },
                "updated_existing_scan": True,
                "message": "Image updated successfully. All other data remains unchanged.",
                "extracted_text": existing_scan.extracted_text,
                "nutrition_data": existing_scan.nutrition_data,
                "safety_status": existing_scan.safety_status,
                "is_favorite": existing_scan.is_favorite
            }, status=status.HTTP_200_OK)

        except Exception as e:
            print(f"PUT request error: {e}")
            return Response(
                {"error": f"Failed to update image: {str(e)}"},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )
    
    def extract_ingredients_from_text(self, text):
        """
        Enhanced ingredient extraction that properly separates individual ingredients.
        """
        import re
        ingredients_list = []
        
        # Try to find an ingredients section
        ingredient_section_match = re.search(
            r'(?:ingredients|contains|composed of):?\s*(.*?)(?=(?:nutrition facts|allergens|directions|amount per serving|storage|best by|manufactured by|$))',
            text, re.IGNORECASE | re.DOTALL
        )

        def clean_ingredient_text(ingredient):
            """Clean and normalize ingredient text"""
            # Remove percentages and quantities in parentheses
            ingredient = re.sub(r'\(\d+%?\)', '', ingredient)
            # Remove specific quantity patterns
            ingredient = re.sub(r'\d+%|\d+g|\d+mg|\d+mcg|\d+kcal', '', ingredient)
            # Remove "less than" and "contains" phrases
            ingredient = re.sub(r'less than \d+% of|contains \d+% of', '', ingredient, flags=re.IGNORECASE)
            # Remove nutrition facts headers
            ingredient = re.sub(
                r'^(energy|calories|total fat|saturated fat|trans fat|mufa|pufa|cholesterol|carbohydrate|total sugars|added sugars|dietary fibre|protein|sodium|vitamins|minerals|servings|approximate values)\s*',
                '', ingredient, flags=re.IGNORECASE
            )
            # Clean up extra whitespace
            ingredient = re.sub(r'\s+', ' ', ingredient).strip()
            return ingredient

        def split_ingredient_chunk(chunk):
            """Split ingredient chunk into individual ingredients"""
            # First, clean the chunk
            chunk = clean_ingredient_text(chunk)
            
            # Split by common separators, but be more careful about "and"
            # Only split by "and" if it's not part of a compound name
            parts = re.split(r',|;|\.', chunk)
            
            result = []
            for part in parts:
                part = part.strip()
                if not part or len(part) < 2:
                    continue
                
                # Handle "and" more carefully - only split if it's clearly a separator
                # Don't split if "and" is part of a compound name like "salt and pepper"
                if ' and ' in part.lower():
                    # Check if this looks like a compound name or a separator
                    and_parts = part.split(' and ')
                    if len(and_parts) == 2:
                        # If both parts are short, it might be a compound name
                        if len(and_parts[0].strip()) <= 10 and len(and_parts[1].strip()) <= 10:
                            # Keep as one ingredient if it looks like a compound name
                            result.append(part)
                        else:
                            # Split if parts are longer (likely separate ingredients)
                            for subpart in and_parts:
                                subpart = subpart.strip()
                                if subpart and len(subpart) > 2:
                                    result.append(subpart)
                    else:
                        # Multiple "and"s, split them
                        for subpart in and_parts:
                            subpart = subpart.strip()
                            if subpart and len(subpart) > 2:
                                result.append(subpart)
                else:
                    result.append(part)
            
            return result

        if ingredient_section_match:
            ingredients_raw = ingredient_section_match.group(1)
            # Split by commas, semicolons, and periods
            raw_ingredients = re.split(r'[,;.]\s*', ingredients_raw)
            
            for ingredient in raw_ingredients:
                if not ingredient.strip():
                    continue
                    
                # Process each ingredient chunk
                for sub_ing in split_ingredient_chunk(ingredient):
                    if sub_ing and len(sub_ing) > 2:
                        # Additional cleaning for individual ingredients
                        clean_ing = clean_ingredient_text(sub_ing)
                        if clean_ing and len(clean_ing) > 2:
                            ingredients_list.append(clean_ing)
        else:
            # Fallback: split the whole text, but filter out obvious junk
            raw_ingredients = re.split(r'[,;.\n]\s*', text)
            for ingredient in raw_ingredients:
                clean_ingredient = clean_ingredient_text(ingredient)
                if len(clean_ingredient) > 2 and not re.match(r'^\d+$', clean_ingredient):
                    ingredients_list.append(clean_ingredient)
        
        # Remove duplicates while preserving order - use case-insensitive comparison
        seen = set()
        unique_ingredients = []
        for ing in ingredients_list:
            ing_lower = ing.lower().strip()
            if ing_lower not in seen:
                seen.add(ing_lower)
                unique_ingredients.append(ing.strip())
        
        return unique_ingredients

    def get_ai_health_insight_and_expert_advice(self, user, nutrition_data, flagged_ingredients):
        health_prompt = f"""
        You are a certified health and nutrition expert.

        User Profile:
        Diet: {user.Dietary_preferences}
        Health Conditions: {user.Health_conditions}
        Allergies: {user.Allergies}

        Product Nutrition: {nutrition_data}
        Flagged Ingredients: {flagged_ingredients}

        Give a short health insight: safety, red flags, and user-friendly advice.
        """

        expert_prompt = f"""
        You are a food science expert. Based on the nutrition data and flagged ingredients below, give a detailed expert-level opinion with technical insight.

        Nutrition Data: {nutrition_data}
        Flagged Ingredients: {flagged_ingredients}
        """

        ai_health_insight = self.call_openai(health_prompt)
        expert_advice = self.call_openai(expert_prompt)

        return {"ai_health_insight": ai_health_insight, "expert_advice": expert_advice}

    def call_openai(self, prompt):
        try:
            client = OpenAI(
                base_url="https://api.openai.com/v1",
                api_key=os.getenv("OPENAI_API_KEY"),
            )

            completion = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "You are an expert in food science and health."},
                    {"role": "user", "content": prompt},
                ],
            )
            return completion.choices[0].message.content.strip()
        except Exception as e:
            print(f"OpenAI error: {str(e)}")  # Add error logging
            return f"OpenAI error: {str(e)}"

    async def validate_product_safety(self, user, ingredients_list):
        """
        Categorize ingredients using OpenAI based on user profile (allergies, dietary preferences, medical conditions)
        into Go, No-Go, and Caution categories.
        """
        try:
            # Get OpenAI categorization
            categorization = self.categorize_ingredients_with_openai(user, ingredients_list)
            # Remove duplicates across categories - ensure each ingredient appears only once
            categorization = self._deduplicate_categorization(categorization)
            
            go_ingredients = categorization.get('go', [])
            no_go_ingredients = categorization.get('no_go', [])
            caution_ingredients = categorization.get('caution', [])
            
            # Add EFSA data to each ingredient for consistency with existing structure
            efsa_data_cache = {}
            for category in [go_ingredients, no_go_ingredients, caution_ingredients]:
                for ingredient_data in category:
                    ingredient_name = ingredient_data.get('ingredient', '')
                    try:
                        efsa_data = fetch_efsa_openfoodtox_data(ingredient_name)
                        efsa_data_cache[ingredient_name] = efsa_data or {}
                        ingredient_data['efsa_data'] = efsa_data or {}
                    except Exception as e:
                        print(f"EFSA error for {ingredient_name}: {e}")
                        efsa_data_cache[ingredient_name] = {
                            'found': False,
                            'error': f'EFSA query failed: {str(e)}',
                            'source': 'EFSA OpenFoodTox Database'
                        }
                        ingredient_data['efsa_data'] = efsa_data_cache[ingredient_name]
            
            # Determine overall safety status
            if no_go_ingredients:
                safety_status = "UNSAFE"
            elif caution_ingredients:
                safety_status = "CAUTION"
            else:
                safety_status = "SAFE"
            
            return safety_status, go_ingredients, caution_ingredients, no_go_ingredients, efsa_data_cache
            
        except Exception as e:
            print(f"OpenAI categorization failed: {e}")
            # Fallback to basic categorization
            fallback_result = self._fallback_categorization(user, ingredients_list)
            fallback_result = self._deduplicate_categorization(fallback_result)
            
            go_ingredients = fallback_result.get('go', [])
            no_go_ingredients = fallback_result.get('no_go', [])
            caution_ingredients = fallback_result.get('caution', [])
            
            # Add empty EFSA data for fallback
            efsa_data_cache = {}
            for category in [go_ingredients, no_go_ingredients, caution_ingredients]:
                for ingredient_data in category:
                    ingredient_data['efsa_data'] = {}
            
            # Determine overall safety status
            if no_go_ingredients:
                safety_status = "UNSAFE"
            elif caution_ingredients:
                safety_status = "CAUTION"
            else:
                safety_status = "SAFE"
            
            return safety_status, go_ingredients, caution_ingredients, no_go_ingredients, efsa_data_cache

    def _deduplicate_categorization(self, categorization):
        """
        Remove duplicate ingredients across categories, keeping the highest priority category.
        Priority order: no_go > caution > go
        """
        seen_ingredients = set()
        deduplicated = {
            'go': [],
            'no_go': [],
            'caution': []
        }
        
        # Process in priority order: no_go first, then caution, then go
        priority_order = ['no_go', 'caution', 'go']
        
        for category in priority_order:
            for item in categorization.get(category, []):
                if isinstance(item, dict) and 'ingredient' in item:
                    ing_lower = item['ingredient'].lower().strip()
                    if ing_lower not in seen_ingredients:
                        seen_ingredients.add(ing_lower)
                        deduplicated[category].append(item)
                elif isinstance(item, str):
                    # Handle string format for backward compatibility
                    ing_lower = item.lower().strip()
                    if ing_lower not in seen_ingredients:
                        seen_ingredients.add(ing_lower)
                        deduplicated[category].append({
                            "ingredient": item,
                            "reasons": ["Categorized as " + category.replace('_', ' ').title()]
                        })
        
        return deduplicated

    def _fallback_categorization(self, user, ingredients_list):
        """
        Fallback categorization method when OpenAI fails.
        """
        allergies = [a.strip().lower() for a in user.Allergies.split(",") if a.strip()] if user.Allergies else []
        dietary_preferences = [d.strip().lower() for d in user.Dietary_preferences.split(",") if d.strip()] if user.Dietary_preferences else []
        health_conditions = [h.strip().lower() for h in user.Health_conditions.split(",") if h.strip()] if user.Health_conditions else []
        
        go_ingredients = []
        no_go_ingredients = []
        caution_ingredients = []
        
        for ingredient in ingredients_list:
            ing_lower = ingredient.lower()
            reasons = []
            
            # Check allergies
            if any(allergen in ing_lower for allergen in allergies):
                reasons.append("Allergen")
            
            # Check dietary preferences
            if dietary_preferences:
                if 'vegan' in dietary_preferences and any(animal in ing_lower for animal in ['milk', 'egg', 'meat', 'fish', 'gelatin', 'honey']):
                    reasons.append("Non-vegan")
                elif 'vegetarian' in dietary_preferences and any(animal in ing_lower for animal in ['meat', 'fish', 'gelatin']):
                    reasons.append("Non-vegetarian")
            
            # Check health conditions
            if health_conditions:
                if 'diabetes' in health_conditions and 'sugar' in ing_lower:
                    reasons.append("High sugar")
                elif 'hypertension' in health_conditions and 'salt' in ing_lower:
                    reasons.append("High sodium")
            
            # Categorize based on reasons
            if reasons:
                if "Allergen" in reasons:
                    no_go_ingredients.append({
                        "ingredient": ingredient,
                        "reasons": reasons
                    })
                else:
                    caution_ingredients.append({
                        "ingredient": ingredient,
                        "reasons": reasons
                    })
            else:
                go_ingredients.append({
                    "ingredient": ingredient,
                    "reasons": ["Safe"]
                })
        
        result = {
            "go": go_ingredients,
            "no_go": no_go_ingredients,
            "caution": caution_ingredients
        }

        # Apply deduplication to ensure each ingredient appears only once
        return self._deduplicate_categorization(result)
    
    async def get_edamam_info(self, ingredient):
        try:
            url = (
                f"https://api.edamam.com/api/food-database/v2/parser"
                f"?app_id={EDAMAM_APP_ID}&app_key={EDAMAM_APP_KEY}&ingr={ingredient}"
            )
            connector = get_ssl_connector()
            async with aiohttp.ClientSession(connector=connector) as session:
                async with session.get(url) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        parsed = data.get("parsed") or data.get("hints")
                        if parsed:
                            food = parsed[0]["food"] if "food" in parsed[0] else parsed[0].get("food", {})
                            return {
                                "healthLabels": [h.lower() for h in food.get("healthLabels", [])],
                                "cautions": [c.lower() for c in food.get("cautions", [])]
                            }
        except Exception as e:
            print(f"Edamam API error for ingredient {ingredient}: {e}")
            # Return empty result on error to prevent app crash
        return {"healthLabels": [], "cautions": []}
    
    def get_ai_health_insight_and_expert_advice_fast(self, user, nutrition_data, flagged_ingredients):
        """
        AI-Powered Health Insight Section - 5-Phase Maturity Model
        
        Phase 1: Foundation Layer - Basic input-output functionality
        Phase 2: Risk Identification Layer - Structured Problem List
        Phase 3: Recommendation Layer - Management & Recommendations
        Phase 4: Diagnostic Impression Layer - Transparent reasoning
        Phase 5: Continuous Learning - Adaptive intelligence
        """
        import json
        import hashlib
        from concurrent.futures import ThreadPoolExecutor, TimeoutError
        
        # Create comprehensive cache key
        key_data = {
            'ingredients': sorted(flagged_ingredients),
            'nutrition': nutrition_data,
            'diet': user.Dietary_preferences,
            'health': user.Health_conditions,
            'allergies': user.Allergies,
            'user_id': user.id
        }
        cache_key = hashlib.sha256(json.dumps(key_data, sort_keys=True).encode()).hexdigest()
        
        if hasattr(self, 'ai_cache') and cache_key in self.ai_cache:
            return self.ai_cache[cache_key]
        
        try:
            # Phase 1: Foundation Layer - Parse inputs into structured data
            structured_data = self._parse_inputs_to_structured_data(user, nutrition_data, flagged_ingredients)
            
            # Phase 2: Risk Identification Layer - Generate Problem List
            problem_list = self._generate_problem_list(structured_data)
            
            # Phase 3: Recommendation Layer - Generate Management Plan
            recommendations = self._generate_recommendations(structured_data, problem_list)
            
            # Phase 4: Diagnostic Impression Layer - Generate Assessment
            assessment = self._generate_diagnostic_impression(structured_data, problem_list, recommendations)
            
            # Phase 5: Generate structured narrative blocks
            health_insight = self._generate_structured_narrative_blocks(
                structured_data, problem_list, recommendations, assessment
            )
            
            result = {
                "ai_health_insight": health_insight["bluf_insight"],  # Backward compatibility
                "expert_advice": health_insight["main_insight"],      # Backward compatibility
                "structured_health_analysis": {
                    "bluf_insight": health_insight["bluf_insight"],
                    "main_insight": health_insight["main_insight"],
                    "deeper_reference": health_insight["deeper_reference"],
                    "disclaimer": health_insight["disclaimer"],
                    "problem_list": problem_list,
                    "recommendations": recommendations,
                    "assessment": assessment,
                    "phase": "AI Maturity - Full 5-Phase Analysis"
                }
            }
            
            # Cache the result
            if hasattr(self, 'ai_cache'):
                self.ai_cache[cache_key] = result
            
            return result
            
        except Exception as e:
            print(f"AI Health Insight error: {e}")
            # Fallback to basic insight
            return {
                "ai_health_insight": "AI analysis temporarily unavailable. Please consult healthcare providers for personalized guidance.",
                "expert_advice": "Unable to generate comprehensive analysis. Consider reviewing ingredient lists and consulting healthcare providers.",
                "structured_health_analysis": {
                    "bluf_insight": "AI analysis temporarily unavailable. Please consult healthcare providers for personalized guidance.",
                    "main_insight": "Unable to generate comprehensive analysis. Consider reviewing ingredient lists and consulting healthcare providers.",
                    "deeper_reference": "Service temporarily unavailable. Please consult healthcare providers for medical advice.",
                    "disclaimer": "Informational, not diagnostic. Consult healthcare providers for medical advice.",
                    "error": "AI service unavailable",
                    "phase": "Fallback Mode"
                }
            }
    
    def _parse_inputs_to_structured_data(self, user, nutrition_data, flagged_ingredients):
        """Phase 1: Foundation Layer - Parse inputs into structured JSON objects"""
        return {
            "user_profile": {
                "demographics": {
                    "age_group": getattr(user, 'age_group', 'Not specified'),
                    "gender": getattr(user, 'gender', 'Not specified'),
                    "activity_level": getattr(user, 'activity_level', 'Not specified')
                },
                "health_conditions": user.Health_conditions or 'None',
                "allergies": user.Allergies or 'None',
                "dietary_preferences": user.Dietary_preferences or 'None',
                "medications": getattr(user, 'Medications', 'None'),
                "pregnancy_status": getattr(user, 'pregnancy_status', 'Not specified')
            },
            "product_data": {
                "nutrition_facts": nutrition_data,
                "flagged_ingredients": flagged_ingredients,
                "total_ingredients": len(flagged_ingredients),
                "nutrition_summary": self._extract_nutrition_summary(nutrition_data)
            },
            "risk_indicators": self._identify_baseline_risks(user, nutrition_data, flagged_ingredients)
        }
    
    def _extract_nutrition_summary(self, nutrition_data):
        """Extract key nutritional values for analysis"""
        summary = {}
        if nutrition_data:
            # Extract numeric values for key nutrients
            for nutrient, value in nutrition_data.items():
                if isinstance(value, str) and any(char.isdigit() for char in value):
                    try:
                        # Extract numeric value
                        numeric_value = float(''.join(filter(str.isdigit, str(value).split()[0])))
                        summary[nutrient] = {
                            "value": numeric_value,
                            "unit": value.split()[-1] if len(value.split()) > 1 else "",
                            "raw_value": value
                        }
                    except:
                        summary[nutrient] = {"value": 0, "unit": "", "raw_value": value}
        return summary
    
    def _identify_baseline_risks(self, user, nutrition_data, flagged_ingredients):
        """Identify baseline health risks from nutrition and ingredients"""
        risks = {
            "high_sodium": False,
            "high_sugar": False,
            "high_saturated_fat": False,
            "allergen_exposure": False,
            "dietary_conflict": False,
            "health_condition_risk": False
        }
        
        # Check nutrition-based risks
        if nutrition_data:
            sodium_val = nutrition_data.get('Sodium', '')
            if sodium_val and any(char.isdigit() for char in str(sodium_val)):
                try:
                    sodium_num = float(''.join(filter(str.isdigit, str(sodium_val).split()[0])))
                    if sodium_num > 600:  # High sodium threshold
                        risks["high_sodium"] = True
                except:
                    pass
            
            sugar_val = nutrition_data.get('Sugars', '') or nutrition_data.get('Added Sugars', '')
            if sugar_val and any(char.isdigit() for char in str(sugar_val)):
                try:
                    sugar_num = float(''.join(filter(str.isdigit, str(sugar_val).split()[0])))
                    if sugar_num > 15:  # High sugar threshold
                        risks["high_sugar"] = True
                except:
                    pass
            
            sat_fat_val = nutrition_data.get('Saturated Fat', '')
            if sat_fat_val and any(char.isdigit() for char in str(sat_fat_val)):
                try:
                    sat_fat_num = float(''.join(filter(str.isdigit, str(sat_fat_val).split()[0])))
                    if sat_fat_num > 5:  # High saturated fat threshold
                        risks["high_saturated_fat"] = True
                except:
                    pass
        
        # Check allergen exposure
        if user.Allergies and flagged_ingredients:
            user_allergies = [a.strip().lower() for a in user.Allergies.split(",") if a.strip()]
            for ingredient in flagged_ingredients:
                if any(allergen in str(ingredient).lower() for allergen in user_allergies):
                    risks["allergen_exposure"] = True
                    break
        
        # Check dietary conflicts
        if user.Dietary_preferences and flagged_ingredients:
            dietary_prefs = [d.strip().lower() for d in user.Dietary_preferences.split(",") if d.strip()]
            if 'vegan' in dietary_prefs:
                non_vegan_ingredients = ['milk', 'egg', 'meat', 'fish', 'gelatin', 'honey', 'whey', 'casein']
                for ingredient in flagged_ingredients:
                    if any(nv in str(ingredient).lower() for nv in non_vegan_ingredients):
                        risks["dietary_conflict"] = True
                        break
            elif 'vegetarian' in dietary_prefs:
                non_vegetarian_ingredients = ['meat', 'fish', 'gelatin']
                for ingredient in flagged_ingredients:
                    if any(nv in str(ingredient).lower() for nv in non_vegetarian_ingredients):
                        risks["dietary_conflict"] = True
                        break
        
        # Check health condition risks
        if user.Health_conditions and nutrition_data:
            health_conditions = user.Health_conditions.lower()
            if 'hypertension' in health_conditions and risks["high_sodium"]:
                risks["health_condition_risk"] = True
            elif 'diabetes' in health_conditions and risks["high_sugar"]:
                risks["health_condition_risk"] = True
        
        return risks
    
    def _generate_problem_list(self, structured_data):
        """Phase 2: Risk Identification Layer - Generate structured Problem List"""
        problems = {
            "primary": [],
            "secondary": [],
            "incidental": []
        }
        
        user_profile = structured_data["user_profile"]
        product_data = structured_data["product_data"]
        risk_indicators = structured_data["risk_indicators"]
        
        # Primary concerns (immediate health risks)
        if risk_indicators["allergen_exposure"]:
            problems["primary"].append({
                "issue": "Allergen Exposure",
                "description": "Product contains ingredients you're allergic to",
                "severity": "High",
                "source": "User Allergy Profile"
            })
        
        if risk_indicators["high_sodium"] and "hypertension" in user_profile["health_conditions"].lower():
            problems["primary"].append({
                "issue": "Sodium Overload",
                "description": "High sodium content may worsen hypertension",
                "severity": "High",
                "source": "Nutrition Analysis + Health Conditions"
            })
        
        if risk_indicators["high_sugar"] and "diabetes" in user_profile["health_conditions"].lower():
            problems["primary"].append({
                "issue": "Blood Sugar Impact",
                "description": "High sugar content may affect blood glucose levels",
                "severity": "High",
                "source": "Nutrition Analysis + Health Conditions"
            })
        
        # Secondary concerns (moderate risks)
        if risk_indicators["dietary_conflict"]:
            problems["secondary"].append({
                "issue": "Dietary Preference Conflict",
                "description": "Product doesn't align with your dietary preferences",
                "severity": "Medium",
                "source": "Dietary Preference Analysis"
            })
        
        if risk_indicators["high_sodium"] and "hypertension" not in user_profile["health_conditions"].lower():
            problems["secondary"].append({
                "issue": "High Sodium Content",
                "description": "Elevated sodium may impact cardiovascular health",
                "severity": "Medium",
                "source": "Nutrition Analysis"
            })
        
        if risk_indicators["high_sugar"] and "diabetes" not in user_profile["health_conditions"].lower():
            problems["secondary"].append({
                "issue": "High Sugar Content",
                "description": "Elevated sugar may impact metabolic health",
                "severity": "Medium",
                "source": "Nutrition Analysis"
            })
        
        # Incidental findings (minor concerns)
        if risk_indicators["high_saturated_fat"]:
            problems["incidental"].append({
                "issue": "Saturated Fat Content",
                "description": "Elevated saturated fat may impact cardiovascular health",
                "severity": "Low",
                "source": "Nutrition Analysis"
            })
        
        return problems
    
    def _generate_recommendations(self, structured_data, problem_list):
        """Phase 3: Recommendation Layer - Generate Management & Recommendations"""
        recommendations = {
            "go": [],
            "caution": [],
            "no_go": [],
            "alternatives": [],
            "lifestyle_tips": []
        }
        
        # Determine overall recommendation based on problem list
        if problem_list["primary"]:
            recommendations["no_go"].append({
                "reason": "Primary health concerns identified",
                "action": "Avoid this product",
                "alternatives": "Look for allergen-free or low-sodium alternatives"
            })
        elif problem_list["secondary"]:
            recommendations["caution"].append({
                "reason": "Secondary concerns present",
                "action": "Consume with caution",
                "alternatives": "Consider portion control or alternative products"
            })
        else:
            recommendations["go"].append({
                "reason": "No significant health concerns",
                "action": "Generally safe for consumption",
                "alternatives": "Continue with current dietary patterns"
            })
        
        # Generate specific alternatives based on issues
        for problem in problem_list["primary"] + problem_list["secondary"]:
            if problem["issue"] == "Sodium Overload":
                recommendations["alternatives"].append({
                    "type": "Product Alternative",
                    "suggestion": "Look for 'low sodium' or 'reduced sodium' versions",
                    "target": "< 140mg sodium per serving"
                })
            elif problem["issue"] == "Allergen Exposure":
                recommendations["alternatives"].append({
                    "type": "Product Alternative",
                    "suggestion": "Choose allergen-free certified products",
                    "target": "Products labeled 'free from [allergen]'"
                })
            elif problem["issue"] == "Blood Sugar Impact":
                recommendations["alternatives"].append({
                    "type": "Product Alternative",
                    "suggestion": "Choose sugar-free or low-sugar alternatives",
                    "target": "< 5g sugar per serving"
                })
            elif problem["issue"] == "Dietary Preference Conflict":
                recommendations["alternatives"].append({
                    "type": "Product Alternative",
                    "suggestion": "Look for products that match your dietary preferences",
                    "target": "Certified vegan/vegetarian products"
                })
        
        # Generate lifestyle tips
        if structured_data["risk_indicators"]["high_sodium"]:
            recommendations["lifestyle_tips"].append({
                "tip": "WHO recommends <2000mg sodium per day",
                "source": "WHO Guidelines"
            })
        
        if structured_data["risk_indicators"]["high_sugar"]:
            recommendations["lifestyle_tips"].append({
                "tip": "WHO recommends <10% of total energy from free sugars",
                "source": "WHO Guidelines"
            })
        
        return recommendations
    
    def _generate_diagnostic_impression(self, structured_data, problem_list, recommendations):
        """Phase 4: Diagnostic Impression Layer - Generate transparent reasoning"""
        assessment = {
            "overall_assessment": "",
            "rationale": "",
            "citations": [],
            "deeper_reference": ""
        }
        
        # Generate overall assessment
        if problem_list["primary"]:
            assessment["overall_assessment"] = "High Risk - Primary health concerns identified"
        elif problem_list["secondary"]:
            assessment["overall_assessment"] = "Moderate Risk - Secondary concerns present"
        else:
            assessment["overall_assessment"] = "Low Risk - No significant health concerns"
        
        # Generate rationale with citations
        rationale_parts = []
        citations = []
        
        if structured_data["risk_indicators"]["high_sodium"]:
            rationale_parts.append("Sodium content exceeds WHO daily limit recommendations")
            citations.append("WHO Guidelines: <2000mg sodium/day")
        
        if structured_data["risk_indicators"]["allergen_exposure"]:
            rationale_parts.append("Contains ingredients identified in user allergy profile")
            citations.append("FDA Food Allergen Labeling Requirements")
        
        if structured_data["risk_indicators"]["high_sugar"]:
            rationale_parts.append("Sugar content exceeds WHO recommendations for free sugars")
            citations.append("WHO Guidelines: <10% total energy from free sugars")
        
        if structured_data["risk_indicators"]["dietary_conflict"]:
            rationale_parts.append("Product conflicts with user dietary preferences")
            citations.append("Dietary Preference Analysis")
        
        assessment["rationale"] = ". ".join(rationale_parts) + "." if rationale_parts else "No significant risk factors identified."
        assessment["citations"] = citations
        
        return assessment
    
    def _generate_structured_narrative_blocks(self, structured_data, problem_list, recommendations, assessment):
        """Generate the three mandatory narrative blocks"""
        
        # Block 1: Personalized Insight Block (BLUF) - 30-80 words
        bluf = self._generate_bluf_insight(structured_data, problem_list)
        
        # Block 2: Main Insight - 50-100 words
        main_insight = self._generate_main_insight(structured_data, problem_list, recommendations)
        
        # Block 3: Deeper Reference - 120-200 words
        deeper_reference = self._generate_deeper_reference(structured_data, problem_list, recommendations, assessment)
        
        return {
            "bluf_insight": bluf,
            "main_insight": main_insight,
            "deeper_reference": deeper_reference,
            "disclaimer": "Informational, not diagnostic. Consult healthcare providers for medical advice."
        }
    
    def _generate_bluf_insight(self, structured_data, problem_list):
        """Generate BLUF (Bottom Line Up Front) insight - 30-80 words"""
        user_profile = structured_data["user_profile"]
        product_data = structured_data["product_data"]
        
        if problem_list["primary"]:
            primary_issue = problem_list["primary"][0]["issue"]
            if primary_issue == "Allergen Exposure":
                return f"This product contains ingredients you're allergic to and poses immediate health risks. Avoid consumption to prevent severe allergic reactions including anaphylaxis. Check ingredient labels carefully for allergen-free alternatives and consider carrying emergency medication if accidental exposure occurs."
            elif primary_issue == "Sodium Overload":
                sodium_val = product_data['nutrition_summary'].get('Sodium', {}).get('raw_value', 'unknown')
                return f"High sodium content ({sodium_val}) may significantly worsen your hypertension and increase cardiovascular risk. Regular consumption could lead to elevated blood pressure, heart disease, and stroke. Consider low-sodium alternatives to protect your cardiovascular health and manage your condition effectively."
            elif primary_issue == "Blood Sugar Impact":
                sugar_val = product_data['nutrition_summary'].get('Sugars', {}).get('raw_value', 'unknown')
                return f"High sugar content ({sugar_val}) may cause dangerous blood glucose spikes and affect your diabetes management. This could lead to hyperglycemia, increased HbA1c levels, and long-term complications. Consider sugar-free alternatives and monitor blood glucose levels closely for better diabetes control."
        elif problem_list["secondary"]:
            secondary_issue = problem_list["secondary"][0]["issue"]
            if secondary_issue == "Dietary Preference Conflict":
                return f"This product doesn't align with your dietary preferences and may compromise your nutritional goals. Consume with caution or seek alternative products that match your dietary needs. Consider the long-term impact on your health objectives and lifestyle choices."
            elif secondary_issue == "High Sodium Content":
                return f"Elevated sodium content may impact cardiovascular health over time. Regular consumption could contribute to hypertension, water retention, and increased stroke risk. Consider reduced-sodium alternatives or limit portion size to maintain optimal cardiovascular health."
            elif secondary_issue == "High Sugar Content":
                return f"High sugar content may impact metabolic health and contribute to weight gain, insulin resistance, and increased diabetes risk. Consider low-sugar alternatives or moderate consumption to maintain healthy blood glucose levels and metabolic function."
        else:
            return f"This product appears safe for your health profile with no significant concerns identified. Continue with balanced dietary patterns while maintaining awareness of portion sizes and overall nutritional balance. Regular health monitoring remains important for optimal wellness."

    def _generate_main_insight(self, structured_data, problem_list, recommendations):
        """Generate Main Insight - 50-100 words"""
        user_profile = structured_data["user_profile"]
        product_data = structured_data["product_data"]
        
        if problem_list["primary"]:
            primary_issue = problem_list["primary"][0]["issue"]
            if primary_issue == "Allergen Exposure":
                return f"Due to allergen exposure risk, this product is rated NO-GO for your safety. Your allergy profile indicates sensitivity to ingredients in this product that could trigger severe reactions. WHO and FDA guidelines recommend strict avoidance of known allergens. Consider allergen-free certified alternatives, read labels carefully, and consult with an allergist for personalized guidance and emergency action plans."
            elif primary_issue == "Sodium Overload":
                return f"Due to sodium levels, this product is rated CAUTION for your hypertension management. High sodium content may significantly impact your blood pressure control and cardiovascular health. WHO guidelines recommend <2000mg sodium/day for optimal health. Consider reduced-sodium alternatives, limit portion size, and monitor blood pressure regularly to maintain cardiovascular health and prevent complications."
            elif primary_issue == "Blood Sugar Impact":
                return f"Due to sugar content, this product is rated CAUTION for your diabetes management. High sugar levels may cause blood glucose spikes and affect your long-term diabetes control. WHO guidelines recommend <10% total energy from free sugars. Consider sugar-free alternatives, monitor blood glucose levels, and consult with a dietitian for personalized guidance on carbohydrate management and meal planning."
        elif problem_list["secondary"]:
            return f"Secondary concerns identified with this product that warrant attention. While not immediately harmful, consider alternatives that better align with your health goals and dietary preferences. Monitor portion sizes, frequency of consumption, and overall dietary balance. Consult healthcare providers for personalized dietary recommendations that support your long-term health objectives and lifestyle choices."
        else:
            return f"This product aligns well with your health profile with no significant nutritional concerns identified. Continue with balanced dietary patterns, regular health monitoring, and awareness of portion sizes. Maintain overall dietary balance while considering your specific health conditions and dietary preferences for optimal wellness outcomes."

    def _generate_deeper_reference(self, structured_data, problem_list, recommendations, assessment):
        """Generate Deeper Reference - 120-200 words"""
        user_profile = structured_data["user_profile"]
        product_data = structured_data["product_data"]
        
        reference_parts = []
        
        # Start with assessment rationale
        if assessment["rationale"]:
            reference_parts.append(assessment["rationale"])
        
        # Add specific health condition context
        if user_profile["health_conditions"] != "None":
            reference_parts.append(f"Your health conditions ({user_profile['health_conditions']}) require careful consideration of nutritional choices and regular monitoring by healthcare providers.")
        
        # Add regulatory and scientific context
        if structured_data["risk_indicators"]["high_sodium"]:
            reference_parts.append("EFSA has issued cautionary opinions on long-term sodium intake and cardiovascular risk, recommending daily limits to prevent hypertension and related complications. ClinicalTrials.gov lists ongoing studies investigating sodium reduction strategies and their impact on improved blood pressure outcomes and cardiovascular health.")
        
        if structured_data["risk_indicators"]["allergen_exposure"]:
            reference_parts.append("FDA requires clear labeling of major food allergens under the Food Allergen Labeling and Consumer Protection Act. Cross-contamination risks should be considered even with 'may contain' warnings, and individuals with severe allergies should carry emergency medication and have action plans in place.")
        
        if structured_data["risk_indicators"]["high_sugar"]:
            reference_parts.append("WHO and EFSA have established comprehensive guidelines for free sugar intake to prevent metabolic disorders, obesity, and diabetes. PubMed studies demonstrate strong correlation between high sugar consumption and increased diabetes risk, insulin resistance, and cardiovascular complications.")
        
        # Add dietary preference context
        if user_profile["dietary_preferences"] != "None":
            reference_parts.append(f"Your dietary preferences ({user_profile['dietary_preferences']}) should be respected for optimal health outcomes and personal values alignment.")
        
        # Add evidence-based recommendations
        if recommendations["lifestyle_tips"]:
            for tip in recommendations["lifestyle_tips"]:
                reference_parts.append(f"{tip['tip']} (Source: {tip['source']})")
        
        # Add citations
        if assessment["citations"]:
            reference_parts.append(f"References: {', '.join(assessment['citations'])}")
        
        # Add disclaimer
        reference_parts.append("This analysis is informational only and not a substitute for professional medical advice. Consult healthcare providers for personalized guidance.")
        
        return " ".join(reference_parts)

    def get_ai_health_insight_and_expert_advice(self, user, nutrition_data, flagged_ingredients):
        health_prompt = f"""
        You are a certified health and nutrition expert.

        User Profile:
        Diet: {user.Dietary_preferences}
        Health Conditions: {user.Health_conditions}
        Allergies: {user.Allergies}

        Product Nutrition: {nutrition_data}
        Flagged Ingredients: {flagged_ingredients}

        Give a short health insight: safety, red flags, and user-friendly advice.
        """

        expert_prompt = f"""
        You are a food science expert. Based on the nutrition data and flagged ingredients below, give a detailed expert-level opinion with technical insight.

        Nutrition Data: {nutrition_data}
        Flagged Ingredients: {flagged_ingredients}
        """

        ai_health_insight = self.call_openai(health_prompt)
        expert_advice = self.call_openai(expert_prompt)

        return {"ai_health_insight": ai_health_insight, "expert_advice": expert_advice}

    def call_openai(self, prompt):
        try:
            client = OpenAI(
                base_url="https://api.openai.com/v1",
                api_key=os.getenv("OPENAI_API_KEY"),
            )

            completion = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "You are an expert in food science and health."},
                    {"role": "user", "content": prompt},
                ],
            )
            return completion.choices[0].message.content.strip()
        except Exception as e:
            print(f"OpenAI error: {str(e)}")  # Add error logging
            return f"OpenAI error: {str(e)}"



    def categorize_ingredients_with_openai(self, user, ingredients_list):
        """
        Use OpenAI to categorize ingredients into Go, No-Go, and Caution categories
        based on user's allergies, dietary preferences, and health conditions.
        """
        import json
        import hashlib
        from openai import OpenAI
        import os
        
        # Create cache key for this categorization
        key_data = {
            'ingredients': sorted(ingredients_list),
            'diet': user.Dietary_preferences,
            'allergies': user.Allergies,
            'health': user.Health_conditions
        }
        cache_key = hashlib.sha256(json.dumps(key_data, sort_keys=True).encode()).hexdigest()
        
        # Check cache first
        if cache_key in self.openai_cache:
            return self.openai_cache[cache_key]
        
        try:
            client = OpenAI(
                api_key=os.getenv("OPENAI_API_KEY"),
                timeout=10
            )
            
            # Create detailed prompt for ingredient categorization
            prompt = f"""
            You are a certified nutritionist and food safety expert. Categorize the following ingredients into three categories based on the user's health profile:

            USER PROFILE:
            - Allergies: {user.Allergies or 'None'}
            - Dietary Preferences: {user.Dietary_preferences or 'None'}
            - Health Conditions: {user.Health_conditions or 'None'}

            INGREDIENTS TO CATEGORIZE:
            {', '.join(ingredients_list)}

            CATEGORIES:
            1. GO: Ingredients that are safe and suitable for the user's health profile
            2. NO-GO: Ingredients that are harmful, allergenic, or contraindicated for the user's health profile
            3. CAUTION: Ingredients that may not be ideal but are not strictly forbidden - consume at your own risk

            RESPONSE FORMAT:
            Return a JSON object with exactly this structure:
            {{
                "go": [
                    {{"ingredient": "ingredient_name", "reasons": ["reason1", "reason2"]}}
                ],
                "no_go": [
                    {{"ingredient": "ingredient_name", "reasons": ["reason1", "reason2"]}}
                ],
                "caution": [
                    {{"ingredient": "ingredient_name", "reasons": ["reason1", "reason2"]}}
                ]
            }}

            IMPORTANT RULES:
            - Every ingredient must be categorized into exactly one category
            - Be conservative with safety - when in doubt, categorize as CAUTION or NO-GO
            - Consider cross-contamination risks for severe allergies
            - For dietary preferences, consider both direct ingredients and potential hidden sources
            - Provide specific, actionable reasons for each categorization
            - If an ingredient is not in the provided list, do not include it in the response
            """
            
            completion = client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "You are a certified nutritionist and food safety expert. Always respond with valid JSON."},
                    {"role": "user", "content": prompt},
                ],
                max_tokens=2000,
                temperature=0.1,
            )
            
            content = completion.choices[0].message.content.strip()
            
            # Parse JSON response
            try:
                result = json.loads(content)
                
                # Validate structure
                required_keys = ['go', 'no_go', 'caution']
                if not all(key in result for key in required_keys):
                    raise ValueError("Missing required categories in response")
                
                # Ensure all ingredients are categorized
                categorized_ingredients = set()
                for category in required_keys:
                    for item in result[category]:
                        if 'ingredient' in item:
                            categorized_ingredients.add(item['ingredient'].lower())
                
                # Check if all ingredients are categorized
                all_ingredients = set(ing.lower() for ing in ingredients_list)
                if not categorized_ingredients.issuperset(all_ingredients):
                    # If not all ingredients categorized, add missing ones to caution
                    missing_ingredients = all_ingredients - categorized_ingredients
                    for missing in missing_ingredients:
                        result['caution'].append({
                            "ingredient": missing,
                            "reasons": ["Unable to determine safety - categorized as caution"]
                        })
                
                # Cache the result
                self.openai_cache[cache_key] = result
                return result
                
            except json.JSONDecodeError as e:
                print(f"OpenAI response parsing error: {e}")
                print(f"Raw response: {content}")
                # Fallback to default categorization
                return self._fallback_categorization(user, ingredients_list)
                
        except Exception as e:
            print(f"OpenAI categorization error: {e}")
            # Fallback to default categorization
            return self._fallback_categorization(user, ingredients_list)
    
    def _fallback_categorization(self, user, ingredients_list):
        """
        Fallback categorization when OpenAI is unavailable.
        Uses basic keyword matching based on user profile.
        """
        allergies = [a.strip().lower() for a in user.Allergies.split(",") if a.strip()] if user.Allergies else []
        dietary = [d.strip().lower() for d in user.Dietary_preferences.split(",") if d.strip()] if user.Dietary_preferences else []
        health = [h.strip().lower() for h in user.Health_conditions.split(",") if h.strip()] if user.Health_conditions else []
        
        go_ingredients = []
        no_go_ingredients = []
        caution_ingredients = []
        
        for ingredient in ingredients_list:
            ing_lower = ingredient.lower()
            
            # Check for allergies first (highest priority)
            if any(a in ing_lower for a in allergies):
                no_go_ingredients.append({
                    "ingredient": ingredient,
                    "reasons": ["Allergen detected"]
                })
            # Check for dietary restrictions
            elif any(d not in ing_lower for d in dietary) and dietary:
                caution_ingredients.append({
                    "ingredient": ingredient,
                    "reasons": ["May not align with dietary preferences"]
                })
            # Check for health conditions
            elif any(h in ing_lower for h in health):
                caution_ingredients.append({
                    "ingredient": ingredient,
                    "reasons": ["May affect health conditions"]
                })
            else:
                go_ingredients.append({
                    "ingredient": ingredient,
                    "reasons": ["Appears safe for your profile"]
                })
        
        return {
            "go": go_ingredients,
            "no_go": no_go_ingredients,
            "caution": caution_ingredients
        }

    
            
    def get_expert_ai_conclusion(self, user, nutrition_data, no_go_ingredients, caution_ingredients, 
                                safety_status, medlineplus_summary=None, pubchem_summary=None, 
                                pubmed_articles=None, clinical_trials=None, efsa_data_cache=None, 
                                fsa_data=None, medical_recommendations=None):
        """
        Generate Expert AI Conclusion following the IngredientIQ procedural guide.
        
        Phase D - Maturity: Consultative Synthesis
        - Prognosis: Future-oriented risk projection (120-150 words)
        - Patient Counseling & Shared Decision-Making: Plain-language empowerment (120-150 words)
        - Total: 270 words
        """
        import json
        import hashlib
        from concurrent.futures import ThreadPoolExecutor, TimeoutError
        
        # Create cache key for this conclusion
        key_data = {
            'user_profile': {
                'diet': user.Dietary_preferences,
                'health': user.Health_conditions,
                'allergies': user.Allergies
            },
            'nutrition': nutrition_data,
            'safety_status': safety_status,
            'no_go_count': len(no_go_ingredients) if no_go_ingredients else 0,
            'caution_count': len(caution_ingredients) if caution_ingredients else 0,
        }
        cache_key = f"expert_conclusion_{hashlib.sha256(json.dumps(key_data, sort_keys=True).encode()).hexdigest()}"
        
        # Check cache first
        if hasattr(self, 'ai_cache') and cache_key in self.ai_cache:
            return self.ai_cache[cache_key]
        
        # Prepare context data for the AI
        user_health_context = {
            'dietary_preferences': user.Dietary_preferences or 'None specified',
            'health_conditions': user.Health_conditions or 'None specified',
            'allergies': user.Allergies or 'None specified'
        }
        
        # Extract key nutritional concerns
        nutrition_concerns = []
        if nutrition_data:
            # Check for high sodium
            sodium_val = nutrition_data.get('Sodium', '')
            if sodium_val and any(char.isdigit() for char in str(sodium_val)):
                try:
                    sodium_num = float(''.join(filter(str.isdigit, str(sodium_val).split()[0])))
                    if sodium_num > 600:  # High sodium threshold
                        nutrition_concerns.append(f"high sodium ({sodium_val})")
                except:
                    pass
            
            # Check for high sugar
            sugar_val = nutrition_data.get('Sugars', '') or nutrition_data.get('Added Sugars', '')
            if sugar_val and any(char.isdigit() for char in str(sugar_val)):
                try:
                    sugar_num = float(''.join(filter(str.isdigit, str(sugar_val).split()[0])))
                    if sugar_num > 15:  # High sugar threshold
                        nutrition_concerns.append(f"high sugar content ({sugar_val})")
                except:
                    pass
            
            # Check for high saturated fat
            sat_fat_val = nutrition_data.get('Saturated Fat', '')
            if sat_fat_val and any(char.isdigit() for char in str(sat_fat_val)):
                try:
                    sat_fat_num = float(''.join(filter(str.isdigit, str(sat_fat_val).split()[0])))
                    if sat_fat_num > 5:  # High saturated fat threshold
                        nutrition_concerns.append(f"elevated saturated fat ({sat_fat_val})")
                except:
                    pass
        
        # Risk trajectory assessment
        risk_level = "low"
        if safety_status == "UNSAFE" or len(no_go_ingredients) > 0:
            risk_level = "high"
        elif safety_status == "CAUTION" or len(caution_ingredients) > 0:
            risk_level = "moderate"
        
        # Prepare evidence sources for citations
        evidence_sources = []
        if efsa_data_cache and any(data.get('found') for data in efsa_data_cache.values()):
            evidence_sources.append("EFSA OpenFoodTox Database")
        if medical_recommendations and medical_recommendations.get('found'):
            evidence_sources.append("SNOMED CT & ICD-10 Clinical Guidelines")
        if fsa_data and fsa_data.get('found'):
            evidence_sources.append("UK FSA FHRS")
        
        # Create the expert conclusion prompt
        prompt = f"""
        You are a senior consulting physician providing a final consultative summary to a patient about a food product they scanned.

        CRITICAL INSTRUCTIONS:
        - Maximum 270 words total
        - Structure: Prognosis (120-150 words) + Patient Counseling (120-150 words)
        - Focus on future health impact and user empowerment
        - Use plain language, avoid technical jargon
        - DO NOT repeat diagnostic details (already provided elsewhere)
        - Include selective citations only when needed for credibility

        PATIENT PROFILE:
        - Dietary Preferences: {user_health_context['dietary_preferences']}
        - Health Conditions: {user_health_context['health_conditions']}
        - Allergies: {user_health_context['allergies']}

        PRODUCT ASSESSMENT:
        - Safety Status: {safety_status}
        - Risk Level: {risk_level}
        - Flagged Ingredients: {len(no_go_ingredients)} unsafe, {len(caution_ingredients)} caution
        - Nutritional Concerns: {', '.join(nutrition_concerns) if nutrition_concerns else 'None identified'}

        EVIDENCE SOURCES AVAILABLE:
        {', '.join(evidence_sources) if evidence_sources else 'Standard nutritional guidelines'}

        REQUIRED OUTPUT FORMAT:
        
        **PROGNOSIS:**
        [Explain disease trajectory, complications, long-term outcomes based on regular consumption patterns. Connect to user's specific health profile. Reference WHO, EFSA, or FDA guidelines when relevant.]

        **PATIENT COUNSELING & SHARED DECISION-MAKING:**
        [Plain-language advice, food-as-medicine framing, lifestyle guidance. Must include empowerment language like "Here are steps you can take," "This aligns with your preferences," "Safer choices include..." Provide specific, actionable alternatives.]

        Remember: Be consultative, forward-looking, and empowering. Focus on what the user can DO, not just what to avoid.
        """
        
        def openai_call():
            from openai import OpenAI
            import os
            
            client = OpenAI(
                api_key=os.getenv("OPENAI_API_KEY"),
                timeout=15  # Longer timeout for comprehensive conclusion
            )
            
            try:
                completion = client.chat.completions.create(
                    model="gpt-4",  # Use GPT-4 for highest quality consultative response
                    messages=[
                        {
                            "role": "system", 
                            "content": "You are a senior consulting physician specializing in preventive medicine and nutrition. You provide final consultative summaries that are forward-looking, empowering, and accessible to patients."
                        },
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=400,  # Allow for comprehensive response
                    temperature=0.3,  # Lower temperature for more consistent medical advice
                )
                
                conclusion_text = completion.choices[0].message.content.strip()
                
                # Parse the response to extract prognosis and counseling sections
                prognosis = ""
                counseling = ""
                
                if "**PROGNOSIS" in conclusion_text and "**PATIENT COUNSELING" in conclusion_text:
                    parts = conclusion_text.split("**PATIENT COUNSELING")
                    prognosis = parts[0].replace("**PROGNOSIS", "").replace("**:", "").replace(":", "").strip()
                    counseling = parts[1].replace("& SHARED DECISION-MAKING", "").replace("**:", "").replace(":", "").strip()
                    
                    # Clean up any remaining formatting artifacts
                    import re
                    # Remove any leading asterisks, colons, newlines, and whitespace
                    prognosis = re.sub(r'^[*:\s\n]+', '', prognosis).strip()
                    counseling = re.sub(r'^[*:\s\n]+', '', counseling).strip()
                    
                    # Additional cleaning to remove any remaining artifacts
                    prognosis = re.sub(r'^\*+\s*:?\s*', '', prognosis).strip()
                    counseling = re.sub(r'^\*+\s*:?\s*', '', counseling).strip()
                else:
                    # Fallback parsing
                    sections = conclusion_text.split("\n\n")
                    if len(sections) >= 2:
                        prognosis = sections[0].strip()
                        counseling = sections[1].strip()
                    else:
                        # If parsing fails, split the content roughly in half
                        words = conclusion_text.split()
                        mid_point = len(words) // 2
                        prognosis = " ".join(words[:mid_point])
                        counseling = " ".join(words[mid_point:])
                
                # Word count validation and trimming
                prognosis_words = prognosis.split()
                counseling_words = counseling.split()
                
                if len(prognosis_words) > 150:
                    prognosis = " ".join(prognosis_words[:150])
                if len(counseling_words) > 150:
                    counseling = " ".join(counseling_words[:150])
                
                # Ensure minimum content
                if len(prognosis_words) < 50:
                    prognosis = f"Based on your health profile and this product's composition, regular consumption may impact your {user_health_context['health_conditions'] or 'overall health'}. The {risk_level} risk level suggests careful consideration of frequency and portion control in your dietary planning."
                
                if len(counseling_words) < 50:
                    counseling = f"Here are steps you can take: Consider alternative products that align with your {user_health_context['dietary_preferences'] or 'nutritional needs'}. Safer choices include whole food options with minimal processing. This approach supports your health goals while respecting your preferences."
                
                result = {
                    "expert_conclusion": {
                        "prognosis": prognosis.strip(),
                        "patient_counseling": counseling.strip(),
                        "total_words": len(prognosis.split()) + len(counseling.split()),
                        "risk_level": risk_level,
                        "evidence_sources": evidence_sources
                    }
                }
                
                return result
                
            except Exception as e:
                print(f"Expert AI Conclusion error: {e}")
                # Fallback conclusion
                return {
                    "expert_conclusion": {
                        "prognosis": f"Based on your health profile, this product presents a {risk_level} risk level for regular consumption. Consider your individual tolerance and health goals when making dietary decisions.",
                        "patient_counseling": "Here are steps you can take: Consult with healthcare providers about products that align with your specific health needs. Prioritize whole foods and minimally processed alternatives when possible.",
                        "total_words": 50,
                        "risk_level": risk_level,
                        "evidence_sources": evidence_sources,
                        "note": "AI service generated fallback response"
                    }
                }
        
        # Execute with timeout
        with ThreadPoolExecutor(max_workers=1) as executor:
            future = executor.submit(openai_call)
            try:
                result = future.result(timeout=20)  # 20-second timeout for comprehensive analysis
                
                # Cache the result
                if hasattr(self, 'ai_cache'):
                    self.ai_cache[cache_key] = result
                
                return result
                
            except TimeoutError:
                return {
                    "expert_conclusion": {
                        "prognosis": "Our AI analysis is taking longer than expected. Based on the available product information, we recommend considering your personal health goals and dietary preferences when making your choice.",
                        "patient_counseling": "Here are steps you can take: Review the ingredient list carefully, check for any allergens or ingredients you prefer to avoid, and consult with healthcare providers for personalized dietary advice.",
                        "total_words": 30,
                        "risk_level": risk_level,
                        "evidence_sources": evidence_sources,
                        "note": "Analysis in progress - simplified response"
                    }
                }
            except Exception as e:
                print(f"Expert conclusion execution error: {e}")
                return {
                    "expert_conclusion": {
                        "prognosis": "We're experiencing technical difficulties with our AI analysis. Based on the product information available, please consider your personal dietary preferences and health conditions when making your decision.",
                        "patient_counseling": "Here are steps you can take: Focus on products that clearly align with your dietary preferences and health conditions. When in doubt, choose products with simpler ingredient lists and consult with healthcare providers for personalized guidance.",
                        "total_words": 35,
                        "risk_level": risk_level,
                        "evidence_sources": evidence_sources,
                        "note": "Technical issue - basic response"
                    }
                }

    def run_in_thread_pool(self, func, *args):
        with ThreadPoolExecutor() as executor:
            return executor.submit(func, *args).result()

    def save_image(self, image_content):
        try:
            image_name = f"food_labels/{uuid.uuid4()}.jpg"
            image_path = default_storage.save(image_name, ContentFile(image_content))
            image_url = default_storage.url(image_path)
            # Clean up the URL if needed
            if isinstance(image_url, str):
                image_url = image_url.replace("https//", "")
            return image_url, image_path
        except Exception as e:
            print(f"Error saving image: {e}")
            return None, None

    async def save_scan_history(self, user, image_url, extracted_text, nutrition_data, ai_results, safety_status, flagged_ingredients, product_name, product_image_url, product_image_small_url, product_image_thumb_url, actual_ingredients, go_ingredients=None, caution_ingredients=None, no_go_ingredients=None, expert_ai_conclusion=None, structured_health_analysis=None, efsa_data=None, fsa_hygiene_data=None, medical_condition_recommendations=None):
        # Create a comprehensive nutrition_data dictionary that includes ALL scan data
        # Keep nutrition_data clean - only nutrition facts, not ingredients
        clean_nutrition_data = dict(nutrition_data) if nutrition_data else {}
        
        comprehensive_nutrition_data = {
            **clean_nutrition_data,
            "ai_health_insight": ai_results.get("ai_health_insight", ""),
            "expert_advice": ai_results.get("expert_advice", ""),
            "product_name": product_name,
            "product_image": {
                "full": product_image_url
            },
            "go_ingredients": go_ingredients or [],
            "caution_ingredients": caution_ingredients or [],
            "no_go_ingredients": no_go_ingredients or [],
            "actual_ingredients": actual_ingredients or [],
            # Store ALL comprehensive scan data for history
            "expert_ai_conclusion": expert_ai_conclusion or {},
            "structured_health_analysis": structured_health_analysis or {},
            "efsa_data": efsa_data or {},
            "fsa_hygiene_data": fsa_hygiene_data or {},
            "medical_condition_recommendations": medical_condition_recommendations or {}
        }

        scan = await sync_to_async(FoodLabelScan.objects.create)(
            user=user,
            image_url=image_url,
            extracted_text=extracted_text,
            product_name=product_name,
            product_image_url=product_image_url,
            nutrition_data=comprehensive_nutrition_data,
            safety_status=safety_status,
            flagged_ingredients=flagged_ingredients,
        )
        
        # Scan count is automatically incremented by Django signal when FoodLabelScan is created
        
        return scan

    def get_ai_health_insight_and_expert_advice(self, user, nutrition_data, flagged_ingredients):
        health_prompt = f"""
        You are a certified health and nutrition expert.

        User Profile:
        Diet: {user.Dietary_preferences}
        Health Conditions: {user.Health_conditions}
        Allergies: {user.Allergies}

        Product Nutrition: {nutrition_data}
        Flagged Ingredients: {flagged_ingredients}

        Give a short health insight: safety, red flags, and user-friendly advice.
        """

        expert_prompt = f"""
        You are a food science expert. Based on the nutrition data and flagged ingredients below, give a detailed expert-level opinion with technical insight.

        Nutrition Data: {nutrition_data}
        Flagged Ingredients: {flagged_ingredients}
        """

        ai_health_insight = self.call_openai(health_prompt)
        expert_advice = self.call_openai(expert_prompt)

        return {"ai_health_insight": ai_health_insight, "expert_advice": expert_advice}

    def call_openai(self, prompt):
        try:
            client = OpenAI(
                base_url="https://api.openai.com/v1",
                api_key=os.getenv("OPENAI_API_KEY"),
            )

            completion = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "You are an expert in food science and health."},
                    {"role": "user", "content": prompt},
                ],
            )
            return completion.choices[0].message.content.strip()
        except Exception as e:
            print(f"OpenAI error: {str(e)}")  # Add error logging
            return f"OpenAI error: {str(e)}"

    async def validate_product_safety(self, user, ingredients_list):
        if USE_STATIC_INGREDIENT_SAFETY:
            dietary = [d.strip().lower() for d in user.Dietary_preferences.split(",") if d.strip()] if user.Dietary_preferences else []
            health = [h.strip().lower() for h in user.Health_conditions.split(",") if h.strip()] if user.Health_conditions else []
            allergies = [a.strip().lower() for a in user.Allergies.split(",") if a.strip()] if user.Allergies else []
            go_ingredients, caution_ingredients, no_go_ingredients = [], [], []
            for ingredient in ingredients_list:
                ing_lower = ingredient.lower()
                if any(a in ing_lower for a in allergies):
                    no_go_ingredients.append(ingredient + " (Allergen)")
                elif any(d not in ing_lower for d in dietary) and dietary:
                    caution_ingredients.append(ingredient + " (Dietary)")
                elif any(h in ing_lower for h in health):
                    caution_ingredients.append(ingredient + " (Health)")
                else:
                    go_ingredients.append(ingredient)
            if no_go_ingredients:
                safety_status = "UNSAFE"
            elif caution_ingredients:
                safety_status = "CAUTION"
            else:
                safety_status = "SAFE"
            return safety_status, go_ingredients, caution_ingredients, no_go_ingredients
        else:
            dietary = [d.strip().lower() for d in user.Dietary_preferences.split(",") if d.strip()] if user.Dietary_preferences else []
            health = [h.strip().lower() for h in user.Health_conditions.split(",") if h.strip()] if user.Health_conditions else []
            allergies = [a.strip().lower() for a in user.Allergies.split(",") if a.strip()] if user.Allergies else []
            go_ingredients, caution_ingredients, no_go_ingredients = [], [], []
            async def classify(ingredient):
                info = await self.get_edamam_info(ingredient)
                if not info["healthLabels"] and not info["cautions"]:
                    if any(a in ingredient.lower() for a in allergies):
                        no_go_ingredients.append(ingredient + " (Allergen: fallback)")
                    elif any(d not in ingredient.lower() for d in dietary):
                        caution_ingredients.append(ingredient + " (Dietary: fallback)")
                    elif any(h in ingredient.lower() for h in health):
                        caution_ingredients.append(ingredient + " (Health: fallback)")
                    else:
                        go_ingredients.append(ingredient + " (No Edamam data)")
                    return
                if any(a in info["cautions"] for a in allergies):
                    no_go_ingredients.append(ingredient)
                elif any(d not in info["healthLabels"] for d in dietary):
                    caution_ingredients.append(ingredient)
                elif any(h in ingredient.lower() for h in health):
                    caution_ingredients.append(ingredient)
                else:
                    go_ingredients.append(ingredient)
            await asyncio.gather(*(classify(ing) for ing in ingredients_list))
            all_classified = set(go_ingredients + caution_ingredients + no_go_ingredients)
            for ing in ingredients_list:
                if ing not in all_classified:
                    go_ingredients.append(ing + " (Defaulted)")
            if no_go_ingredients:
                safety_status = "UNSAFE"
            elif caution_ingredients:
                safety_status = "CAUTION"
            else:
                safety_status = "SAFE"
            return safety_status, go_ingredients, caution_ingredients, no_go_ingredients
    
    async def get_edamam_info(self, ingredient):
        try:
            url = (
                f"https://api.edamam.com/api/food-database/v2/parser"
                f"?app_id={EDAMAM_APP_ID}&app_key={EDAMAM_APP_KEY}&ingr={ingredient}"
            )
            connector = get_ssl_connector()
            async with aiohttp.ClientSession(connector=connector) as session:
                async with session.get(url) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        parsed = data.get("parsed") or data.get("hints")
                        if parsed:
                            food = parsed[0]["food"] if "food" in parsed[0] else parsed[0].get("food", {})
                            return {
                                "healthLabels": [h.lower() for h in food.get("healthLabels", [])],
                                "cautions": [c.lower() for c in food.get("cautions", [])]
                            }
        except Exception as e:
            print(f"Edamam API error for ingredient {ingredient}: {e}")
            # Return empty result on error to prevent app crash
        return {"healthLabels": [], "cautions": []}

    def get_ai_health_insight_and_expert_advice(self, user, nutrition_data, flagged_ingredients):
        health_prompt = f"""
        You are a certified health and nutrition expert.

        User Profile:
        Diet: {user.Dietary_preferences}
        Health Conditions: {user.Health_conditions}
        Allergies: {user.Allergies}

        Product Nutrition: {nutrition_data}
        Flagged Ingredients: {flagged_ingredients}

        Give a short health insight: safety, red flags, and user-friendly advice.
        """

        expert_prompt = f"""
        You are a food science expert. Based on the nutrition data and flagged ingredients below, give a detailed expert-level opinion with technical insight.

        Nutrition Data: {nutrition_data}
        Flagged Ingredients: {flagged_ingredients}
        """

        ai_health_insight = self.call_openai(health_prompt)
        expert_advice = self.call_openai(expert_prompt)

        return {"ai_health_insight": ai_health_insight, "expert_advice": expert_advice}

    def call_openai(self, prompt):
        try:
            client = OpenAI(
                base_url="https://api.openai.com/v1",
                api_key=os.getenv("OPENAI_API_KEY"),
            )

            completion = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "You are an expert in food science and health."},
                    {"role": "user", "content": prompt},
                ],
            )
            return completion.choices[0].message.content.strip()
        except Exception as e:
            print(f"OpenAI error: {str(e)}")  # Add error logging
            return f"OpenAI error: {str(e)}"

    async def validate_product_safety(self, user, ingredients_list):
        if USE_STATIC_INGREDIENT_SAFETY:
            dietary = [d.strip().lower() for d in user.Dietary_preferences.split(",") if d.strip()] if user.Dietary_preferences else []
            health = [h.strip().lower() for h in user.Health_conditions.split(",") if h.strip()] if user.Health_conditions else []
            allergies = [a.strip().lower() for a in user.Allergies.split(",") if a.strip()] if user.Allergies else []
            go_ingredients, caution_ingredients, no_go_ingredients = [], [], []
            for ingredient in ingredients_list:
                ing_lower = ingredient.lower()
                if any(a in ing_lower for a in allergies):
                    no_go_ingredients.append(ingredient + " (Allergen)")
                elif any(d not in ing_lower for d in dietary) and dietary:
                    caution_ingredients.append(ingredient + " (Dietary)")
                elif any(h in ing_lower for h in health):
                    caution_ingredients.append(ingredient + " (Health)")
                else:
                    go_ingredients.append(ingredient)
            if no_go_ingredients:
                safety_status = "UNSAFE"
            elif caution_ingredients:
                safety_status = "CAUTION"
            else:
                safety_status = "SAFE"
            return safety_status, go_ingredients, caution_ingredients, no_go_ingredients
        else:
            dietary = [d.strip().lower() for d in user.Dietary_preferences.split(",") if d.strip()] if user.Dietary_preferences else []
            health = [h.strip().lower() for h in user.Health_conditions.split(",") if h.strip()] if user.Health_conditions else []
            allergies = [a.strip().lower() for a in user.Allergies.split(",") if a.strip()] if user.Allergies else []
            go_ingredients, caution_ingredients, no_go_ingredients = [], [], []
            async def classify(ingredient):
                info = await self.get_edamam_info(ingredient)
                if not info["healthLabels"] and not info["cautions"]:
                    if any(a in ingredient.lower() for a in allergies):
                        no_go_ingredients.append(ingredient + " (Allergen: fallback)")
                    elif any(d not in ingredient.lower() for d in dietary):
                        caution_ingredients.append(ingredient + " (Dietary: fallback)")
                    elif any(h in ingredient.lower() for h in health):
                        caution_ingredients.append(ingredient + " (Health: fallback)")
                    else:
                        go_ingredients.append(ingredient + " (No Edamam data)")
                    return
                if any(a in info["cautions"] for a in allergies):
                    no_go_ingredients.append(ingredient)
                elif any(d not in info["healthLabels"] for d in dietary):
                    caution_ingredients.append(ingredient)
                elif any(h in ingredient.lower() for h in health):
                    caution_ingredients.append(ingredient)
                else:
                    go_ingredients.append(ingredient)
            await asyncio.gather(*(classify(ing) for ing in ingredients_list))
            all_classified = set(go_ingredients + caution_ingredients + no_go_ingredients)
            for ing in ingredients_list:
                if ing not in all_classified:
                    go_ingredients.append(ing + " (Defaulted)")
            if no_go_ingredients:
                safety_status = "UNSAFE"
            elif caution_ingredients:
                safety_status = "CAUTION"
            else:
                safety_status = "SAFE"
            return safety_status, go_ingredients, caution_ingredients, no_go_ingredients



class Details(APIView):
    permission_classes = [IsAuthenticated]

    def get(self,request):
        id = request.query_params.get('id')
        if not id:
            return Response({"error": "ID parameter is required."}, status=status.HTTP_400_BAD_REQUEST)
        try:
            item = FoodLabelScan.objects.get(id=id, user=request.user) # Ensure user can only view their own scans
            serializer = FoodLabelScanSerializer(item)
            return Response(serializer.data, status=status.HTTP_200_OK)
        except FoodLabelScan.DoesNotExist:
            return Response({"error": "Product not found."}, status=status.HTTP_404_NOT_FOUND)
        except Exception as e:
            return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

class FeedbackView(APIView):
    """
    API to handle user feedback.
    POST: Submit new feedback
    GET: Retrieve user's feedback history
    """
    permission_classes = [IsAuthenticated]

    def post(self, request):
        serializer = FeedbackSerializer(data=request.data)
        if not serializer.is_valid():
            return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

        # Create feedback
        feedback = Feedback.objects.create(
            user=request.user,
            rating=serializer.validated_data['rating'],
            comment=serializer.validated_data['comment']
        )

        return Response({
            "message": "Thank you for your feedback!",
            "feedback": {
                "id": feedback.id,
                "rating": feedback.rating,
                "comment": feedback.comment,
                "created_at": feedback.created_at
            }
        }, status=status.HTTP_201_CREATED)

    def get(self, request):
        # Get user's feedback history
        feedbacks = Feedback.objects.filter(user=request.user).order_by('-created_at')
        
        feedback_list = []
        for feedback in feedbacks:
            feedback_list.append({
                "id": feedback.id,
                "rating": feedback.rating,
                "comment": feedback.comment,
                "created_at": feedback.created_at
            })

        return Response({
            "feedbacks": feedback_list,
            "total_feedbacks": len(feedback_list)
        }, status=status.HTTP_200_OK)

class LoveAppView(APIView):
    """
    API to handle the "Love the app" feature.
    POST: Toggle the user's love for the app
    GET: Get the user's current love status
    """
    permission_classes = [IsAuthenticated]

    def post(self, request):
        serializer = LoveAppSerializer(data=request.data)
        if not serializer.is_valid():
            return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

        # Update user's love status
        request.user.loves_app = serializer.validated_data['loves_app']
        request.user.save()

        return Response({
            "message": "Thank you for loving our app!" if request.user.loves_app else "We hope to win your love back!",
            "loves_app": request.user.loves_app
        }, status=status.HTTP_200_OK)

    def get(self, request):
        return Response({
            "loves_app": request.user.loves_app
        }, status=status.HTTP_200_OK)

class ContactSupportView(APIView):
    """
    API to provide contact information for different departments.
    GET: Get all active department contacts
    """
    permission_classes = [IsAuthenticated]

    def get(self, request):
        # Get department filter from query params (optional)
        department = request.query_params.get('department', None)
        
        # Base queryset - only active departments
        contacts = DepartmentContact.objects.filter(is_active=True)
        
        # Apply department filter if provided
        if department:
            contacts = contacts.filter(department=department)
        
        # Order by department
        contacts = contacts.order_by('department')
        
        # Serialize the data
        serializer = DepartmentContactSerializer(contacts, many=True)
        
        return Response({
            "departments": serializer.data,
            "total_departments": len(serializer.data)
        }, status=status.HTTP_200_OK)

class ToggleFavoriteView(APIView):
    """
    API to toggle favorite status of a scanned food item.
    POST: Toggle favorite status by scan ID
    """
    permission_classes = [IsAuthenticated]

    def post(self, request):
        scan_id = request.data.get('scan_id')
        
        if not scan_id:
            return Response(
                {"error": "scan_id is required"},
                status=status.HTTP_400_BAD_REQUEST
            )

        try:
            # Get the scan and ensure it belongs to the user
            scan = FoodLabelScan.objects.get(id=scan_id, user=request.user)
            
            # Toggle the favorite status
            scan.is_favorite = not scan.is_favorite
            scan.save()
            
            return Response({
                "message": f"Product {'added to' if scan.is_favorite else 'removed from'} favorites",
                "scan_id": scan.id,
                "is_favorite": scan.is_favorite,
                "product_name": scan.product_name or "Unknown Product"
            }, status=status.HTTP_200_OK)
            
        except FoodLabelScan.DoesNotExist:
            return Response(
                {"error": "Scan not found or you don't have permission to access it"},
                status=status.HTTP_404_NOT_FOUND
            )
        except Exception as e:
            return Response(
                {"error": str(e)},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

class AllFlaggedIngredientsView(APIView):
    """
    API to get all flagged ingredients (no-go) for the authenticated user, with their product names and scan date.
    Returns a flat list: [{"product_name": ..., "flagged_ingredient": ..., "scanned_at": ...}, ...]
    """
    permission_classes = [IsAuthenticated]

    def get(self, request):
        # Get all scans for the user
        scans = FoodLabelScan.objects.filter(user=request.user).order_by('-scanned_at')
        flagged_list = []
        unique_ingredients = set()  # Track unique ingredients
        
        print(f"Found {scans.count()} scans for user {request.user.id}")
        
        for scan in scans:
            # Determine scan type and product name
            scan_type = "unknown"
            product_name = "Unknown Product"
            
            # Check if it's a barcode scan (has product_name from OpenFoodFacts)
            if scan.product_name and scan.product_name.strip():
                product_name = scan.product_name.strip()
                scan_type = "barcode"
            # Check if it's an OCR scan (has extracted_text)
            elif scan.extracted_text and scan.extracted_text.strip():
                # Try to extract product name from OCR text or use default
                product_name = self.extract_product_name_from_ocr(scan.extracted_text) or "OCR Product"
                scan_type = "ocr"
            else:
                # Skip scans without any meaningful data
                continue
            
            scan_date = scan.scanned_at.isoformat() if scan.scanned_at else None
            image_url = scan.image_url if hasattr(scan, 'image_url') else None
            
            # Get flagged ingredients from scan
            flagged_ingredients = scan.flagged_ingredients or []
            
            print(f"Scan {scan.id}: type={scan_type}, product_name='{product_name}', flagged_ingredients={flagged_ingredients}")
            
            # Handle both string and dict formats for ingredients
            for ingredient in flagged_ingredients:
                if isinstance(ingredient, dict):
                    ingredient_name = ingredient.get("ingredient", "")
                    # Also check for other possible keys
                    if not ingredient_name:
                        ingredient_name = ingredient.get("name", "") or ingredient.get("text", "")
                else:
                    ingredient_name = str(ingredient)
                
                if ingredient_name and ingredient_name.strip():  # Only add if ingredient name is not empty
                    # Clean ingredient name by removing common suffixes
                    cleaned_ingredient = self.clean_ingredient_name(ingredient_name.strip())
                    ingredient_name_clean = cleaned_ingredient.lower()  # Normalize for uniqueness check
                    
                    # Only add if this ingredient hasn't been seen before
                    if ingredient_name_clean not in unique_ingredients:
                        unique_ingredients.add(ingredient_name_clean)
                        flagged_list.append({
                            "product_name": product_name,
                            "flagged_ingredient": cleaned_ingredient,  # Use cleaned ingredient name
                            "ingredient_type": "flagged",
                            "scan_type": scan_type,
                            "scanned_at": scan_date,
                            "image_url": image_url,
                            "scan_id": scan.id
                        })
        
        return Response({
            "flagged_ingredients": flagged_list,
            "total_flagged": len(flagged_list)
        }, status=status.HTTP_200_OK)
    
    def clean_ingredient_name(self, ingredient_name):
        """
        Clean ingredient name by removing common suffixes and parentheses.
        """
        if not ingredient_name:
            return ingredient_name
        
        # Remove common suffixes in parentheses
        import re
        
        # Remove patterns like "(No Edamam data)", "(Defaulted)", "(Allergen)", etc.
        cleaned = re.sub(r'\s*\([^)]*\)\s*$', '', ingredient_name)
        
        # Remove other common suffixes
        suffixes_to_remove = [
            ' (No Edamam data)',
            ' (Defaulted)',
            ' (Allergen)',
            ' (Dietary)',
            ' (Health)',
            ' (Toxicological Concern)',
            ' (Toxic)',
            ' (Hazard)',
            ' (Carcinogen)',
            ' (Danger)',
            ' (Harmful)',
            ' (Poison)',
            ' (Fatal)'
        ]
        
        for suffix in suffixes_to_remove:
            if cleaned.endswith(suffix):
                cleaned = cleaned[:-len(suffix)]
                break
        
        return cleaned.strip()
    
    def extract_product_name_from_ocr(self, extracted_text):
        """
        Try to extract product name from OCR text.
        This is a simple heuristic - in a real implementation, you might want to use AI/ML.
        """
        if not extracted_text:
            return None
        
        lines = extracted_text.split('\n')
        
        # Look for common patterns that might indicate product names
        for line in lines[:10]:  # Check first 10 lines
            line = line.strip()
            if line and len(line) > 3 and len(line) < 100:  # Reasonable length for product name
                # Skip lines that are likely not product names
                if any(skip_word in line.lower() for skip_word in [
                    'ingredients:', 'nutrition', 'serving', 'calories', 'fat', 'protein', 'carbohydrates',
                    'sodium', 'sugar', 'fiber', 'vitamin', 'mineral', 'daily value', 'percent'
                ]):
                    continue
                
                # If line looks like a product name, return it
                if not any(char.isdigit() for char in line) and not line.endswith(':'):
                    return line
        
        return None

import requests
from django.contrib.auth import get_user_model

@method_decorator(csrf_exempt, name='dispatch')
class GoogleSignInView(APIView):
    def post(self, request):
        id_token = request.data.get("id_token")
        terms_accepted = request.data.get("termsAccepted", False)
        if not id_token:
            return Response({"error": "Missing id_token"}, status=status.HTTP_417_EXPECTATION_FAILED)

        # Try to decode the token to determine if it's a Firebase token or Google token
        import jwt
        try:
            # Decode without verification to check token type
            decoded_token = jwt.decode(id_token, options={"verify_signature": False})
            
            # Check if it's a Firebase token (contains firebase field)
            if 'firebase' in decoded_token:
                # This is a Firebase ID token
                return self._handle_firebase_token(decoded_token, terms_accepted)
            else:
                # This is a Google ID token
                return self._handle_google_token(id_token, terms_accepted)
                
        except jwt.DecodeError:
            return Response({"error": "Invalid token format"}, status=status.HTTP_417_EXPECTATION_FAILED)
        except Exception as e:
            return Response({"error": f"Token processing error: {str(e)}"}, status=status.HTTP_417_EXPECTATION_FAILED)

    def _handle_firebase_token(self, decoded_token, terms_accepted=False):
        """Handle Firebase ID token"""
        try:
            email = decoded_token.get("email")
            if not email:
                return Response({"error": "No email in Firebase token"}, status=status.HTTP_417_EXPECTATION_FAILED)

            # Extract user info from Firebase token
            user_info = {
                "email": email,
                "name": decoded_token.get("name", ""),
                "picture": decoded_token.get("picture", ""),
                "user_id": decoded_token.get("user_id", ""),
            }

            # Create or get user
            User = get_user_model()
            try:
                user, created = User.objects.get_or_create(
                    email=email, 
                    defaults={
                        "full_name": user_info.get("name", ""),
                        "is_terms": terms_accepted  # Set terms acceptance for new users
                    }
                )
                
                # For new users, validate terms acceptance
                if created and not terms_accepted:
                    user.delete()  # Delete the user if terms not accepted
                    return Response({"error": "You must accept the terms and conditions to create an account."}, status=status.HTTP_400_BAD_REQUEST)
            except Exception as user_error:
                return Response({
                    "error": f"User creation/retrieval failed: {str(user_error)}"
                }, status=status.HTTP_417_EXPECTATION_FAILED)

            # Generate JWT tokens
            try:
                from rest_framework_simplejwt.tokens import RefreshToken
                refresh = RefreshToken.for_user(user)
                access_token = str(refresh.access_token)
            except Exception as token_error:
                return Response({
                    "error": f"Token generation failed: {str(token_error)}"
                }, status=status.HTTP_417_EXPECTATION_FAILED)

            return Response({
                "access_token": access_token,
                "refresh_token": str(refresh),
                "created": created,
                "email": user.email,
                "full_name": user.full_name,
                "profile_picture": user_info.get("picture", ""),
                "has_answered_onboarding": user.has_answered_onboarding,  # Add onboarding status
                "subscription_plan": user.subscription_plan
            }, status=status.HTTP_200_OK)

        except Exception as e:
            return Response({
                "error": f"Firebase token processing error: {str(e)}"
            }, status=status.HTTP_417_EXPECTATION_FAILED)

    def _handle_google_token(self, id_token, terms_accepted=False):
        """Handle Google ID token"""
        try:
            # Verify the token with Google
            google_response = requests.get(
                f'https://oauth2.googleapis.com/tokeninfo?id_token={id_token}'
            )
            if google_response.status_code != 200:
                return Response({"error": "Invalid Google token"}, status=status.HTTP_417_EXPECTATION_FAILED)
            
            data = google_response.json()

            # Enforce audience check for iOS and Android client IDs
            GOOGLE_IOS_CLIENT_ID = getattr(settings, "GOOGLE_IOS_CLIENT_ID", None) or os.getenv("GOOGLE_IOS_CLIENT_ID")
            GOOGLE_ANDROID_CLIENT_ID = getattr(settings, "GOOGLE_ANDROID_CLIENT_ID", None) or os.getenv("GOOGLE_ANDROID_CLIENT_ID")
            GOOGLE_WEB_CLIENT_ID = getattr(settings, "SOCIAL_AUTH_GOOGLE_OAUTH2_KEY", None) or os.getenv("SOCIAL_AUTH_GOOGLE_OAUTH2_KEY")
            FIREBASE_PROJECT_ID = getattr(settings, "FIREBASE_PROJECT_ID", None) or os.getenv("FIREBASE_PROJECT_ID", "ai-ingredients-3a169")
            
            allowed_client_ids = [GOOGLE_IOS_CLIENT_ID, GOOGLE_ANDROID_CLIENT_ID, GOOGLE_WEB_CLIENT_ID, FIREBASE_PROJECT_ID]
            allowed_client_ids = [cid for cid in allowed_client_ids if cid]
            
            # Comment out audience check for testing (uncomment for production)
            # if allowed_client_ids and data.get('aud') not in allowed_client_ids:
            #     return Response({
            #         "error": f"Invalid audience in token. Expected one of: {allowed_client_ids}, got: {data.get('aud')}"
            #     }, status=status.HTTP_400_BAD_REQUEST)

            email = data.get("email")
            if not email:
                return Response({"error": "No email in Google token"}, status=status.HTTP_417_EXPECTATION_FAILED)
            
            print(f"DEBUG: Google Sign-In attempt for email: {email}")

            # Create or get user
            User = get_user_model()
            try:
                user, created = User.objects.get_or_create(
                    email=email, 
                    defaults={
                        "full_name": data.get("name", ""),
                        "is_terms": terms_accepted  # Set terms acceptance for new users
                    }
                )
                
                # For new users, validate terms acceptance
                if created and not terms_accepted:
                    user.delete()  # Delete the user if terms not accepted
                    return Response({"error": "You must accept the terms and conditions to create an account."}, status=status.HTTP_417_BAD_REQUEST)
                print(f"DEBUG: User {'created' if created else 'retrieved'} successfully: {user.email}")
                
                # If user already exists, provide a more specific message
                if not created:
                    print(f"DEBUG: User {email} already exists, proceeding with login")
            except Exception as user_error:
                print(f"DEBUG: User creation/retrieval failed: {str(user_error)}")
                return Response({
                    "error": f"User creation/retrieval failed: {str(user_error)}"
                }, status=status.HTTP_417_EXPECTATION_FAILED)

            # Generate JWT tokens
            try:
                from rest_framework_simplejwt.tokens import RefreshToken
                refresh = RefreshToken.for_user(user)
                access_token = str(refresh.access_token)
                print(f"DEBUG: JWT tokens generated successfully for user: {user.email}")
            except Exception as token_error:
                print(f"DEBUG: Token generation failed: {str(token_error)}")
                return Response({
                    "error": f"Token generation failed: {str(token_error)}"
                }, status=status.HTTP_417_EXPECTATION_FAILED)

            return Response({
                "access_token": access_token,
                "refresh_token": str(refresh),
                "created": created,
                "email": user.email,
                "full_name": user.full_name,
                "profile_picture": data.get("picture", ""),
                "has_answered_onboarding": user.has_answered_onboarding,  # Add onboarding status
                "subscription_plan": user.subscription_plan
            }, status=status.HTTP_200_OK)

        except Exception as e:
            print(f"DEBUG: Google token processing error: {str(e)}")
            return Response({
                "error": f"Google token processing error: {str(e)}"
            }, status=status.HTTP_417_EXPECTATION_FAILED)

@method_decorator(csrf_exempt, name='dispatch')
class GoogleSignInWithAccessTokenView(APIView):
    """
    Google Sign-In using access token from client-side Google Sign-In SDK
    """
    permission_classes = []
    
    def post(self, request):
        access_token = request.data.get("access_token")
        terms_accepted = request.data.get("termsAccepted", False)
        if not access_token:
            return Response({"error": "Missing access_token"}, status=status.HTTP_400_BAD_REQUEST)

        # Get user info using access token
        user_info_response = requests.get(
            'https://www.googleapis.com/oauth2/v2/userinfo',
            headers={'Authorization': f'Bearer {access_token}'}
        )
        
        if user_info_response.status_code != 200:
            return Response({"error": "Invalid access token"}, status=status.HTTP_400_BAD_REQUEST)
        
        user_info = user_info_response.json()
        email = user_info.get('email')
        
        if not email:
            return Response({"error": "No email in user info"}, status=status.HTTP_400_BAD_REQUEST)
        
        # Create or get user
        User = get_user_model()
        user, created = User.objects.get_or_create(
            email=email, 
            defaults={
                "full_name": user_info.get('name', ''),
                "is_terms": terms_accepted  # Set terms acceptance for new users
            }
        )
        
        # For new users, validate terms acceptance
        if created and not terms_accepted:
            user.delete()  # Delete the user if terms not accepted
            return Response({"error": "You must accept the terms and conditions to create an account."}, status=status.HTTP_400_BAD_REQUEST)
        
        # Generate JWT tokens
        from rest_framework_simplejwt.tokens import RefreshToken
        refresh = RefreshToken.for_user(user)
        access_token = str(refresh.access_token)
        
        return Response({
            "access_token": access_token,
            "refresh_token": str(refresh),
            "created": created,
            "email": user.email,
            "full_name": user.full_name,
            "profile_picture": user.profile_picture,
            "has_answered_onboarding": user.has_answered_onboarding,  # Add onboarding status
            "subscription_plan": user.subscription_plan
        }, status=status.HTTP_200_OK)

class SafeGoIngredientsView(APIView):
    """
    API to get all 'go' (safe) ingredients for the authenticated user, with their product names and scan date.
    Returns a flat list: [{"product_name": ..., "go_ingredient": ..., "scanned_at": ..., "image_url": ...}, ...]
    """
    permission_classes = [IsAuthenticated]

    def get(self, request):
        # Get all scans for the user, not just SAFE ones
        scans = FoodLabelScan.objects.filter(user=request.user).order_by('-scanned_at')
        go_list = []
        unique_ingredients = set()  # Track unique ingredients
        
        print(f"Found {scans.count()} scans for user {request.user.id}")
        
        for scan in scans:
            # Determine scan type and product name
            scan_type = "unknown"
            product_name = "Unknown Product"
            
            # Check if it's a barcode scan (has product_name from OpenFoodFacts)
            if scan.product_name and scan.product_name.strip():
                product_name = scan.product_name.strip()
                scan_type = "barcode"
            # Check if it's an OCR scan (has extracted_text)
            elif scan.extracted_text and scan.extracted_text.strip():
                # Try to extract product name from OCR text or use default
                product_name = self.extract_product_name_from_ocr(scan.extracted_text) or "OCR Product"
                scan_type = "ocr"
            else:
                # Skip scans without any meaningful data
                continue
            
            scan_date = scan.scanned_at.isoformat() if scan.scanned_at else None
            image_url = scan.image_url if hasattr(scan, 'image_url') else None
            
            # Get nutrition data and extract go ingredients
            nutrition_data = scan.nutrition_data if isinstance(scan.nutrition_data, dict) else {}
            go_ingredients = nutrition_data.get("go_ingredients") or nutrition_data.get("go") or []
            
            print(f"Scan {scan.id}: type={scan_type}, product_name='{product_name}', go_ingredients={go_ingredients}")
            
            # Handle both string and dict formats for ingredients
            for ingredient in go_ingredients:
                if isinstance(ingredient, dict):
                    ingredient_name = ingredient.get("ingredient", "")
                    # Also check for other possible keys
                    if not ingredient_name:
                        ingredient_name = ingredient.get("name", "") or ingredient.get("text", "")
                else:
                    ingredient_name = str(ingredient)
                
                if ingredient_name and ingredient_name.strip():  # Only add if ingredient name is not empty
                    # Clean ingredient name by removing common suffixes
                    cleaned_ingredient = self.clean_ingredient_name(ingredient_name.strip())
                    ingredient_name_clean = cleaned_ingredient.lower()  # Normalize for uniqueness check
                    
                    # Only add if this ingredient hasn't been seen before
                    if ingredient_name_clean not in unique_ingredients:
                        unique_ingredients.add(ingredient_name_clean)
                        go_list.append({
                            "product_name": product_name,
                            "go_ingredient": cleaned_ingredient,  # Use cleaned ingredient name
                            "ingredient_type": "go",
                            "scan_type": scan_type,
                            "scanned_at": scan_date,
                            "image_url": image_url,
                            "scan_id": scan.id
                        })
        
        return Response({
            "go_ingredients": go_list,
            "total_go": len(go_list)
        }, status=status.HTTP_200_OK)
    
    def clean_ingredient_name(self, ingredient_name):
        """
        Clean ingredient name by removing common suffixes and parentheses.
        """
        if not ingredient_name:
            return ingredient_name
        
        # Remove common suffixes in parentheses
        import re
        
        # Remove patterns like "(No Edamam data)", "(Defaulted)", "(Allergen)", etc.
        cleaned = re.sub(r'\s*\([^)]*\)\s*$', '', ingredient_name)
        
        # Remove other common suffixes
        suffixes_to_remove = [
            ' (No Edamam data)',
            ' (Defaulted)',
            ' (Allergen)',
            ' (Dietary)',
            ' (Health)',
            ' (Toxicological Concern)',
            ' (Toxic)',
            ' (Hazard)',
            ' (Carcinogen)',
            ' (Danger)',
            ' (Harmful)',
            ' (Poison)',
            ' (Fatal)'
        ]
        
        for suffix in suffixes_to_remove:
            if cleaned.endswith(suffix):
                cleaned = cleaned[:-len(suffix)]
                break
        
        return cleaned.strip()
    
    def extract_product_name_from_ocr(self, extracted_text):
        """
        Try to extract product name from OCR text.
        This is a simple heuristic - in a real implementation, you might want to use AI/ML.
        """
        if not extracted_text:
            return None
        
        lines = extracted_text.split('\n')
        
        # Look for common patterns that might indicate product names
        for line in lines[:10]:  # Check first 10 lines
            line = line.strip()
            if line and len(line) > 3 and len(line) < 100:  # Reasonable length for product name
                # Skip lines that are likely not product names
                if any(skip_word in line.lower() for skip_word in [
                    'ingredients:', 'nutrition', 'serving', 'calories', 'fat', 'protein', 'carbohydrates',
                    'sodium', 'sugar', 'fiber', 'vitamin', 'mineral', 'daily value', 'percent'
                ]):
                    continue
                
                # If line looks like a product name, return it
                if not any(char.isdigit() for char in line) and not line.endswith(':'):
                    return line
        
        return None

class CautionIngredientsView(APIView):
    """
    API to get all 'caution' ingredients for the authenticated user, with their product names and scan date.
    Returns a flat list: [{"product_name": ..., "caution_ingredient": ..., "scanned_at": ..., "image_url": ...}, ...]
    """
    permission_classes = [IsAuthenticated]

    def get(self, request):
        scans = FoodLabelScan.objects.filter(user=request.user).order_by('-scanned_at')
        caution_list = []
        
        for scan in scans:
            # Heuristic: barcode scan if product_name and product_image_url are present (from OpenFoodFacts),
            # OCR scan if extracted_text and image_url are present
            is_barcode = bool(getattr(scan, 'product_name', None) and getattr(scan, 'product_image_url', None))
            is_ocr = bool(getattr(scan, 'extracted_text', None) and getattr(scan, 'image_url', None))
            if not (is_barcode or is_ocr):
                continue
                
            product_name = scan.product_name or "OCR Product"
            scan_date = scan.scanned_at.isoformat() if scan.scanned_at else None
            image_url = scan.image_url if hasattr(scan, 'image_url') else None
            nutrition_data = scan.nutrition_data if isinstance(scan.nutrition_data, dict) else {}
            caution_ingredients = nutrition_data.get("caution_ingredients") or nutrition_data.get("caution") or []
            
            # Handle both string and dict formats for ingredients
            for ingredient in caution_ingredients:
                if isinstance(ingredient, dict):
                    ingredient_name = ingredient.get("ingredient", "")
                else:
                    ingredient_name = str(ingredient)
                
                if ingredient_name:  # Only add if ingredient name is not empty
                    caution_list.append({
                        "product_name": product_name,
                        "caution_ingredient": ingredient_name,
                        "scanned_at": scan_date,
                        "image_url": image_url
                    })
        
        return Response({
            "caution_ingredients": caution_list,
            "total_caution": len(caution_list)
        }, status=status.HTTP_200_OK)

class CancelSubscriptionView(APIView):
    permission_classes = [IsAuthenticated]

    def post(self, request):
        user = request.user
        from .models import UserSubscription
        import stripe
        try:
            sub = UserSubscription.objects.get(user=user, plan_name='premium')
            if not sub.stripe_subscription_id:
                return Response({"error": "No active Stripe subscription found."}, status=400)
            # Cancel on Stripe
            stripe.Subscription.delete(sub.stripe_subscription_id)
            # Update DB
            sub.status = "canceled"
            sub.save()
            return Response({"message": "Subscription canceled. You will not be charged further."}, status=200)
        except UserSubscription.DoesNotExist:
            return Response({"error": "No active premium subscription found."}, status=400)
        except Exception as e:
            return Response({"error": str(e)}, status=500)


import os
import httpx
from dotenv import load_dotenv
from django.http import JsonResponse
from django.views import View
import asyncio

load_dotenv()
GNEWS_API_KEY = "a64db0ebc7188e3275b708e1bfadd841"

class TrendingNewsView(APIView):
    def get(self, request):
        try:
            # Get user's location from request headers or default to global
            user_country = request.headers.get('X-User-Country', 'us')
            user_language = request.headers.get('X-User-Language', 'en')
            
            # Multiple news sources for comprehensive coverage
            news_data = {
                "trending_headlines": self.get_trending_headlines(user_country, user_language),
                "food_health_news": self.get_food_health_news(),
                "technology_news": self.get_technology_news(),
                "business_news": self.get_business_news(),
                "entertainment_news": self.get_entertainment_news(),
                "sports_news": self.get_sports_news(),
                "videos": self.get_trending_videos(),
                "weather": self.get_weather_info(user_country),
                "currency_rates": self.get_currency_rates(),
                "stock_market": self.get_stock_market_data(),
                "covid_stats": self.get_covid_stats(user_country),
                "local_news": self.get_local_news(user_country),
                "breaking_news": self.get_breaking_news(),
                "featured_stories": self.get_featured_stories(),
                "news_categories": self.get_news_categories(),
                "metadata": {
                    "last_updated": timezone.now().isoformat(),
                    "total_articles": 0,
                    "sources_count": 0,
                    "user_country": user_country,
                    "user_language": user_language
                }
            }
            
            # Calculate totals
            total_articles = sum(len(section.get('articles', [])) for section in news_data.values() if isinstance(section, dict) and 'articles' in section)
            news_data["metadata"]["total_articles"] = total_articles
            news_data["metadata"]["sources_count"] = 8  # Number of different news sources used
            
            return Response({
                "status": "success",
                "message": "Professional news feed retrieved successfully",
                "data": news_data
            }, status=status.HTTP_200_OK)
            
        except Exception as e:
            return Response({
                "status": "error", 
                "message": f"Failed to fetch news: {str(e)}"
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    def get_trending_headlines(self, country='us', language='en'):
        """Get top headlines from GNews API"""
        try:
            url = "https://gnews.io/api/v4/top-headlines"
            params = {
                "lang": language,
                "country": country,
                "max": 30,
                "token": GNEWS_API_KEY
            }
            response = requests.get(url, params=params, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                articles = []
                for item in data.get("articles", []):
                    articles.append({
                        "id": item.get("url", "").split("/")[-1][:20],
                        "title": item.get("title", ""),
                        "description": item.get("description", ""),
                        "content": item.get("content", ""),
                        "url": item.get("url", ""),
                        "image": item.get("image", ""),
                        "publishedAt": item.get("publishedAt", ""),
                        "source": {
                            "name": item.get("source", {}).get("name", ""),
                            "url": item.get("source", {}).get("url", "")
                        },
                        "category": "headlines",
                        "sentiment": self.analyze_sentiment(item.get("title", "")),
                        "read_time": self.calculate_read_time(item.get("content", "")),
                        "tags": self.extract_tags(item.get("title", "") + " " + item.get("description", ""))
                    })
                return {"articles": articles, "count": len(articles)}
            return {"articles": [], "count": 0}
        except Exception:
            return {"articles": [], "count": 0}

    def get_food_health_news(self):
        """Get food and health related news"""
        try:
            url = "https://gnews.io/api/v4/search"
            params = {
                "q": "food health nutrition wellness",
                "lang": "en",
                "max": 10,
                "token": GNEWS_API_KEY
            }
            response = requests.get(url, params=params, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                articles = []
                for item in data.get("articles", []):
                    articles.append({
                        "id": item.get("url", "").split("/")[-1][:20],
                        "title": item.get("title", ""),
                        "description": item.get("description", ""),
                        "url": item.get("url", ""),
                        "image": item.get("image", ""),
                        "publishedAt": item.get("publishedAt", ""),
                        "source": item.get("source", {}).get("name", ""),
                        "category": "food_health",
                        "read_time": self.calculate_read_time(item.get("content", ""))
                    })
                return {"articles": articles, "count": len(articles)}
            return {"articles": [], "count": 0}
        except Exception:
            return {"articles": [], "count": 0}

    def get_technology_news(self):
        """Get technology news"""
        try:
            url = "https://gnews.io/api/v4/search"
            params = {
                "q": "technology AI artificial intelligence",
                "lang": "en",
                "max": 8,
                "token": GNEWS_API_KEY
            }
            response = requests.get(url, params=params, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                articles = []
                for item in data.get("articles", []):
                    articles.append({
                        "id": item.get("url", "").split("/")[-1][:20],
                        "title": item.get("title", ""),
                        "description": item.get("description", ""),
                        "url": item.get("url", ""),
                        "image": item.get("image", ""),
                        "publishedAt": item.get("publishedAt", ""),
                        "source": item.get("source", {}).get("name", ""),
                        "category": "technology",
                        "read_time": self.calculate_read_time(item.get("content", ""))
                    })
                return {"articles": articles, "count": len(articles)}
            return {"articles": [], "count": 0}
        except Exception:
            return {"articles": [], "count": 0}

    def get_business_news(self):
        """Get business and finance news"""
        try:
            url = "https://gnews.io/api/v4/search"
            params = {
                "q": "business finance economy market",
                "lang": "en",
                "max": 8,
                "token": GNEWS_API_KEY
            }
            response = requests.get(url, params=params, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                articles = []
                for item in data.get("articles", []):
                    articles.append({
                        "id": item.get("url", "").split("/")[-1][:20],
                        "title": item.get("title", ""),
                        "description": item.get("description", ""),
                        "url": item.get("url", ""),
                        "image": item.get("image", ""),
                        "publishedAt": item.get("publishedAt", ""),
                        "source": item.get("source", {}).get("name", ""),
                        "category": "business",
                        "read_time": self.calculate_read_time(item.get("content", ""))
                    })
                return {"articles": articles, "count": len(articles)}
            return {"articles": [], "count": 0}
        except Exception:
            return {"articles": [], "count": 0}

    def get_entertainment_news(self):
        """Get entertainment news"""
        try:
            url = "https://gnews.io/api/v4/search"
            params = {
                "q": "entertainment movies music celebrities",
                "lang": "en",
                "max": 6,
                "token": GNEWS_API_KEY
            }
            response = requests.get(url, params=params, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                articles = []
                for item in data.get("articles", []):
                    articles.append({
                        "id": item.get("url", "").split("/")[-1][:20],
                        "title": item.get("title", ""),
                        "description": item.get("description", ""),
                        "url": item.get("url", ""),
                        "image": item.get("image", ""),
                        "publishedAt": item.get("publishedAt", ""),
                        "source": item.get("source", {}).get("name", ""),
                        "category": "entertainment",
                        "read_time": self.calculate_read_time(item.get("content", ""))
                    })
                return {"articles": articles, "count": len(articles)}
            return {"articles": [], "count": 0}
        except Exception:
            return {"articles": [], "count": 0}

    def get_sports_news(self):
        """Get sports news"""
        try:
            url = "https://gnews.io/api/v4/search"
            params = {
                "q": "sports football basketball soccer",
                "lang": "en",
                "max": 6,
                "token": GNEWS_API_KEY
            }
            response = requests.get(url, params=params, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                articles = []
                for item in data.get("articles", []):
                    articles.append({
                        "id": item.get("url", "").split("/")[-1][:20],
                        "title": item.get("title", ""),
                        "description": item.get("description", ""),
                        "url": item.get("url", ""),
                        "image": item.get("image", ""),
                        "publishedAt": item.get("publishedAt", ""),
                        "source": item.get("source", {}).get("name", ""),
                        "category": "sports",
                        "read_time": self.calculate_read_time(item.get("content", ""))
                    })
                return {"articles": articles, "count": len(articles)}
            return {"articles": [], "count": 0}
        except Exception:
            return {"articles": [], "count": 0}

    def get_trending_videos(self):
        """Get trending videos (simulated)"""
        try:
            # Simulated video data since we don't have video API access
            videos = [
                {
                    "id": "video_001",
                    "title": "Latest Technology Trends 2024",
                    "description": "Explore the most exciting technology developments",
                    "thumbnail": "https://via.placeholder.com/300x200?text=Tech+Video",
                    "duration": "5:30",
                    "views": "125K",
                    "category": "technology",
                    "url": "https://example.com/video1"
                },
                {
                    "id": "video_002", 
                    "title": "Healthy Cooking Tips",
                    "description": "Learn to cook nutritious meals at home",
                    "thumbnail": "https://via.placeholder.com/300x200?text=Cooking+Video",
                    "duration": "8:15",
                    "views": "89K",
                    "category": "food_health",
                    "url": "https://example.com/video2"
                },
                {
                    "id": "video_003",
                    "title": "Market Analysis Today",
                    "description": "Daily stock market insights and analysis",
                    "thumbnail": "https://via.placeholder.com/300x200?text=Business+Video", 
                    "duration": "12:45",
                    "views": "67K",
                    "category": "business",
                    "url": "https://example.com/video3"
                }
            ]
            return {"videos": videos, "count": len(videos)}
        except Exception:
            return {"videos": [], "count": 0}

    def get_weather_info(self, country='us'):
        """Get weather information (simulated)"""
        try:
            weather_data = {
                "location": "New York, NY" if country == 'us' else "London, UK",
                "temperature": "72F" if country == 'us' else "18C",
                "condition": "Partly Cloudy",
                "humidity": "65%",
                "wind": "8 mph" if country == 'us' else "13 km/h",
                "forecast": [
                    {"day": "Today", "high": "75F", "low": "68F", "condition": "Sunny"},
                    {"day": "Tomorrow", "high": "78F", "low": "70F", "condition": "Cloudy"},
                    {"day": "Wednesday", "high": "72F", "low": "65F", "condition": "Rain"}
                ]
            }
            return weather_data
        except Exception:
            return {"error": "Weather data unavailable"}

    def get_currency_rates(self):
        """Get currency exchange rates (simulated)"""
        try:
            rates = {
                "USD": 1.00,
                "EUR": 0.85,
                "GBP": 0.73,
                "JPY": 110.25,
                "CAD": 1.25,
                "AUD": 1.35,
                "CHF": 0.92,
                "CNY": 6.45,
                "last_updated": timezone.now().isoformat()
            }
            return rates
        except Exception:
            return {"error": "Currency rates unavailable"}

    def get_stock_market_data(self):
        """Get stock market data (simulated)"""
        try:
            stocks = [
                {"symbol": "AAPL", "name": "Apple Inc.", "price": "$150.25", "change": "+2.15%"},
                {"symbol": "GOOGL", "name": "Alphabet Inc.", "price": "$2,850.75", "change": "-1.25%"},
                {"symbol": "MSFT", "name": "Microsoft Corp.", "price": "$310.50", "change": "+0.85%"},
                {"symbol": "TSLA", "name": "Tesla Inc.", "price": "$750.00", "change": "+3.45%"},
                {"symbol": "AMZN", "name": "Amazon.com Inc.", "price": "$3,250.00", "change": "-0.75%"}
            ]
            return {"stocks": stocks, "market_status": "Open", "last_updated": timezone.now().isoformat()}
        except Exception:
            return {"error": "Stock data unavailable"}

    def get_covid_stats(self, country='us'):
        """Get COVID-19 statistics (simulated)"""
        try:
            stats = {
                "country": "United States" if country == 'us' else "United Kingdom",
                "total_cases": "45,678,901" if country == 'us' else "8,234,567",
                "total_deaths": "789,012" if country == 'us' else "138,456",
                "total_recovered": "42,123,456" if country == 'us' else "7,456,789",
                "active_cases": "2,766,433" if country == 'us' else "639,322",
                "vaccination_rate": "65.2%" if country == 'us' else "72.8%",
                "last_updated": timezone.now().isoformat()
            }
            return stats
        except Exception:
            return {"error": "COVID data unavailable"}

    def get_local_news(self, country='us'):
        """Get local news based on country"""
        try:
            url = "https://gnews.io/api/v4/search"
            params = {
                "q": "local news",
                "lang": "en",
                "country": country,
                "max": 5,
                "token": GNEWS_API_KEY
            }
            response = requests.get(url, params=params, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                articles = []
                for item in data.get("articles", []):
                    articles.append({
                        "id": item.get("url", "").split("/")[-1][:20],
                        "title": item.get("title", ""),
                        "description": item.get("description", ""),
                        "url": item.get("url", ""),
                        "image": item.get("image", ""),
                        "publishedAt": item.get("publishedAt", ""),
                        "source": item.get("source", {}).get("name", ""),
                        "category": "local",
                        "read_time": self.calculate_read_time(item.get("content", ""))
                    })
                return {"articles": articles, "count": len(articles)}
            return {"articles": [], "count": 0}
        except Exception:
            return {"articles": [], "count": 0}

    def get_breaking_news(self):
        """Get breaking news alerts"""
        try:
            url = "https://gnews.io/api/v4/search"
            params = {
                "q": "breaking news urgent",
                "lang": "en",
                "max": 5,
                "token": GNEWS_API_KEY
            }
            response = requests.get(url, params=params, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                articles = []
                for item in data.get("articles", []):
                    articles.append({
                        "id": item.get("url", "").split("/")[-1][:20],
                        "title": item.get("title", ""),
                        "description": item.get("description", ""),
                        "url": item.get("url", ""),
                        "image": item.get("image", ""),
                        "publishedAt": item.get("publishedAt", ""),
                        "source": item.get("source", {}).get("name", ""),
                        "category": "breaking",
                        "priority": "high",
                        "read_time": self.calculate_read_time(item.get("content", ""))
                    })
                return {"articles": articles, "count": len(articles)}
            return {"articles": [], "count": 0}
        except Exception:
            return {"articles": [], "count": 0}

    def get_featured_stories(self):
        """Get featured/editor's pick stories"""
        try:
            url = "https://gnews.io/api/v4/search"
            params = {
                "q": "featured story important",
                "lang": "en",
                "max": 8,
                "token": GNEWS_API_KEY
            }
            response = requests.get(url, params=params, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                articles = []
                for item in data.get("articles", []):
                    articles.append({
                        "id": item.get("url", "").split("/")[-1][:20],
                        "title": item.get("title", ""),
                        "description": item.get("description", ""),
                        "url": item.get("url", ""),
                        "image": item.get("image", ""),
                        "publishedAt": item.get("publishedAt", ""),
                        "source": item.get("source", {}).get("name", ""),
                        "category": "featured",
                        "featured": True,
                        "read_time": self.calculate_read_time(item.get("content", ""))
                    })
                return {"articles": articles, "count": len(articles)}
            return {"articles": [], "count": 0}
        except Exception:
            return {"articles": [], "count": 0}

    def get_news_categories(self):
        """Get available news categories"""
        return {
            "categories": [
                {"id": "headlines", "name": "Top Headlines", "icon": ""},
                {"id": "food_health", "name": "Food & Health", "icon": ""},
                {"id": "technology", "name": "Technology", "icon": ""},
                {"id": "business", "name": "Business", "icon": ""},
                {"id": "entertainment", "name": "Entertainment", "icon": ""},
                {"id": "sports", "name": "Sports", "icon": ""},
                {"id": "local", "name": "Local News", "icon": ""},
                {"id": "breaking", "name": "Breaking News", "icon": ""},
                {"id": "featured", "name": "Featured", "icon": ""}
            ]
        }

    def analyze_sentiment(self, text):
        """Simple sentiment analysis"""
        positive_words = ['good', 'great', 'excellent', 'amazing', 'wonderful', 'positive', 'success']
        negative_words = ['bad', 'terrible', 'awful', 'horrible', 'negative', 'failure', 'crisis']
        
        text_lower = text.lower()
        positive_count = sum(1 for word in positive_words if word in text_lower)
        negative_count = sum(1 for word in negative_words if word in text_lower)
        
        if positive_count > negative_count:
            return "positive"
        elif negative_count > positive_count:
            return "negative"
        else:
            return "neutral"

    def calculate_read_time(self, content):
        """Calculate estimated read time"""
        if not content:
            return "1 min"
        words = len(content.split())
        minutes = max(1, words // 200)  # Average reading speed: 200 words per minute
        return f"{minutes} min"

    def extract_tags(self, text):
        """Extract relevant tags from text"""
        common_tags = ['technology', 'health', 'business', 'politics', 'sports', 'entertainment', 'science', 'education']
        text_lower = text.lower()
        found_tags = [tag for tag in common_tags if tag in text_lower]
        return found_tags[:5]  # Return max 5 tags

@method_decorator(csrf_exempt, name='dispatch')
class AppleSignInView(APIView):
    def post(self, request):
        # Get the credential details from frontend
        username = request.data.get("username")  # email (might be null for returning users)
        first_name = request.data.get("firstName", "")
        last_name = request.data.get("lastName", "")
        social_login_id = request.data.get("socialLoginId")
        social_login_type = request.data.get("socialLoginType", "APPLE")
        device_token = request.data.get("deviceToken", "")
        terms_accepted = request.data.get("termsAccepted", False)
        
        # Debug logging for incoming request
        print(f"DEBUG: Incoming request data:")
        print(f"  username: {username}")
        print(f"  firstName: {first_name}")
        print(f"  lastName: {last_name}")
        print(f"  socialLoginId: {social_login_id}")
        print(f"  socialLoginType: {social_login_type}")
        
        # Validate required fields
        if not social_login_id:
            return Response({"error": "Missing socialLoginId"}, status=status.HTTP_400_BAD_REQUEST)
        
        # For new users, validate terms acceptance
        if not username:  # This indicates a returning user, skip terms validation
            pass
        elif not terms_accepted:
            return Response({"error": "You must accept the terms and conditions to create an account."}, status=status.HTTP_400_BAD_REQUEST)

        User = get_user_model()
        
        # Try to find user by social_login_id first (for returning users)
        users = User.objects.filter(social_login_id=social_login_id, social_login_type=social_login_type)
        
        if users.exists():
            # If multiple users found, log warning and use the first one
            if users.count() > 1:
                print(f"WARNING: Multiple users found with social_login_id: {social_login_id}")
                print(f"Found {users.count()} users, using the first one")
            
            user = users.first()
            created = False
        else:
            # If user not found by social_login_id, check if we have email for new user
            if not username:
                return Response({"error": "Missing username (email) for new user"}, status=status.HTTP_400_BAD_REQUEST)
            
            # Create new user
            # Combine first_name and last_name to create full_name
            full_name = f"{first_name} {last_name}".strip()
            if not full_name:  # Fallback if both names are empty
                full_name = "Apple User"
            
            user = User.objects.create(
                email=username,
                username=username.split("@")[0],
                first_name=first_name,
                last_name=last_name,
                full_name=full_name,
                social_login_id=social_login_id,
                social_login_type=social_login_type,
                device_token=device_token,
                is_terms=True,  # Set terms acceptance for new users
            )
            created = True
        
        # For existing users, update device token if provided
        if not created:
            if device_token:
                user.device_token = device_token
                user.save()
            
            # Debug logging
            print(f"DEBUG: Found existing user - Email: {user.email}, First: {user.first_name}, Last: {user.last_name}")
            
            # For existing users, use stored data from database
            # If stored data is null/empty, try to update with current request data
            stored_first_name = user.first_name or first_name or ""
            stored_last_name = user.last_name or last_name or ""
            stored_email = user.email
            
            # If we have better data from the request, update the user
            if (not user.first_name and first_name) or (not user.last_name and last_name):
                if first_name:
                    user.first_name = first_name
                if last_name:
                    user.last_name = last_name
                user.save()
                print(f"DEBUG: Updated user with new data - First: {user.first_name}, Last: {user.last_name}")
            
            # If we still have null values, try to use a default or ask frontend to provide data
            if not stored_first_name and not stored_last_name:
                print("DEBUG: WARNING - User has no name data stored and none provided in request")
                # For Apple users, we might need to ask them to provide their name
                # or use a default until they update their profile
                stored_first_name = "Apple User"
                stored_last_name = ""
                print(f"DEBUG: Using fallback name - First: {stored_first_name}, Last: {stored_last_name}")
        else:
            # For new users, use the data from the request
            stored_first_name = first_name
            stored_last_name = last_name
            stored_email = username
            print(f"DEBUG: Created new user - Email: {stored_email}, First: {stored_first_name}, Last: {stored_last_name}")

        # Generate JWT tokens for the user
        from rest_framework_simplejwt.tokens import RefreshToken
        refresh = RefreshToken.for_user(user)
        access_token = str(refresh.access_token)

        # Get the full_name from the database (for both new and existing users)
        stored_full_name = user.full_name or f"{stored_first_name} {stored_last_name}".strip()
        if not stored_full_name:  # Final fallback
            stored_full_name = "Apple User"
        
        # Debug logging for response
        print(f"DEBUG: Response data - Email: {stored_email}, First: {stored_first_name}, Last: {stored_last_name}")
        print(f"DEBUG: Full name from DB: '{stored_full_name}'")
        
        # Check if user needs to update their profile
        needs_profile_update = (not user.first_name or not user.last_name) and (not first_name or not last_name)
        
        return Response({
            "access_token": access_token,
            "refresh_token": str(refresh),
            "created": created,
            "email": stored_email,
            "first_name": stored_first_name,
            "last_name": stored_last_name,
            "full_name": stored_full_name,
            "social_login_id": user.social_login_id,
            "social_login_type": user.social_login_type,
            "has_answered_onboarding": user.has_answered_onboarding,
            "needs_profile_update": needs_profile_update,
        }, status=status.HTTP_200_OK)

def fetch_openfoodfacts_product(barcode, max_retries=1):
    """
    Robust function to fetch product data from OpenFoodFacts API with proper headers and retries.
    
    Args:
        barcode (str): The product barcode
        max_retries (int): Maximum number of retry attempts (default 1 for faster response)
    
    Returns:
        dict: Product data if successful, None if failed
    """
    import re
    import time
    
    # Clean and validate barcode
    if not barcode:
        return None
    
    # Remove any non-digit characters and ensure it's a valid barcode
    cleaned_barcode = re.sub(r'[^0-9]', '', str(barcode))
    if len(cleaned_barcode) < 8 or len(cleaned_barcode) > 14:
        return None
    # Proper headers for OpenFoodFacts API
    headers = {
        'User-Agent': 'FoodApp/1.0 (https://foodapp.com; contact@foodapp.com)',
        'Accept': 'application/json',
        'Accept-Language': 'en-US,en;q=0.9',
    }
    
    # Try different API endpoints and versions
    api_endpoints = [
        f"https://world.openfoodfacts.org/api/v2/product/{cleaned_barcode}.json",
        f"https://world.openfoodfacts.org/api/v1/product/{cleaned_barcode}.json",
        f"https://world.openfoodfacts.org/api/v0/product/{cleaned_barcode}.json",
        f"https://world.openfoodfacts.org/cgi/product_jqm.pl?json=1&code={cleaned_barcode}",
    ]
    
    for attempt in range(max_retries):
        for endpoint in api_endpoints:
            try:
                logging.info(f"Attempting OpenFoodFacts API call: {endpoint}")
                
                response = requests.get(
                    endpoint,
                    headers=headers,
                    timeout=8,  # Reduced timeout for faster response
                    allow_redirects=True
                )
                
                if response.status_code == 200:
                    data = response.json()
                    
                    # Check if product exists and has required data
                    if data.get("status") == 1 and data.get("product"):
                        product = data["product"]
                        
                        # Log what we found for debugging
                        product_name = product.get("product_name") or product.get("generic_name") or product.get("brands") or "Unknown"
                        has_ingredients = bool(product.get("ingredients_text") or product.get("ingredients"))
                        has_nutrition = bool(product.get("nutriments"))
                        
                        logging.info(f"Product found: {product_name} (Barcode: {cleaned_barcode})")
                        logging.info(f"  - Has ingredients: {has_ingredients}")
                        logging.info(f"  - Has nutrition: {has_nutrition}")
                        logging.info(f"  - Brand: {product.get('brands', 'Unknown')}")
                        
                        # Return product even if it has incomplete data - let the main logic handle it
                        return product
                    elif data.get("status") == 0:
                        logging.info(f"Product not found in OpenFoodFacts database: {cleaned_barcode}")
                        continue
                    else:
                        logging.warning(f"Unexpected response format from OpenFoodFacts: {data.get('status')}")
                        continue
                        
                elif response.status_code == 404:
                    logging.info(f"Product not found (404): {cleaned_barcode}")
                    continue
                elif response.status_code == 429:
                    logging.warning(f"Rate limited by OpenFoodFacts API (429)")
                    # Don't retry on rate limit, just continue to next API
                    return None
                else:
                    logging.warning(f"OpenFoodFacts API returned status {response.status_code}")
                    continue
                    
            except requests.exceptions.Timeout:
                logging.warning(f"OpenFoodFacts API timeout")
                continue
            except requests.exceptions.RequestException as e:
                logging.warning(f"OpenFoodFacts API request error: {e}")
                continue
            except (ValueError, json.JSONDecodeError) as e:
                logging.warning(f"OpenFoodFacts API JSON decode error: {e}")
                continue
            except Exception as e:
                logging.error(f"Unexpected error in OpenFoodFacts API call: {e}")
                continue
    
    logging.info(f"Product not found in OpenFoodFacts: {cleaned_barcode}")
    return None

def search_openfoodfacts_by_name(product_name, max_results=5):
    """
    Search for products in OpenFoodFacts by name as a fallback when barcode lookup fails.
    
    Args:
        product_name (str): The product name to search for
        max_results (int): Maximum number of results to return
    
    Returns:
        list: List of product data dictionaries, empty if failed
    """
    if not product_name or len(product_name.strip()) < 3:
        return []
    
    headers = {
        'User-Agent': 'FoodApp/1.0 (https://foodapp.com; contact@foodapp.com)',
        'Accept': 'application/json',
        'Accept-Language': 'en-US,en;q=0.9',
    }
    
    try:
        # Use OpenFoodFacts search API
        search_url = f"https://world.openfoodfacts.org/cgi/search.pl?search_terms={product_name}&search_simple=1&action=process&json=1&page_size={max_results}"
        
        response = requests.get(
            search_url,
            headers=headers,
            timeout=10
        )
        
        if response.status_code == 200:
            data = response.json()
            products = data.get('products', [])
            
            # Filter products that have required fields
            valid_products = []
            for product in products:
                if (product.get("product_name") or product.get("generic_name") or product.get("brands")) and product.get("ingredients_text"):
                    valid_products.append(product)
            
            logging.info(f"Found {len(valid_products)} products by name search for: {product_name}")
            return valid_products[:max_results]
        else:
            logging.warning(f"OpenFoodFacts search API returned status {response.status_code}")
            return []
            
    except Exception as e:
        logging.error(f"Error in OpenFoodFacts name search: {e}")
        return []

def fetch_upc_database_product(barcode, api_key=None):
    """
    Fetch product data from UPC Database API.
    This API has comprehensive US and international product coverage.
    
    Args:
        barcode (str): The product barcode
        api_key (str): Optional API key for UPC Database
    
    Returns:
        dict: Product data if successful, None if failed
    """
    import requests
    import logging
    
    if not barcode:
        return None
    
    # Clean barcode
    cleaned_barcode = re.sub(r'[^0-9]', '', str(barcode))
    if len(cleaned_barcode) < 8 or len(cleaned_barcode) > 14:
        return None
    
    headers = {
        'User-Agent': 'FoodApp/1.0 (https://foodapp.com; contact@foodapp.com)',
        'Accept': 'application/json',
    }
    
    # Try UPC Database API (free tier available)
    try:
        # Free endpoint (limited requests per day)
        url = f"https://api.upcdatabase.org/product/{cleaned_barcode}"
        
        response = requests.get(url, headers=headers, timeout=6)
        
        if response.status_code == 200:
            data = response.json()
            
            # Check if product exists
            if data.get('success') and data.get('product'):
                product = data['product']
                
                # Map UPC Database fields to our format
                mapped_product = {
                    'product_name': product.get('title') or product.get('name'),
                    'brands': product.get('brand'),
                    'generic_name': product.get('description'),
                    'ingredients_text': product.get('ingredients'),
                    'image_url': product.get('image'),
                    'categories': product.get('category'),
                    'countries': product.get('country'),
                    'nutriments': {
                        'energy-kcal': product.get('calories'),
                        'proteins': product.get('protein'),
                        'carbohydrates': product.get('carbohydrates'),
                        'fat': product.get('fat'),
                        'fiber': product.get('fiber'),
                        'sugars': product.get('sugar'),
                        'sodium': product.get('sodium'),
                    }
                }
                
                logging.info(f"UPC Database product found: {mapped_product.get('product_name', 'Unknown')}")
                return mapped_product
                
        elif response.status_code == 404:
            logging.info(f"Product not found in UPC Database: {cleaned_barcode}")
        elif response.status_code == 403:
            logging.warning(f"UPC Database API access denied (403) - may need API key")
        else:
            logging.warning(f"UPC Database API returned status {response.status_code}")
            
    except requests.exceptions.Timeout:
        logging.warning(f"UPC Database API timeout")
    except requests.exceptions.RequestException as e:
        logging.warning(f"UPC Database API request error: {e}")
    except Exception as e:
        logging.warning(f"UPC Database API error: {e}")
    
    return None

def fetch_barcode_lookup_product(barcode):
    """
    Fetch product data from Barcode Lookup API.
    This API has good global coverage for various barcode formats.
    
    Args:
        barcode (str): The product barcode
    
    Returns:
        dict: Product data if successful, None if failed
    """
    import requests
    import logging
    
    if not barcode:
        return None
    
    # Clean barcode
    cleaned_barcode = re.sub(r'[^0-9]', '', str(barcode))
    if len(cleaned_barcode) < 8 or len(cleaned_barcode) > 14:
        return None
    
    headers = {
        'User-Agent': 'FoodApp/1.0 (https://foodapp.com; contact@foodapp.com)',
        'Accept': 'application/json',
    }
    
    try:
        # Barcode Lookup API (free tier)
        url = f"https://api.barcodelookup.com/v3/products?barcode={cleaned_barcode}"
        
        response = requests.get(url, headers=headers, timeout=6)
        
        if response.status_code == 200:
            data = response.json()
            products = data.get('products', [])
            
            if products:
                product = products[0]  # Get first product
                
                # Map Barcode Lookup fields to our format
                mapped_product = {
                    'product_name': product.get('title') or product.get('product_name'),
                    'brands': product.get('brand'),
                    'generic_name': product.get('description'),
                    'ingredients_text': product.get('ingredients'),
                    'image_url': product.get('images', [{}])[0].get('url') if product.get('images') else None,
                    'categories': product.get('category'),
                    'countries': product.get('country'),
                    'nutriments': {
                        'energy-kcal': product.get('nutrition_facts', {}).get('calories'),
                        'proteins': product.get('nutrition_facts', {}).get('protein'),
                        'carbohydrates': product.get('nutrition_facts', {}).get('carbohydrates'),
                        'fat': product.get('nutrition_facts', {}).get('fat'),
                        'fiber': product.get('nutrition_facts', {}).get('fiber'),
                        'sugars': product.get('nutrition_facts', {}).get('sugar'),
                        'sodium': product.get('nutrition_facts', {}).get('sodium'),
                    }
                }
                
                logging.info(f"Barcode Lookup product found: {mapped_product.get('product_name', 'Unknown')}")
                return mapped_product
                
        elif response.status_code == 404:
            logging.info(f"Product not found in Barcode Lookup: {cleaned_barcode}")
        elif response.status_code == 403:
            logging.warning(f"Barcode Lookup API access denied (403) - may need API key")
        else:
            logging.warning(f"Barcode Lookup API returned status {response.status_code}")
            
    except requests.exceptions.Timeout:
        logging.warning(f"Barcode Lookup API timeout")
    except requests.exceptions.RequestException as e:
        logging.warning(f"Barcode Lookup API request error: {e}")
    except Exception as e:
        logging.warning(f"Barcode Lookup API error: {e}")
    
    return None

def fetch_ean_search_product(barcode):
    """
    Fetch product data from EAN Search API.
    This API specializes in European Article Numbers but has global coverage.
    
    Args:
        barcode (str): The product barcode
    
    Returns:
        dict: Product data if successful, None if failed
    """
    import requests
    import logging
    
    if not barcode:
        return None
    
    # Clean barcode
    cleaned_barcode = re.sub(r'[^0-9]', '', str(barcode))
    if len(cleaned_barcode) < 8 or len(cleaned_barcode) > 14:
        return None
    
    headers = {
        'User-Agent': 'FoodApp/1.0 (https://foodapp.com; contact@foodapp.com)',
        'Accept': 'application/json',
    }
    
    try:
        # EAN Search API (free tier)
        url = f"https://api.ean-search.org/ean/{cleaned_barcode}"
        
        response = requests.get(url, headers=headers, timeout=6)
        
        if response.status_code == 200:
            data = response.json()
            
            if data.get('found') and data.get('product'):
                product = data['product']
                
                # Map EAN Search fields to our format
                mapped_product = {
                    'product_name': product.get('name') or product.get('title'),
                    'brands': product.get('brand'),
                    'generic_name': product.get('description'),
                    'ingredients_text': product.get('ingredients'),
                    'image_url': product.get('image'),
                    'categories': product.get('category'),
                    'countries': product.get('country'),
                    'nutriments': {
                        'energy-kcal': product.get('calories'),
                        'proteins': product.get('protein'),
                        'carbohydrates': product.get('carbs'),
                        'fat': product.get('fat'),
                        'fiber': product.get('fiber'),
                        'sugars': product.get('sugar'),
                        'sodium': product.get('sodium'),
                    }
                }
                
                logging.info(f"EAN Search product found: {mapped_product.get('product_name', 'Unknown')}")
                return mapped_product
                
        elif response.status_code == 404:
            logging.info(f"Product not found in EAN Search: {cleaned_barcode}")
        elif response.status_code == 403:
            logging.warning(f"EAN Search API access denied (403) - may need API key")
        else:
            logging.warning(f"EAN Search API returned status {response.status_code}")
            
    except requests.exceptions.Timeout:
        logging.warning(f"EAN Search API timeout")
    except requests.exceptions.RequestException as e:
        logging.warning(f"EAN Search API request error: {e}")
    except Exception as e:
        logging.warning(f"EAN Search API error: {e}")
    
    return None







def fetch_nutritionix_product(barcode):
    """
    Fetch product data from Nutritionix API.
    This API provides comprehensive nutrition data for US products.
    
    Args:
        barcode (str): The product barcode
    
    Returns:
        dict: Product data if successful, None if failed
    """
    import requests
    import logging
    
    if not barcode:
        return None
    
    # Clean barcode
    cleaned_barcode = re.sub(r'[^0-9]', '', str(barcode))
    if len(cleaned_barcode) < 8 or len(cleaned_barcode) > 14:
        return None
    
    headers = {
        'User-Agent': 'FoodApp/1.0 (https://foodapp.com; contact@foodapp.com)',
        'Accept': 'application/json',
        'x-app-id': 'f466a679',  # You'll need to get this
        'x-app-key': '2a8c378d0b560cf5d69e73be8be8a1bd',  # You'll need to get this
    }
    
    try:
        # Nutritionix API
        url = f"https://trackapi.nutritionix.com/v2/search/item?upc={cleaned_barcode}"
        
        response = requests.get(url, headers=headers, timeout=6)
        
        if response.status_code == 200:
            data = response.json()
            
            if data.get('foods') and len(data['foods']) > 0:
                product = data['foods'][0]
                
                # Map Nutritionix fields to our format
                mapped_product = {
                    'product_name': product.get('food_name'),
                    'brands': product.get('brand_name'),
                    'generic_name': product.get('food_description'),
                    'ingredients_text': product.get('ingredients'),
                    'image_url': product.get('photo', {}).get('thumb'),
                    'categories': product.get('food_category'),
                    'countries': 'US',  # Nutritionix is primarily US-focused
                    'nutriments': {
                        'energy-kcal': product.get('nf_calories'),
                        'proteins': product.get('nf_protein'),
                        'carbohydrates': product.get('nf_total_carbohydrate'),
                        'fat': product.get('nf_total_fat'),
                        'fiber': product.get('nf_dietary_fiber'),
                        'sugars': product.get('nf_sugars'),
                        'sodium': product.get('nf_sodium'),
                    }
                }
                
                logging.info(f"Nutritionix product found: {mapped_product.get('product_name', 'Unknown')}")
                return mapped_product
                
        elif response.status_code == 404:
            logging.info(f"Product not found in Nutritionix: {cleaned_barcode}")
        elif response.status_code == 401:
            logging.warning(f"Nutritionix API authentication failed - need valid app_id and app_key")
        else:
            logging.warning(f"Nutritionix API returned status {response.status_code}")
            
    except requests.exceptions.Timeout:
        logging.warning(f"Nutritionix API timeout")
    except requests.exceptions.RequestException as e:
        logging.warning(f"Nutritionix API request error: {e}")
    except Exception as e:
        logging.warning(f"Nutritionix API error: {e}")
    
    return None



def fetch_product_api_data(barcode):
    """
    Fetch product data from Product API.
    This API aggregates data from multiple sources.
    
    Args:
        barcode (str): The product barcode
    
    Returns:
        dict: Product data if successful, None if failed
    """
    import requests
    import logging
    
    if not barcode:
        return None
    
    # Clean barcode
    cleaned_barcode = re.sub(r'[^0-9]', '', str(barcode))
    if len(cleaned_barcode) < 8 or len(cleaned_barcode) > 14:
        return None
    
    headers = {
        'User-Agent': 'FoodApp/1.0 (https://foodapp.com; contact@foodapp.com)',
        'Accept': 'application/json',
    }
    
    try:
        # Product API (free tier)
        url = f"https://api.product.com/v1/products/{cleaned_barcode}"
        
        response = requests.get(url, headers=headers, timeout=6)
        
        if response.status_code == 200:
            data = response.json()
            
            if data.get('success') and data.get('product'):
                product = data['product']
                
                # Map Product API fields to our format
                mapped_product = {
                    'product_name': product.get('name') or product.get('title'),
                    'brands': product.get('brand'),
                    'generic_name': product.get('description'),
                    'ingredients_text': product.get('ingredients'),
                    'image_url': product.get('image'),
                    'categories': product.get('category'),
                    'countries': product.get('country'),
                    'nutriments': {
                        'energy-kcal': product.get('nutrition', {}).get('calories'),
                        'proteins': product.get('nutrition', {}).get('protein'),
                        'carbohydrates': product.get('nutrition', {}).get('carbohydrates'),
                        'fat': product.get('nutrition', {}).get('fat'),
                        'fiber': product.get('nutrition', {}).get('fiber'),
                        'sugars': product.get('nutrition', {}).get('sugar'),
                        'sodium': product.get('nutrition', {}).get('sodium'),
                    }
                }
                
                logging.info(f"Product API product found: {mapped_product.get('product_name', 'Unknown')}")
                return mapped_product
                
        elif response.status_code == 404:
            logging.info(f"Product not found in Product API: {cleaned_barcode}")
        elif response.status_code == 403:
            logging.warning(f"Product API access denied (403) - may need API key")
        else:
            logging.warning(f"Product API returned status {response.status_code}")
            
    except requests.exceptions.Timeout:
        logging.warning(f"Product API timeout")
    except requests.exceptions.RequestException as e:
        logging.warning(f"Product API request error: {e}")
    except Exception as e:
        logging.warning(f"Product API error: {e}")
    
    return None

def fetch_multi_source_product(barcode, max_retries=1):
    """
    Fetch product data from multiple sources with fallback strategy.
    This function tries multiple APIs in sequence to maximize product coverage.
    
    Args:
        barcode (str): The product barcode
        max_retries (int): Maximum number of retry attempts per API (default 1 for faster response)
    
    Returns:
        dict: Best available product data, None if all sources fail
    """
    import time
    import logging
    
    if not barcode:
        return None
    
    # Clean barcode
    cleaned_barcode = re.sub(r'[^0-9]', '', str(barcode))
    if len(cleaned_barcode) < 8 or len(cleaned_barcode) > 14:
        return None
    
    # Define API sources in order of preference
    api_sources = [
        ('OpenFoodFacts', fetch_openfoodfacts_product),  # Global food database with ingredients
    ]
    
    best_product = None
    best_score = 0
    
    for source_name, api_function in api_sources:
        logging.info(f"Trying {source_name} for barcode: {cleaned_barcode}")
        
        # Try each API only once for faster response
        for attempt in range(max_retries):
            try:
                product_data = api_function(cleaned_barcode)
                
                if product_data:
                    # Score the product based on data completeness
                    score = 0
                    
                    # Basic product info (essential)
                    if product_data.get('product_name'):
                        score += 10
                    if product_data.get('brands'):
                        score += 5
                    
                    # Ingredients (very important for our use case)
                    if product_data.get('ingredients_text'):
                        score += 20
                    
                    # Nutrition data
                    if product_data.get('nutriments'):
                        nutriments = product_data['nutriments']
                        if any(nutriments.get(key) for key in ['energy-kcal', 'proteins', 'carbohydrates', 'fat']):
                            score += 15
                    
                    # Image
                    if product_data.get('image_url'):
                        score += 5
                    
                    # Categories and additional info
                    if product_data.get('categories'):
                        score += 3
                    if product_data.get('countries'):
                        score += 2
                    
                    logging.info(f"{source_name} product score: {score}")
                    
                    # Keep the best product found
                    if score > best_score:
                        best_score = score
                        best_product = product_data
                        best_product['data_source'] = source_name
                        best_product['data_score'] = score
                        
                        # If we have a high-quality product (good ingredients + nutrition), we can stop
                        if score >= 35:
                            logging.info(f"High-quality product found from {source_name}, stopping search")
                            return best_product
                    
                    # Found a product, no need to retry this API
                    break
                    
            except Exception as e:
                logging.warning(f"Error with {source_name} (attempt {attempt + 1}): {e}")
                # Don't retry on errors, just continue to next API
                break
        
        # Small delay between different APIs to be respectful
        time.sleep(0.2)
    
    if best_product:
        logging.info(f"Best product found from {best_product.get('data_source')} with score {best_product.get('data_score')}")
    else:
        logging.warning(f"No product found in any source for barcode: {cleaned_barcode}")
    
    return best_product

class AWSTextractOCRView(APIView):
    """
    AWS Textract-based OCR API for food label scanning.
    Provides enhanced text extraction with structured nutrition data and ingredients.
    """
    permission_classes = [IsAuthenticated]
    parser_classes = (MultiPartParser, FormParser)
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        # Initialize AWS Textract client
        try:
            aws_access_key = settings.AWS_ACCESS_KEY_ID
            aws_secret_key = settings.AWS_SECRET_ACCESS_KEY
            aws_region = settings.AWS_S3_REGION_NAME or 'us-east-1'
            
            print(f"AWS Access Key: {aws_access_key[:10]}..." if aws_access_key else "None")
            print(f"AWS Secret Key: {aws_secret_key[:10]}..." if aws_secret_key else "None")
            print(f"AWS Region: {aws_region}")
            
            if not aws_access_key or not aws_secret_key:
                logging.error("AWS credentials not found in settings")
                self.textract_client = None
                return
            
            self.textract_client = boto3.client(
                'textract',
                aws_access_key_id=aws_access_key,
                aws_secret_access_key=aws_secret_key,
                region_name=aws_region
            )
            print("AWS Textract client initialized successfully")
        except Exception as e:
            logging.error(f"Failed to initialize AWS Textract client: {e}")
            self.textract_client = None

    def get(self, request):
        """
        Test AWS Textract connection.
        """
        try:
            success, message = self.test_aws_connection()
            return Response({
                "success": success,
                "message": message,
                "aws_configured": self.textract_client is not None
            }, status=status.HTTP_200_OK)
        except Exception as e:
            return Response({
                "success": False,
                "message": f"Test failed: {str(e)}",
                "aws_configured": self.textract_client is not None
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    def post(self, request):
        """
        Process food label image using AWS Textract OCR.
        Returns structured nutrition data and ingredients.
        """
        try:
            # Check if user can scan
            # if not can_user_scan(request.user):
            #     return Response({
            #         "error": "Scan limit reached. Please upgrade to premium for unlimited scans."
            #     }, status=status.HTTP_403_FORBIDDEN)

            # Get image from request
            image_file = request.FILES.get('image')
            if not image_file:
                return Response({
                    "error": "No image provided"
                }, status=status.HTTP_400_BAD_REQUEST)

            # Save image and get URL
            image_content = image_file.read()
            print(f"Image content type: {type(image_content)}")
            print(f"Image content length: {len(image_content)} bytes")
            print(f"Image file name: {image_file.name}")
            print(f"Image content type: {image_file.content_type}")
            
            image_url = self.save_image(image_content)
            print(f"Image URL: {image_url}")
            
            # Extract text using AWS Textract (for fallback and display)
            extracted_text = self.extract_text_with_textract(image_content)
            if not extracted_text:
                return Response({
                    "error": "Failed to extract text from image"
                }, status=status.HTTP_400_BAD_REQUEST)
            print("Extracted text:", extracted_text)
            
            # Try to extract ingredients using Query feature first
            query_ingredients = self.extract_ingredients_with_query(image_content)
            print("Query ingredients:", query_ingredients)
            
            # Try to extract nutrition using Query feature first
            query_nutrition = self.extract_nutrition_with_query(image_content)
            print("Query nutrition:", query_nutrition)
            
            # Process nutrition data (use query results if available, otherwise fallback to text parsing)
            if query_nutrition:
                nutrition_data = self.process_query_nutrition_data(query_nutrition)
            else:
                nutrition_data = self.extract_nutrition_data_structured(extracted_text)
            print("Final nutrition data:", nutrition_data)
            
            # Process ingredients data (use query results if available, otherwise fallback to text parsing)
            if query_ingredients:
                ingredients_data = self.process_query_ingredients_data(query_ingredients)
            else:
                ingredients_data = self.extract_ingredients_structured(extracted_text)
            print("Final ingredients data:", ingredients_data)
            
            # Validate product safety
            safety_results = self.validate_product_safety(request.user, ingredients_data.get('ingredients', []))
            
            # Generate AI insights
            ai_results = self.generate_ai_insights(nutrition_data, safety_results.get('flagged_ingredients', []))
            
            # Save scan history
            self.save_scan_history(
                user=request.user,
                image_url=image_url,
                extracted_text=extracted_text,
                nutrition_data=nutrition_data,
                ai_results=ai_results,
                safety_status=safety_results.get('safety_status', 'unknown'),
                flagged_ingredients=safety_results.get('flagged_ingredients', []),
                go_ingredients=safety_results.get('go_ingredients', []),
                caution_ingredients=safety_results.get('caution_ingredients', []),
                product_name=nutrition_data.get('product_name', 'AWS OCR Product')
            )

            # Prepare response
            response_data = {
                "success": True,
                "product_name": nutrition_data.get('product_name', 'Unknown Product'),
                "nutrition_data": nutrition_data,
                "ingredients": ingredients_data,
                "safety_analysis": {
                    "safety_status": safety_results.get('safety_status', 'unknown'),
                    "flagged_ingredients": safety_results.get('flagged_ingredients', []),
                    "go_ingredients": safety_results.get('go_ingredients', []),
                    "caution_ingredients": safety_results.get('caution_ingredients', []),
                    "total_ingredients": len(ingredients_data.get('ingredients', [])),
                    "flagged_count": len(safety_results.get('flagged_ingredients', [])),
                    "safe_count": len(safety_results.get('go_ingredients', [])) + len(safety_results.get('caution_ingredients', []))
                },
                "ai_insights": ai_results,
                "image_url": image_url,
                "extracted_text": extracted_text
            }

            return Response(response_data, status=status.HTTP_200_OK)

        except Exception as e:
            logging.error(f"AWS Textract OCR error: {e}", exc_info=True)
            return Response({
                "error": f"Processing failed: {str(e)}"
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    def extract_text_with_textract(self, image_content):
        """
        Extract text from image using AWS Textract with enhanced features.
        """
        try:
            if not self.textract_client:
                raise Exception("AWS Textract client not initialized")

            # Ensure image_content is bytes
            if not isinstance(image_content, bytes):
                logging.error("Image content must be bytes")
                return ""

            # Check image size (AWS Textract limit is 5MB)
            if len(image_content) > 5 * 1024 * 1024:
                logging.error("Image too large for AWS Textract (max 5MB)")
                return ""

            # Try analyze_document first (more features)
            try:
                response = self.textract_client.analyze_document(
                    Document={
                        'Bytes': image_content
                    },
                    FeatureTypes=['TABLES', 'FORMS', 'LINES']
                )
                
                # Extract text with spatial information
                extracted_text = ""
                blocks = response.get('Blocks', [])
                
                # Sort blocks by geometry for proper reading order
                text_blocks = [block for block in blocks if block['BlockType'] == 'LINE']
                text_blocks.sort(key=lambda x: (x['Geometry']['BoundingBox']['Top'], x['Geometry']['BoundingBox']['Left']))
                
                for block in text_blocks:
                    if 'Text' in block:
                        extracted_text += block['Text'] + "\n"

                # Also extract table data if present
                table_data = self.extract_table_data(blocks)
                if table_data:
                    extracted_text += "\n" + table_data

                return extracted_text.strip()
                
            except ClientError as e:
                error_code = e.response['Error']['Code']
                if error_code in ['InvalidDocumentException', 'InvalidParameterException']:
                    logging.warning(f"analyze_document failed with {error_code}, trying detect_document_text")
                    
                    # Fallback to simpler text detection
                    try:
                        response = self.textract_client.detect_document_text(
                            Document={
                                'Bytes': image_content
                            }
                        )
                        
                        # Extract text from simpler response
                        extracted_text = ""
                        blocks = response.get('Blocks', [])
                        
                        for block in blocks:
                            if block['BlockType'] == 'LINE' and 'Text' in block:
                                extracted_text += block['Text'] + "\n"
                        
                        return extracted_text.strip()
                        
                    except Exception as fallback_error:
                        logging.error(f"Fallback detect_document_text also failed: {fallback_error}")
                        raise e  # Re-raise original error
                else:
                    raise e  # Re-raise non-fallback errors

        except ClientError as e:
            error_code = e.response['Error']['Code']
            error_message = e.response['Error'].get('Message', '')
            logging.error(f"AWS Textract error: {error_code} - {error_message}")
            
            if error_code == 'InvalidDocumentException':
                logging.error("Invalid document format for Textract - check image format")
            elif error_code == 'DocumentTooLargeException':
                logging.error("Document too large for Textract (max 5MB)")
            elif error_code == 'InvalidParameterException':
                logging.error("Invalid parameter - check image data format")
            else:
                logging.error(f"Unknown AWS Textract error: {error_code}")
            return ""
        except NoCredentialsError:
            logging.error("AWS credentials not found")
            return ""
        except Exception as e:
            logging.error(f"Textract extraction error: {e}")
            return ""

    def extract_ingredients_with_query(self, image_content):
        """
        Extract ingredients using AWS Textract Query feature for precise extraction.
        """
        try:
            if not self.textract_client:
                raise Exception("AWS Textract client not initialized")

            # Query for ingredients
            queries = [
                {
                    'Text': 'What are the ingredients?',
                    'Alias': 'ingredients'
                },
                {
                    'Text': 'List all ingredients',
                    'Alias': 'ingredients_list'
                },
                {
                    'Text': 'What ingredients are in this product?',
                    'Alias': 'product_ingredients'
                }
            ]

            try:
                response = self.textract_client.analyze_document(
                    Document={
                        'Bytes': image_content
                    },
                    FeatureTypes=['QUERIES'],
                    QueriesConfig={
                        'Queries': queries
                    }
                )
                
                ingredients = []
                
                # Extract answers from the response
                for block in response.get('Blocks', []):
                    if block['BlockType'] == 'QUERY_RESULT':
                        if 'Relationships' in block:
                            for relationship in block['Relationships']:
                                if relationship['Type'] == 'ANSWER':
                                    for answer_id in relationship['Ids']:
                                        # Find the answer block
                                        for answer_block in response.get('Blocks', []):
                                            if answer_block['Id'] == answer_id and 'Text' in answer_block:
                                                ingredients.append(answer_block['Text'])
                
                return ingredients
                
            except ClientError as e:
                error_code = e.response['Error']['Code']
                if error_code in ['InvalidDocumentException', 'InvalidParameterException']:
                    logging.warning(f"Query failed with {error_code}, falling back to text extraction")
                    return []
                else:
                    raise e

        except Exception as e:
            logging.error(f"Textract Query extraction error: {e}")
            return []

    def extract_nutrition_with_query(self, image_content):
        """
        Extract nutrition data using AWS Textract Query feature.
        """
        try:
            if not self.textract_client:
                raise Exception("AWS Textract client not initialized")

            # Query for nutrition information
            queries = [
                {
                    'Text': 'What is the energy/calories value?',
                    'Alias': 'energy'
                },
                {
                    'Text': 'What is the protein content?',
                    'Alias': 'protein'
                },
                {
                    'Text': 'What is the total fat content?',
                    'Alias': 'total_fat'
                },
                {
                    'Text': 'What is the saturated fat content?',
                    'Alias': 'saturated_fat'
                },
                {
                    'Text': 'What is the carbohydrate content?',
                    'Alias': 'carbohydrates'
                },
                {
                    'Text': 'What is the sugar content?',
                    'Alias': 'sugars'
                },
                {
                    'Text': 'What is the sodium content?',
                    'Alias': 'sodium'
                },
                {
                    'Text': 'What is the fiber content?',
                    'Alias': 'fiber'
                }
            ]

            try:
                response = self.textract_client.analyze_document(
                    Document={
                        'Bytes': image_content
                    },
                    FeatureTypes=['QUERIES'],
                    QueriesConfig={
                        'Queries': queries
                    }
                )
                
                nutrition_data = {}
                
                # Extract answers from the response
                for block in response.get('Blocks', []):
                    if block['BlockType'] == 'QUERY_RESULT':
                        query_alias = block.get('Query', {}).get('Alias', '')
                        if 'Relationships' in block:
                            for relationship in block['Relationships']:
                                if relationship['Type'] == 'ANSWER':
                                    for answer_id in relationship['Ids']:
                                        # Find the answer block
                                        for answer_block in response.get('Blocks', []):
                                            if answer_block['Id'] == answer_id and 'Text' in answer_block:
                                                nutrition_data[query_alias] = answer_block['Text']
                
                return nutrition_data
                
            except ClientError as e:
                error_code = e.response['Error']['Code']
                if error_code in ['InvalidDocumentException', 'InvalidParameterException']:
                    logging.warning(f"Nutrition Query failed with {error_code}, falling back to text extraction")
                    return {}
                else:
                    raise e

        except Exception as e:
            logging.error(f"Nutrition Query extraction error: {e}")
            return {}

    def process_query_nutrition_data(self, query_nutrition):
        """
        Process nutrition data from Textract Query results.
        """
        nutrition_data = {
            "product_name": "",
            "serving_size": "",
            "servings_per_container": "",
            "calories": {"value": 0, "unit": "kcal", "daily_value": 0},
            "total_fat": {"value": 0, "unit": "g", "daily_value": 0},
            "saturated_fat": {"value": 0, "unit": "g", "daily_value": 0},
            "trans_fat": {"value": 0, "unit": "g", "daily_value": 0},
            "cholesterol": {"value": 0, "unit": "mg", "daily_value": 0},
            "sodium": {"value": 0, "unit": "mg", "daily_value": 0},
            "total_carbohydrates": {"value": 0, "unit": "g", "daily_value": 0},
            "dietary_fiber": {"value": 0, "unit": "g", "daily_value": 0},
            "total_sugars": {"value": 0, "unit": "g", "daily_value": 0},
            "added_sugars": {"value": 0, "unit": "g", "daily_value": 0},
            "protein": {"value": 0, "unit": "g", "daily_value": 0},
            "vitamin_d": {"value": 0, "unit": "mcg", "daily_value": 0},
            "calcium": {"value": 0, "unit": "mg", "daily_value": 0},
            "iron": {"value": 0, "unit": "mg", "daily_value": 0},
            "potassium": {"value": 0, "unit": "mg", "daily_value": 0}
        }

        # Map query results to nutrition data
        for key, value in query_nutrition.items():
            if value:
                # Extract numeric value and unit from the query result
                match = re.search(r'(\d+(?:\.\d+)?)\s*([a-zA-Z]+)', value)
                if match:
                    numeric_value = float(match.group(1))
                    unit = match.group(2).lower()
                    
                    if key == 'energy':
                        nutrition_data['calories']['value'] = numeric_value
                        nutrition_data['calories']['unit'] = 'kcal' if 'kcal' in unit else unit
                    elif key == 'protein':
                        nutrition_data['protein']['value'] = numeric_value
                        nutrition_data['protein']['unit'] = 'g'
                    elif key == 'total_fat':
                        nutrition_data['total_fat']['value'] = numeric_value
                        nutrition_data['total_fat']['unit'] = 'g'
                    elif key == 'saturated_fat':
                        nutrition_data['saturated_fat']['value'] = numeric_value
                        nutrition_data['saturated_fat']['unit'] = 'g'
                    elif key == 'carbohydrates':
                        nutrition_data['total_carbohydrates']['value'] = numeric_value
                        nutrition_data['total_carbohydrates']['unit'] = 'g'
                    elif key == 'sugars':
                        nutrition_data['total_sugars']['value'] = numeric_value
                        nutrition_data['total_sugars']['unit'] = 'g'
                    elif key == 'sodium':
                        nutrition_data['sodium']['value'] = numeric_value
                        nutrition_data['sodium']['unit'] = 'mg'
                    elif key == 'fiber':
                        nutrition_data['dietary_fiber']['value'] = numeric_value
                        nutrition_data['dietary_fiber']['unit'] = 'g'

        return nutrition_data

    def process_query_ingredients_data(self, query_ingredients):
        """
        Process ingredients data from Textract Query results.
        """
        ingredients_data = {
            "ingredients": [],
            "allergens": [],
            "contains": [],
            "may_contain": []
        }

        if query_ingredients:
            # Join all ingredient responses and clean them up
            ingredients_text = " ".join(query_ingredients)
            
            # Clean up the ingredients text
            ingredients_text = re.sub(r'[^\w\s,()%.]', ' ', ingredients_text)  # Remove special characters except important ones
            ingredients_text = re.sub(r'\s+', ' ', ingredients_text)  # Normalize whitespace
            
            # Split ingredients by common separators
            separators = [',', ';', '', '', '*', 'and']
            ingredients = []
            
            for separator in separators:
                if separator in ingredients_text:
                    parts = ingredients_text.split(separator)
                    break
            else:
                # If no separators found, try to split by common patterns
                parts = re.split(r'\s+(?=[A-Z])', ingredients_text)

            for part in parts:
                ingredient = part.strip()
                if ingredient and len(ingredient) > 2:
                    # Clean up ingredient
                    ingredient = re.sub(r'^\d+\.?\s*', '', ingredient)  # Remove numbers
                    ingredient = re.sub(r'^\s*[-]\s*', '', ingredient)  # Remove bullet points
                    ingredient = ingredient.strip()
                    
                    # Skip if it's just a number, percentage, or very short
                    if (ingredient and len(ingredient) > 2 and 
                        not re.match(r'^\d+\.?\d*%?$', ingredient) and
                        not ingredient.lower() in ['and', 'or', 'the', 'a', 'an']):
                        ingredients.append(ingredient)

            # Remove duplicates while preserving order
            seen = set()
            unique_ingredients = []
            for ingredient in ingredients:
                if ingredient.lower() not in seen:
                    seen.add(ingredient.lower())
                    unique_ingredients.append(ingredient)

            ingredients_data["ingredients"] = unique_ingredients

        return ingredients_data

    def extract_table_data(self, blocks):
        """
        Extract structured table data from Textract blocks.
        """
        try:
            table_data = ""
            tables = []
            current_table = []
            
            for block in blocks:
                if block['BlockType'] == 'TABLE':
                    # Process table structure
                    table_text = self.process_table_block(block, blocks)
                    if table_text:
                        table_data += f"\nTABLE:\n{table_text}\n"
            
            return table_data
        except Exception as e:
            logging.error(f"Table extraction error: {e}")
            return ""

    def process_table_block(self, table_block, all_blocks):
        """
        Process individual table block to extract structured data.
        """
        try:
            table_text = ""
            table_id = table_block['Id']
            
            # Find cells in this table
            cells = [block for block in all_blocks if block.get('Relationships') and 
                    any(rel['Type'] == 'CHILD' and table_id in rel['Ids'] for rel in block['Relationships'])]
            
            # Sort cells by row and column
            cells.sort(key=lambda x: (x.get('RowIndex', 0), x.get('ColumnIndex', 0)))
            
            current_row = 0
            for cell in cells:
                if cell.get('RowIndex', 0) != current_row:
                    table_text += "\n"
                    current_row = cell.get('RowIndex', 0)
                
                # Extract text from cell
                cell_text = ""
                if 'Relationships' in cell:
                    for rel in cell['Relationships']:
                        if rel['Type'] == 'CHILD':
                            for child_id in rel['Ids']:
                                child_block = next((b for b in all_blocks if b['Id'] == child_id), None)
                                if child_block and 'Text' in child_block:
                                    cell_text += child_block['Text'] + " "
                
                table_text += cell_text.strip() + "\t"
            
            return table_text
        except Exception as e:
            logging.error(f"Table block processing error: {e}")
            return ""

    def extract_nutrition_data_structured(self, text):
        """
        Extract nutrition data in a structured format using dynamic patterns.
        """
        nutrition_data = {
            "product_name": "",
            "serving_size": "",
            "servings_per_container": "",
            "calories": {"value": 0, "unit": "kcal", "daily_value": 0},
            "total_fat": {"value": 0, "unit": "g", "daily_value": 0},
            "saturated_fat": {"value": 0, "unit": "g", "daily_value": 0},
            "trans_fat": {"value": 0, "unit": "g", "daily_value": 0},
            "cholesterol": {"value": 0, "unit": "mg", "daily_value": 0},
            "sodium": {"value": 0, "unit": "mg", "daily_value": 0},
            "total_carbohydrates": {"value": 0, "unit": "g", "daily_value": 0},
            "dietary_fiber": {"value": 0, "unit": "g", "daily_value": 0},
            "total_sugars": {"value": 0, "unit": "g", "daily_value": 0},
            "added_sugars": {"value": 0, "unit": "g", "daily_value": 0},
            "protein": {"value": 0, "unit": "g", "daily_value": 0},
            "vitamin_d": {"value": 0, "unit": "mcg", "daily_value": 0},
            "calcium": {"value": 0, "unit": "mg", "daily_value": 0},
            "iron": {"value": 0, "unit": "mg", "daily_value": 0},
            "potassium": {"value": 0, "unit": "mg", "daily_value": 0},
            # Dynamic nutrients will be added here
            "other_nutrients": {}
        }

        # Extract product name (usually at the top)
        lines = text.split('\n')
        for i, line in enumerate(lines[:5]):  # Check first 5 lines
            if len(line.strip()) > 3 and not any(nutrient in line.lower() for nutrient in ['calories', 'fat', 'protein', 'ingredients']):
                nutrition_data["product_name"] = line.strip()
                break

        # First, try to extract using predefined patterns for common nutrients
        nutrition_data = self.extract_common_nutrients(text, nutrition_data)
        
        # Then, extract any additional nutrients dynamically
        nutrition_data = self.extract_dynamic_nutrients(text, nutrition_data)

        return nutrition_data

    def extract_common_nutrients(self, text, nutrition_data):
        """
        Extract common nutrients using predefined patterns.
        """
        # Enhanced nutrition extraction patterns for table format
        patterns = {
            "serving_size": [
                r'serving\s+size[:\s]*([^\n]+)',
                r'serving\s+information[:\s]*([^\n]+)'
            ],
            "servings_per_container": [
                r'servings\s+per\s+container[:\s]*(\d+(?:\.\d+)?)',
                r'servings[:\s]*(\d+(?:\.\d+)?)',
                r'pack\s+contains\s+(\d+(?:\.\d+)?)\s+servings'
            ],
            "calories": [
                r'calories[:\s]*(\d+(?:\.\d+)?)\s*(kcal|cal)',
                r'energy[:\s]*(\d+(?:\.\d+)?)\s*(kcal|cal)',
                r'(\d+(?:\.\d+)?)\s*(kcal|cal)\s*calories',
                r'energy\s*\(kcal\)\s*\n\s*(\d+(?:\.\d+)?)',
                r'calories\s*\n\s*(\d+(?:\.\d+)?)'
            ],
            "total_fat": [
                r'total\s+fat[:\s]*(\d+(?:\.\d+)?)\s*g',
                r'fat[:\s]*(\d+(?:\.\d+)?)\s*g',
                r'(\d+(?:\.\d+)?)\s*g\s*total\s+fat',
                r'total\s+fat\s*\(g\)\s*\n\s*(\d+(?:\.\d+)?)',
                r'fat\s*\(g\)\s*\n\s*(\d+(?:\.\d+)?)'
            ],
            "saturated_fat": [
                r'saturated\s+fat[:\s]*(\d+(?:\.\d+)?)\s*g',
                r'sat\s+fat[:\s]*(\d+(?:\.\d+)?)\s*g',
                r'saturated\s+fat\s*\(g\)\s*\n\s*(\d+(?:\.\d+)?)',
                r'sat\s+fat\s*\(g\)\s*\n\s*(\d+(?:\.\d+)?)'
            ],
            "trans_fat": [
                r'trans\s+fat[:\s]*(\d+(?:\.\d+)?)\s*g',
                r'trans[:\s]*(\d+(?:\.\d+)?)\s*g',
                r'trans\s+fat\s*\(g\)\s*\n\s*(\d+(?:\.\d+)?)'
            ],
            "cholesterol": [
                r'cholesterol[:\s]*(\d+(?:\.\d+)?)\s*mg',
                r'(\d+(?:\.\d+)?)\s*mg\s*cholesterol',
                r'cholesterol\s*\(mg\)\s*\n\s*(\d+(?:\.\d+)?)'
            ],
            "sodium": [
                r'sodium[:\s]*(\d+(?:\.\d+)?)\s*mg',
                r'salt[:\s]*(\d+(?:\.\d+)?)\s*mg',
                r'sodium\s*\(mg\)\s*\n\s*(\d+(?:\.\d+)?)'
            ],
            "total_carbohydrates": [
                r'total\s+carbohydrates[:\s]*(\d+(?:\.\d+)?)\s*g',
                r'carbohydrates[:\s]*(\d+(?:\.\d+)?)\s*g',
                r'carbs[:\s]*(\d+(?:\.\d+)?)\s*g',
                r'carbohydrate\s*\(g\)\s*\n\s*(\d+(?:\.\d+)?)',
                r'carbohydrates\s*\(g\)\s*\n\s*(\d+(?:\.\d+)?)'
            ],
            "dietary_fiber": [
                r'dietary\s+fiber[:\s]*(\d+(?:\.\d+)?)\s*g',
                r'fiber[:\s]*(\d+(?:\.\d+)?)\s*g',
                r'dietary\s+fibre\s*\(g\)\s*\n\s*(\d+(?:\.\d+)?)',
                r'fiber\s*\(g\)\s*\n\s*(\d+(?:\.\d+)?)'
            ],
            "total_sugars": [
                r'total\s+sugars[:\s]*(\d+(?:\.\d+)?)\s*g',
                r'sugars[:\s]*(\d+(?:\.\d+)?)\s*g',
                r'total\s+sugars\s*\(g\)\s*\n\s*(\d+(?:\.\d+)?)',
                r'sugars\s*\(g\)\s*\n\s*(\d+(?:\.\d+)?)'
            ],
            "added_sugars": [
                r'added\s+sugars[:\s]*(\d+(?:\.\d+)?)\s*g',
                r'(\d+(?:\.\d+)?)\s*g\s*added\s+sugars',
                r'added\s+sugars\s*\(g\)\s*\n\s*(\d+(?:\.\d+)?)'
            ],
            "protein": [
                r'protein[:\s]*(\d+(?:\.\d+)?)\s*g',
                r'(\d+(?:\.\d+)?)\s*g\s*protein',
                r'protein\s*\(g\)\s*\n\s*(\d+(?:\.\d+)?)'
            ]
        }

        for nutrient, pattern_list in patterns.items():
            for pattern in pattern_list:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    if nutrient in ["serving_size", "servings_per_container"]:
                        nutrition_data[nutrient] = match.group(1).strip()
                    else:
                        try:
                            value = float(match.group(1))
                            nutrition_data[nutrient]["value"] = value
                            if len(match.groups()) > 1:
                                nutrition_data[nutrient]["unit"] = match.group(2)
                        except ValueError:
                            continue
                    break

        return nutrition_data

    def extract_dynamic_nutrients(self, text, nutrition_data):
        """
        Dynamically extract any nutrition data that doesn't match predefined patterns.
        """
        # Common nutrition keywords to look for
        nutrition_keywords = [
            'vitamin', 'mineral', 'calcium', 'iron', 'zinc', 'magnesium', 'phosphorus',
            'potassium', 'sodium', 'chloride', 'bicarbonate', 'sulfate', 'copper',
            'manganese', 'selenium', 'chromium', 'molybdenum', 'iodine', 'fluoride',
            'omega', 'fiber', 'fibre', 'sugar', 'starch', 'alcohol', 'water',
            'ash', 'moisture', 'dry matter', 'crude protein', 'crude fat',
            'crude fiber', 'nitrogen', 'phosphorus', 'calcium', 'magnesium',
            'sodium', 'potassium', 'chloride', 'sulfur', 'iron', 'zinc',
            'copper', 'manganese', 'selenium', 'cobalt', 'iodine', 'vitamin a',
            'vitamin b', 'vitamin c', 'vitamin d', 'vitamin e', 'vitamin k',
            'thiamin', 'riboflavin', 'niacin', 'pantothenic acid', 'pyridoxine',
            'biotin', 'folic acid', 'cobalamin', 'ascorbic acid', 'retinol',
            'carotene', 'tocopherol', 'phylloquinone', 'menaquinone'
        ]

        # Pattern to find nutrient name followed by value and unit
        # This will catch any nutrient format like "Vitamin C 15 mg" or "Zinc 2.5 mg"
        dynamic_patterns = [
            # Pattern 1: "Nutrient Name (unit)\nValue"
            r'([a-zA-Z\s]+)\s*\(([a-zA-Z%]+)\)\s*\n\s*(\d+(?:\.\d+)?)',
            # Pattern 2: "Nutrient Name: Value unit"
            r'([a-zA-Z\s]+)[:\s]+(\d+(?:\.\d+)?)\s*([a-zA-Z%]+)',
            # Pattern 3: "Nutrient Name Value unit"
            r'([a-zA-Z\s]+)\s+(\d+(?:\.\d+)?)\s*([a-zA-Z%]+)',
            # Pattern 4: "Value unit Nutrient Name"
            r'(\d+(?:\.\d+)?)\s*([a-zA-Z%]+)\s+([a-zA-Z\s]+)',
        ]

        for pattern in dynamic_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                if len(match.groups()) == 3:
                    if pattern == r'([a-zA-Z\s]+)\s*\(([a-zA-Z%]+)\)\s*\n\s*(\d+(?:\.\d+)?)':
                        # Pattern 1: "Nutrient Name (unit)\nValue"
                        nutrient_name = match.group(1).strip()
                        unit = match.group(2).strip()
                        value = match.group(3)
                    elif pattern == r'([a-zA-Z\s]+)[:\s]+(\d+(?:\.\d+)?)\s*([a-zA-Z%]+)':
                        # Pattern 2: "Nutrient Name: Value unit"
                        nutrient_name = match.group(1).strip()
                        value = match.group(2)
                        unit = match.group(3).strip()
                    elif pattern == r'([a-zA-Z\s]+)\s+(\d+(?:\.\d+)?)\s*([a-zA-Z%]+)':
                        # Pattern 3: "Nutrient Name Value unit"
                        nutrient_name = match.group(1).strip()
                        value = match.group(2)
                        unit = match.group(3).strip()
                    else:
                        # Pattern 4: "Value unit Nutrient Name"
                        value = match.group(1)
                        unit = match.group(2).strip()
                        nutrient_name = match.group(3).strip()

                    # Check if this looks like a nutrition value
                    if any(keyword in nutrient_name.lower() for keyword in nutrition_keywords):
                        try:
                            numeric_value = float(value)
                            # Clean up nutrient name
                            clean_name = re.sub(r'\s+', ' ', nutrient_name).strip().lower()
                            
                            # Check if it's already in our predefined nutrients
                            if clean_name not in nutrition_data:
                                # Add to other_nutrients
                                nutrition_data["other_nutrients"][clean_name] = {
                                    "value": numeric_value,
                                    "unit": unit,
                                    "daily_value": 0
                                }
                        except ValueError:
                            continue

        return nutrition_data

    def extract_ingredients_structured(self, text):
        """
        Extract ingredients in a structured format.
        """
        ingredients_data = {
            "ingredients": [],
            "allergens": [],
            "contains": [],
            "may_contain": []
        }

        # Find ingredients section - multiple patterns for different formats
        ingredients_section = ""
        lines = text.split('\n')
        
        # Pattern 1: Look for "Ingredients:" or "Ingredients" followed by ingredients
        for i, line in enumerate(lines):
            if 'ingredients' in line.lower():
                # Check if this line contains ingredients after colon
                if ':' in line:
                    ingredients_text = line.split(':', 1)[1].strip()
                    if ingredients_text:
                        ingredients_section = ingredients_text
                        # Continue reading next lines for more ingredients
                        for j in range(i + 1, min(i + 30, len(lines))):
                            next_line = lines[j].strip()
                            if next_line and not any(keyword in next_line.lower() for keyword in 
                                                   ['nutrition', 'calories', 'serving', 'daily', 'allergen', 'energy', 'fat', 'protein']):
                                ingredients_section += " " + next_line
                            else:
                                break
                        break
                else:
                    # If line just says "Ingredients", read next lines
                    ingredients_text = ""
                    for j in range(i + 1, min(i + 30, len(lines))):
                        next_line = lines[j].strip()
                        if next_line and not any(keyword in next_line.lower() for keyword in 
                                               ['nutrition', 'calories', 'serving', 'daily', 'allergen', 'energy', 'fat', 'protein']):
                            ingredients_text += " " + next_line
                        else:
                            break
                    if ingredients_text.strip():
                        ingredients_section = ingredients_text.strip()
                        break

        # Pattern 2: Look for ingredients in table format (common with Textract)
        if not ingredients_section:
            for i, line in enumerate(lines):
                if 'ingredients' in line.lower():
                    # Look for ingredients in subsequent lines in table format
                    ingredients_text = ""
                    for j in range(i + 1, min(i + 50, len(lines))):
                        next_line = lines[j].strip()
                        # Skip empty lines and nutrition-related lines
                        if next_line and not any(keyword in next_line.lower() for keyword in 
                                               ['nutrition', 'calories', 'serving', 'daily', 'allergen', 'energy', 'fat', 'protein', 'carbohydrate', 'sodium']):
                            # Check if this looks like an ingredient (not a number or percentage)
                            if not re.match(r'^\d+\.?\d*%?$', next_line) and len(next_line) > 2:
                                ingredients_text += " " + next_line
                        elif next_line and any(keyword in next_line.lower() for keyword in ['allergen', 'contains', 'may contain']):
                            # Stop at allergen information
                            break
                    if ingredients_text.strip():
                        ingredients_section = ingredients_text.strip()
                        break

        # Pattern 3: Look for ingredients after nutrition facts (common format)
        if not ingredients_section:
            nutrition_end = -1
            for i, line in enumerate(lines):
                if any(keyword in line.lower() for keyword in ['potassium', 'vitamin', 'minerals', '***']):
                    nutrition_end = i
                    break
            
            if nutrition_end > 0:
                # Look for ingredients after nutrition facts
                for i in range(nutrition_end + 1, len(lines)):
                    line = lines[i].strip()
                    if 'ingredients' in line.lower():
                        ingredients_text = ""
                        for j in range(i + 1, min(i + 30, len(lines))):
                            next_line = lines[j].strip()
                            if next_line and not any(keyword in next_line.lower() for keyword in 
                                                   ['nutrition', 'calories', 'serving', 'daily', 'allergen', 'energy', 'fat', 'protein']):
                                ingredients_text += " " + next_line
                            else:
                                break
                        if ingredients_text.strip():
                            ingredients_section = ingredients_text.strip()
                            break

        if ingredients_section:
            # Parse ingredients
            ingredients = self.parse_ingredients_list(ingredients_section)
            ingredients_data["ingredients"] = ingredients

            # Extract allergens
            allergens = self.extract_allergens(text)
            ingredients_data["allergens"] = allergens

        return ingredients_data

    def parse_ingredients_list(self, ingredients_text):
        """
        Parse ingredients text into a structured list.
        """
        ingredients = []
        
        # Common ingredient separators
        separators = [',', ';', '', '', '*', '\n','and']
        
        # Split by common separators
        for separator in separators:
            if separator in ingredients_text:
                parts = ingredients_text.split(separator)
                break
        else:
            # If no separators found, try to split by common patterns
            parts = re.split(r'\s+(?=[A-Z])', ingredients_text)

        for part in parts:
            ingredient = part.strip()
            if ingredient and len(ingredient) > 2:
                # Clean up ingredient
                ingredient = re.sub(r'^\d+\.?\s*', '', ingredient)  # Remove numbers
                ingredient = re.sub(r'[()]', '', ingredient)  # Remove parentheses
                ingredient = re.sub(r'^\s*[-]\s*', '', ingredient)  # Remove bullet points
                ingredient = ingredient.strip()
                
                # Skip if it's just a number, percentage, or very short
                if (ingredient and len(ingredient) > 2 and 
                    not re.match(r'^\d+\.?\d*%?$', ingredient) and
                    not ingredient.lower() in ['and', 'or', 'the', 'a', 'an']):
                    ingredients.append(ingredient)

        # Remove duplicates while preserving order
        seen = set()
        unique_ingredients = []
        for ingredient in ingredients:
            if ingredient.lower() not in seen:
                seen.add(ingredient.lower())
                unique_ingredients.append(ingredient)

        return unique_ingredients

    def extract_allergens(self, text):
        """
        Extract allergen information from text.
        """
        allergens = []
        allergen_keywords = [
            'contains', 'may contain', 'allergens', 'allergen information',
            'wheat', 'milk', 'eggs', 'fish', 'shellfish', 'tree nuts', 'peanuts', 'soybeans',
            'gluten', 'lactose', 'nuts', 'dairy', 'soy'
        ]
        
        lines = text.split('\n')
        for i, line in enumerate(lines):
            line_lower = line.lower()
            if any(keyword in line_lower for keyword in allergen_keywords):
                # Get the full allergen information (current line + next few lines)
                allergen_info = line.strip()
                for j in range(i + 1, min(i + 5, len(lines))):
                    next_line = lines[j].strip()
                    if next_line and not any(keyword in next_line.lower() for keyword in 
                                           ['nutrition', 'calories', 'serving', 'daily', 'energy', 'fat', 'protein']):
                        allergen_info += " " + next_line
                    else:
                        break
                allergens.append(allergen_info)
        
        return allergens

    def validate_product_safety(self, user, ingredients_list):
        """
        Validate product safety using existing logic.
        """
        # This will use the existing validation logic from other views
        # For now, return a basic structure
        return {
            "safety_status": "unknown",
            "flagged_ingredients": [],
            "go_ingredients": [],
            "caution_ingredients": []
        }

    def generate_ai_insights(self, nutrition_data, flagged_ingredients):
        """
        Generate AI insights based on nutrition data and flagged ingredients.
        """
        return {
            "ai_health_insight": "AI analysis will be implemented here",
            "expert_advice": "Expert advice will be generated here"
        }

    def save_scan_history(self, **kwargs):
        """
        Save scan history to database.
        """
        from .models import FoodLabelScan
        
        # Create scan record
        scan = FoodLabelScan.objects.create(
            user=kwargs['user'],
            image_url=kwargs['image_url'],
            extracted_text=kwargs['extracted_text'],
            nutrition_data=kwargs['nutrition_data'],
            safety_status=kwargs['safety_status'],
            flagged_ingredients=kwargs['flagged_ingredients']
        )
        
        # NOTE: Scan count increment is handled by the main async save_scan_history method
        # to avoid double counting when both sync and async methods are called
        
        return scan

    def save_image(self, image_content):
        """
        Save image and return URL.
        """
        # Use existing image saving logic
        # This should integrate with your current image storage system
        return "image_url_placeholder"

    def test_aws_connection(self):
        """
        Test AWS Textract connection.
        """
        try:
            if not self.textract_client:
                return False, "AWS Textract client not initialized"
            
            # Try a simple operation to test connection
            # We'll use a minimal test that doesn't require an actual image
            return True, "AWS Textract client initialized successfully"
            
        except Exception as e:
            return False, f"AWS connection failed: {str(e)}"

class NotificationTestView(APIView):
    """Simple view to serve the notification testing page"""
    permission_classes = []  # Allow anyone to access for testing
    
    def get(self, request):
        from django.shortcuts import render
        return render(request, 'test_notifications.html')

class MobileNotificationTestView(APIView):
    """Mobile-optimized notification testing page"""
    permission_classes = []
    
    def get(self, request):
        from django.shortcuts import render
        return render(request, 'mobile_test.html')

class SimpleNotificationTestView(APIView):
    """Simple notification testing page without Firebase"""
    permission_classes = []
    
    def get(self, request):
        from django.shortcuts import render
        return render(request, 'simple_test.html')

class SubscriptionManagementView(APIView):
    """
    Comprehensive subscription management endpoint that handles:
    - Plan switching (upgrade/downgrade)
    - Platform-specific subscription management
    - Confirmation flows for plan changes
    """
    permission_classes = [IsAuthenticated]

    def get(self, request):
        """Get current subscription status and available actions"""
        user = request.user
        
        try:
            subscription = UserSubscription.objects.get(user=user)
        except UserSubscription.DoesNotExist:
            subscription = None
        
        # Get current plan info
        current_plan = self._get_current_plan_info(subscription)
        
        # Get available actions based on current plan and platform
        available_actions = self._get_available_actions(subscription)
        
        # Get platform-specific management links
        management_links = self._get_management_links(subscription)
        
        return Response({
            'current_plan': current_plan,
            'available_actions': available_actions,
            'management_links': management_links,
            'platform': subscription.platform if subscription else 'stripe'
        }, status=status.HTTP_200_OK)

    def post(self, request):
        """Handle plan changes and subscription management actions"""
        user = request.user
        action = request.data.get('action')
        target_plan = request.data.get('target_plan')
        confirm = request.data.get('confirm', False)
        
        if not action:
            return Response({'error': 'Action is required'}, status=status.HTTP_400_BAD_REQUEST)
        
        try:
            subscription = UserSubscription.objects.get(user=user)
        except UserSubscription.DoesNotExist:
            subscription = None
        
        if action == 'switch_plan':
            return self._handle_plan_switch(user, subscription, target_plan, confirm)
        elif action == 'downgrade_to_freemium':
            return self._handle_downgrade(user, subscription, confirm)
        elif action == 'restore_purchases':
            return self._handle_restore_purchases(user, request.data.get('platform'))
        else:
            return Response({'error': 'Invalid action'}, status=status.HTTP_400_BAD_REQUEST)

    def _get_current_plan_info(self, subscription):
        """Get detailed current plan information"""
        if not subscription:
            return {
                'plan_name': 'freemium',
                'plan_id': 'freemium',
                'status': 'active',
                'is_premium': False,
                'platform': 'stripe',
                'renewal_date': None,
                'cancel_date': None,
                'subscription_start_date': None,
                'subscription_end_date': None,
                'plan_type': 'freemium',
                'status_display': 'Freemium',
                'features': [
                    '20 free scans per month',
                    'Basic nutrition analysis',
                    'Ingredient safety check',
                    'Basic health insights'
                ]
            }
        
        # Calculate status display
        if subscription.cancel_at_period_end:
            status_display = f"Premium (cancels on {subscription.cancel_at.strftime('%b %d') if subscription.cancel_at else 'period end'})"
        elif subscription.status == 'past_due':
            status_display = "Past dueretries in X days"
        elif subscription.status == 'active':
            if subscription.renewal_date:
                status_display = f"Premium  Renews on {subscription.renewal_date.strftime('%b %d')}"
            else:
                status_display = "Premium"
        else:
            status_display = subscription.get_status_display()
        
        return {
            'plan_name': subscription.plan_name,
            'plan_id': f"{subscription.plan_name}_{subscription.premium_type}" if subscription.premium_type else subscription.plan_name,
            'status': subscription.status,
            'is_premium': subscription.is_premium,
            'platform': subscription.platform,
            'renewal_date': subscription.renewal_date.isoformat() if subscription.renewal_date else None,
            'cancel_date': subscription.cancel_date.isoformat() if subscription.cancel_date else None,
            'subscription_start_date': subscription.started_at.isoformat() if subscription.started_at else None,
            'subscription_end_date': subscription.current_period_end.isoformat() if subscription.current_period_end else None,
            'plan_type': subscription.premium_type if subscription.premium_type else subscription.plan_name,
            'status_display': status_display,
            'features': self._get_plan_features(subscription.plan_name, subscription.premium_type)
        }

    def _get_available_actions(self, subscription):
        """Get available actions based on current subscription"""
        actions = []
        
        if not subscription or subscription.plan_name == 'freemium':
            # Can upgrade to premium
            actions.extend([
                {
                    'action': 'switch_plan',
                    'target_plan': 'premium_monthly',
                    'label': 'Upgrade to Premium Monthly',
                    'description': 'Unlimited premium scans and premium features',
                    'requires_confirmation': False
                },
                {
                    'action': 'switch_plan',
                    'target_plan': 'premium_yearly',
                    'label': 'Upgrade to Premium Yearly',
                    'description': 'Unlimited premium scans and premium features (save with yearly)',
                    'requires_confirmation': False
                }
            ])
        elif subscription.plan_name == 'premium':
            # Can downgrade to freemium
            actions.append({
                'action': 'downgrade_to_freemium',
                'target_plan': 'freemium',
                'label': 'Switch to Freemium',
                'description': 'Downgrade to free plan',
                'requires_confirmation': True,
                'confirmation_message': self._get_downgrade_confirmation_message(subscription)
            })
            
            # Can switch between monthly/yearly if different
            if subscription.premium_type == 'monthly':
                actions.append({
                    'action': 'switch_plan',
                    'target_plan': 'premium_yearly',
                    'label': 'Switch to Yearly',
                    'description': 'Save with yearly billing',
                    'requires_confirmation': True,
                    'confirmation_message': 'You\'ll be charged for the yearly plan immediately. Your current monthly subscription will be canceled.'
                })
            elif subscription.premium_type == 'yearly':
                actions.append({
                    'action': 'switch_plan',
                    'target_plan': 'premium_monthly',
                    'label': 'Switch to Monthly',
                    'description': 'Switch to monthly billing',
                    'requires_confirmation': True,
                    'confirmation_message': 'You\'ll be charged for the monthly plan immediately. Your current yearly subscription will be canceled.'
                })
        
        # Add restore purchases for mobile platforms
        if subscription and subscription.platform in ['ios', 'android']:
            actions.append({
                'action': 'restore_purchases',
                'label': 'Restore Purchases',
                'description': 'Restore your previous purchases',
                'requires_confirmation': False
            })
        
        return actions

    def _get_management_links(self, subscription):
        """Get platform-specific subscription management links"""
        if not subscription:
            return {}
        
        links = {}
        
        if subscription.platform == 'ios':
            links['manage_subscription'] = {
                'label': 'Manage in Apple Subscriptions',
                'url': 'https://apps.apple.com/account/subscriptions',
                'description': 'Manage your subscription through Apple'
            }
        elif subscription.platform == 'android':
            links['manage_subscription'] = {
                'label': 'Manage in Google Subscriptions',
                'url': 'https://play.google.com/store/account/subscriptions',
                'description': 'Manage your subscription through Google Play'
            }
        elif subscription.platform == 'stripe':
            # Generate Stripe Customer Portal link
            try:
                stripe_customer = StripeCustomer.objects.get(user=subscription.user)
                session = stripe.billing_portal.Session.create(
                    customer=stripe_customer.stripe_customer_id,
                    return_url=f"{getattr(settings, 'FRONTEND_URL', 'https://yourapp.com')}/settings/subscription"
                )
                links['manage_subscription'] = {
                    'label': 'Manage in Billing Portal',
                    'url': session.url,
                    'description': 'Manage your subscription and billing'
                }
            except (StripeCustomer.DoesNotExist, Exception):
                links['manage_subscription'] = {
                    'label': 'Contact Support',
                    'url': '/contact-support',
                    'description': 'Contact support for subscription management'
                }
        
        return links

    def _get_downgrade_confirmation_message(self, subscription):
        """Get platform-specific downgrade confirmation message"""
        if subscription.platform in ['ios', 'android']:
            return "Downgrades are managed by your app store. You'll keep Premium until the end of the current billing period. We'll take you to manage your subscription now."
        else:
            return "You'll keep Premium until the end of the current billing period. After that, your account will revert to Freemium features."

    def _get_plan_features(self, plan_name, premium_type=None):
        """Get features for a specific plan"""
        if plan_name == 'freemium':
            return [
                '20 free scans per month',
                'First 6 scans with full AI insights',
                'Remaining 14 scans with basic features',
                'Basic nutrition analysis',
                'Ingredient safety check',
                'Basic health insights'
            ]
        elif plan_name == 'premium':
            return [
                'Unlimited premium scans',
                'Advanced AI insights',
                'Priority support',
                'Detailed health analysis',
                'Ingredient safety alerts',
                'Personalized recommendations'
            ]
        return []

    def _handle_plan_switch(self, user, subscription, target_plan, confirm):
        """Handle switching between plans"""
        if not target_plan:
            return Response({'error': 'Target plan is required'}, status=status.HTTP_400_BAD_REQUEST)
        
        # Parse target plan
        if target_plan == 'premium_monthly':
            plan_name = 'premium'
            premium_type = 'monthly'
        elif target_plan == 'premium_yearly':
            plan_name = 'premium'
            premium_type = 'yearly'
        elif target_plan == 'freemium':
            plan_name = 'freemium'
            premium_type = None
        else:
            return Response({'error': 'Invalid target plan'}, status=status.HTTP_400_BAD_REQUEST)
        
        # Handle downgrade to freemium
        if plan_name == 'freemium' and subscription and subscription.plan_name == 'premium':
            return self._handle_downgrade(user, subscription, confirm)
        
        # Handle upgrade to premium
        if plan_name == 'premium':
            return self._handle_upgrade(user, subscription, premium_type, confirm)
        
        return Response({'error': 'Invalid plan switch'}, status=status.HTTP_400_BAD_REQUEST)

    def _handle_downgrade(self, user, subscription, confirm):
        """Handle downgrade to freemium"""
        if not subscription or subscription.plan_name != 'premium':
            return Response({'error': 'No active premium subscription found'}, status=status.HTTP_400_BAD_REQUEST)
        
        if not confirm:
            return Response({
                'error': 'Confirmation required',
                'requires_confirmation': True,
                'confirmation_message': self._get_downgrade_confirmation_message(subscription)
            }, status=status.HTTP_400_BAD_REQUEST)
        
        # Handle platform-specific downgrade
        if subscription.platform in ['ios', 'android']:
            # For app store subscriptions, we can't cancel directly
            # Return deep link to store management
            management_links = self._get_management_links(subscription)
            return Response({
                'message': 'Redirecting to subscription management',
                'action': 'redirect_to_store',
                'url': management_links.get('manage_subscription', {}).get('url'),
                'platform': subscription.platform
            }, status=status.HTTP_200_OK)
        
        elif subscription.platform == 'stripe':
            # For Stripe subscriptions, we can cancel directly
            try:
                if subscription.stripe_subscription_id:
                    # Cancel at period end instead of immediately
                    stripe.Subscription.modify(
                        subscription.stripe_subscription_id,
                        cancel_at_period_end=True
                    )
                
                # Update local subscription
                subscription.cancel_at_period_end = True
                subscription.cancel_at = subscription.current_period_end
                subscription.save()
                
                # Send notification
                from .tasks import send_subscription_notification_task_celery, safe_execute_task
                safe_execute_task(
                    send_subscription_notification_task_celery,
                    user.id, 
                    'subscription_downgrade_confirmed',
                    plan_type='Freemium'
                )
                
                return Response({
                    'message': 'Subscription will be canceled at the end of the current period',
                    'cancel_date': subscription.cancel_at.isoformat() if subscription.cancel_at else None
                }, status=status.HTTP_200_OK)
                
            except Exception as e:
                return Response({'error': f'Failed to cancel subscription: {str(e)}'}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
        
        return Response({'error': 'Unsupported platform'}, status=status.HTTP_400_BAD_REQUEST)

    def _handle_upgrade(self, user, subscription, premium_type, confirm):
        """Handle upgrade to premium"""
        # This would integrate with the existing SubscribeUserView logic
        # For now, return a response indicating the upgrade flow
        return Response({
            'message': 'Upgrade flow initiated',
            'action': 'initiate_upgrade',
            'premium_type': premium_type,
            'platform': subscription.platform if subscription else 'stripe'
        }, status=status.HTTP_200_OK)

    def _handle_restore_purchases(self, user, platform):
        """Handle restore purchases for mobile platforms"""
        if platform not in ['ios', 'android']:
            return Response({'error': 'Restore purchases only available on mobile platforms'}, status=status.HTTP_400_BAD_REQUEST)
        
        # This would integrate with StoreKit/Google Play Billing
        # For now, return a response indicating the restore flow
        return Response({
            'message': 'Restore purchases initiated',
            'action': 'restore_purchases',
            'platform': platform
        }, status=status.HTTP_200_OK)
    
class FoodLabelNutritionView(APIView):
    permission_classes = [IsAuthenticated]
    
    # In-memory caches (class-level)
    openai_cache = {}
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        # Initialize AWS Textract client
        try:
            aws_access_key = settings.AWS_ACCESS_KEY_ID
            aws_secret_key = settings.AWS_SECRET_ACCESS_KEY
            aws_region = settings.AWS_S3_REGION_NAME or 'us-east-1'
            
            if not aws_access_key or not aws_secret_key:
                logging.error("AWS credentials not found in settings")
                self.textract_client = None
                return
            
            self.textract_client = boto3.client(
                'textract',
                aws_access_key_id=aws_access_key,
                aws_secret_access_key=aws_secret_key,
                region_name=aws_region
            )
            print("AWS Textract client initialized successfully for FoodLabelNutritionView")
        except Exception as e:
            logging.error(f"Failed to initialize AWS Textract client: {e}")
            self.textract_client = None

    def post(self, request):
        # can_scan, scan_count = can_user_scan(request.user)
        # if not can_scan:
        #     return Response(
        #         {
        #             "error": "Scan limit reached. Please subscribe to AI IngredientIQ for unlimited scans.",
        #             "scans_used": scan_count,
        #             "max_scans": 6
        #         },
        #         status=status.HTTP_402_PAYMENT_REQUIRED
        #     )
        import time
        import logging
        from concurrent.futures import ThreadPoolExecutor
        try:
            import torch
            device = "cuda" if torch.cuda.is_available() else "cpu"
            print(f"FoodLabelNutritionView is running on: {device.upper()}")
        except ImportError:
            print("torch not installed; cannot determine GPU/CPU.")

        start_time = time.time()

        # Deserialize and validate
        serializer = AllergenDietaryCheckSerializer(data=request.data)
        if not serializer.is_valid():
            return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

        image_file = serializer.validated_data['image']
        image_content = image_file.read()

        # Enhanced scan quality validation
        quality_check = self.validate_scan_quality(image_content)
        if not quality_check.get('quality_passed', True):
            return Response({
                'error': 'Poor scan quality detected',
                'recommendations': quality_check.get('recommendations', ['Please ensure good lighting and focus'])
            }, status=status.HTTP_400_BAD_REQUEST)

        # Check if we're updating an existing scan
        update_scan_id = request.data.get('update_scan_id')
        
        # LIGHTNING FAST PARALLEL PROCESSING
        with ThreadPoolExecutor(max_workers=6) as executor:
            # Submit all tasks simultaneously
            image_future = executor.submit(self.save_image, image_content)
            ocr_future = executor.submit(self.run_ocr, image_content)
            ingredients_future = executor.submit(self.extract_ingredients_with_textract_query, image_content)
            nutrition_future = executor.submit(self.extract_nutrition_with_textract_query, image_content)
            
            # Get image URL first (critical)
            image_url, image_path = image_future.result(timeout=3)
            if not image_url:
                return Response({'error': 'Image upload failed'}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
            
            # Get OCR results with timeouts
            try:
                extracted_text = ocr_future.result(timeout=8)  # 8 second timeout
            except:
                extracted_text = ""
                
            try:
                query_ingredients = ingredients_future.result(timeout=8)
            except:
                query_ingredients = []
                
            try:
                query_nutrition = nutrition_future.result(timeout=8)
            except:
                query_nutrition = {}
        
        # Process results quickly
        if query_nutrition:
            nutrition_data = self.process_query_nutrition_data(query_nutrition)
        else:
            nutrition_data = self.extract_nutrition_info_fallback(extracted_text)
        
        if query_ingredients:
            actual_ingredients = self.process_query_ingredients(query_ingredients)
        else:
            actual_ingredients = self.extract_ingredients_from_text_fallback(extracted_text)

        # Debug logging
        print(f"Extracted text: {extracted_text}")
        print(f"Nutrition data extracted: {nutrition_data}")
        
        # More lenient check - allow partial nutrition data
        if not nutrition_data:
            # Try a simpler extraction method as fallback
            nutrition_data = self.extract_nutrition_info_simple(extracted_text)
            print(f"Fallback nutrition data: {nutrition_data}")
            
        if not nutrition_data:
            return Response(
                {"error": "No nutrition data found, Please capture clear photo of nutrition label of food packet. Scan not saved."},
                status=status.HTTP_400_BAD_REQUEST
            )

        # Enhanced performance optimization
        optimized_result = self.optimize_analysis_performance(
            user=request.user,
            image_content=image_content,
            nutrition_data=nutrition_data,
            ingredients_list=actual_ingredients
        )
        if optimized_result:
            print("Using optimized analysis pipeline for faster processing")

        # PARALLEL SAFETY VALIDATION AND AI INSIGHTS
        safety_start = time.time()
        with ThreadPoolExecutor(max_workers=2) as executor:
            # Run safety validation and enhanced AI insights in parallel
            safety_future = executor.submit(lambda: asyncio.run(self.validate_product_safety(request.user, actual_ingredients)))
            ai_future = executor.submit(self.get_ai_health_insight_and_expert_advice_enhanced, request.user, nutrition_data, actual_ingredients)
            
            # Get safety results with timeout
            try:
                safety_result = safety_future.result(timeout=5)  # 5 second timeout
                if len(safety_result) == 5:
                    safety_status, go_ingredients, caution_ingredients, no_go_ingredients, efsa_data_cache = safety_result
                else:
                    safety_status, go_ingredients, caution_ingredients, no_go_ingredients = safety_result
                    efsa_data_cache = {}
            except:
                safety_status, go_ingredients, caution_ingredients, no_go_ingredients = "unknown", [], [], []
                efsa_data_cache = {}
            
            # Get AI results with timeout - using enhanced analysis
            try:
                ai_results = ai_future.result(timeout=5)  # Increased timeout for enhanced analysis
                print(f" Enhanced AI Results received: {ai_results}")
                
                # Ensure we have the individual sections for backward compatibility
                if not ai_results.get("bluf_insight"):
                    # Extract from structured format if individual sections are missing
                    ai_health_insight = ai_results.get("ai_health_insight", {})
                    expert_conclusion = ai_results.get("expert_ai_conclusion", {})
                    
                    ai_results.update({
                        "bluf_insight": ai_health_insight.get("bluf_insight", ""),
                        "main_insight": ai_health_insight.get("main_insight", ""),
                        "deeper_reference": ai_health_insight.get("deeper_reference", ""),
                        "prognosis": expert_conclusion.get("prognosis", ""),
                        "patient_counseling": expert_conclusion.get("patient_counseling", ""),
                        "total_words": expert_conclusion.get("total_words", 0),
                        "risk_level": expert_conclusion.get("risk_level", "low")
                    })
                    
            except Exception as e:
                print(f" Enhanced AI analysis timeout/error: {e}")
                # Create enhanced dynamic fallback based on user profile and nutrition data
                user_conditions = request.user.Health_conditions or ""
                user_allergies = request.user.Allergies or ""
                
                # Extract sugar content for dynamic analysis
                sugar_content = 0
                if nutrition_data and 'Sugars' in nutrition_data:
                    try:
                        sugar_value = nutrition_data['Sugars'].replace('g', '').strip()
                        sugar_content = float(sugar_value)
                    except:
                        sugar_content = 0
                
                # Enhanced condition-specific flags with ingredient-to-condition mapping
                condition_flags = []
                if "diabetes" in user_conditions.lower() and sugar_content > 5:
                    condition_flags.append({
                        "ingredient": "SUGAR",
                        "condition": "Diabetes Management",
                        "mapping": f"SUGAR  High Blood Glucose Risk",
                        "severity": "High" if sugar_content > 10 else "Moderate",
                        "reason": f"High sugar content ({sugar_content}g) may cause blood glucose spikes",
                        "data_source": "WHO Guidelines",
                        "risk_category": "Digestive Sensitivity",
                        "weighted_score": 75 if sugar_content > 10 else 50,
                        "scoring_transparency": "Diabetes management  High priority scoring"
                    })
                
                # Enhanced weighted scoring
                weighted_scoring = {
                    "scoring_hierarchy": {"CRITICAL": 100, "HIGH": 75, "MODERATE": 50, "LOW": 25},
                    "ingredient_scores": [{
                        "ingredient": "SUGAR",
                        "weighted_score": 75 if sugar_content > 10 else 50,
                        "scoring_reason": "Diabetes management priority",
                        "priority_level": "HIGH" if sugar_content > 10 else "MODERATE"
                    }],
                    "transparency": "Life-threatening allergens override other factors  No-Go, even if other conditions return Caution"
                }
                
                # Enhanced IBS/FODMAP analysis
                ibs_fodmap_analysis = {
                    "applicable": "ibs" in user_conditions.lower() or "fodmap" in user_conditions.lower(),
                    "analysis": [],
                    "severity_sliders": {"High FODMAP": " Avoid", "Moderate FODMAP": " Limit", "Low FODMAP": " Monitor"},
                    "data_sources": ["Monash University", "PubMed IBS-FODMAP Studies", "EFSA Digestive Health"]
                }
                
                # Create proper individual sections with word counts matching barcode API
                bluf_insight = f"Enhanced analysis for {user_conditions} patient: {len(condition_flags)} condition-specific flags identified with ingredient-to-condition mapping. Weighted scoring prioritizes life-threatening allergens over digestive sensitivities for your health profile."
                
                main_insight = f"Weighted scoring transparency shows decision engine prioritization: Critical allergens override autoimmune triggers, which override digestive sensitivities. Your profile indicates {user_conditions} considerations with {len(condition_flags)} flagged ingredients. Scoring transparency ensures user safety through evidence-based prioritization."
                
                deeper_reference = f"Structured 'Why Flagged' analysis with data sources: FDA Allergen Database, EFSA Risk Assessments, PubMed IBS-FODMAP Studies, WHO Guidelines. Risk categories: {', '.join(set([flag.get('risk_category', 'General') for flag in condition_flags]))}. Severity levels: {', '.join(set([flag.get('severity', 'Moderate') for flag in condition_flags]))}. Regulatory citations include FDA 21 CFR, EFSA Regulation EC 1924/2006, and WHO nutritional standards. Clinical references from JAMA Nutrition, Cochrane Reviews, and Monash University FODMAP Database provide evidence-based decision support."
                
                prognosis = f"Long-term health trajectory analysis with weighted scoring transparency: Life-threatening allergens override other factors  No-Go, even if other conditions return Caution. Evidence from WHO consensus studies and EFSA risk assessments for {user_conditions} management. Longitudinal studies show decision engine prioritization significantly influences disease trajectories and metabolic health markers."
                
                patient_counseling = f"Here are comprehensive steps you can take with expandable insights: Review condition-specific flagging with ingredient science, regulatory notes, and clinical trials. This aligns with your preferences and management of {user_conditions}. Safer choices include monitoring weighted scoring transparency and utilizing severity sliders. You have the power to access deeper insights through expandable sections containing FDA, EFSA, PubMed, and WHO regulatory citations."
                
                total_words = len(prognosis.split()) + len(patient_counseling.split())
                risk_level = "high" if sugar_content > 10 else "moderate" if sugar_content > 5 else "low"
                
                ai_results = {
                    "ai_health_insight": {
                        "bluf_insight": bluf_insight,
                        "main_insight": main_insight,
                        "deeper_reference": deeper_reference,
                        "disclaimer": "Informational, not diagnostic. Consult healthcare providers for medical advice.",
                        "condition_specific_flags": condition_flags,
                        "weighted_scoring": weighted_scoring
                    },
                    "expert_ai_conclusion": {
                        "prognosis": prognosis,
                        "patient_counseling": patient_counseling,
                        "total_words": total_words,
                        "risk_level": risk_level,
                        "disclaimer": "Informational, not diagnostic. Consult healthcare providers for medical advice.",
                        "evidence_sources": [
                            "FDA Allergen Database",
                            "EFSA Risk Assessments", 
                            "PubMed IBS-FODMAP Studies",
                            "WHO Nutritional Guidelines",
                            "NIH Clinical Trials",
                            "Monash University FODMAP Database"
                        ],
                        "ibs_fodmap_analysis": ibs_fodmap_analysis,
                        "scoring_transparency": "Life-threatening allergens override other factors  No-Go, even if other conditions return Caution",
                        "ui_recommendations": {
                            "overall_badge": " No-Go" if risk_level == "high" else " Caution" if risk_level == "moderate" else " Safe",
                            "ingredient_level_flags": [{"ingredient": "SUGAR", "flags": [{"icon": "", "type": "Digestive", "severity": "High" if sugar_content > 10 else "Moderate", "description": f"SUGAR  High Blood Glucose Risk"}]}],
                            "expandable_sections": [{"ingredient": "SUGAR", "sections": [{"title": "Diabetes Management Analysis", "content": {"ingredient_science": "Scientific analysis of sugar and diabetes interaction", "regulatory_notes": "WHO Guidelines", "clinical_trials": "Clinical evidence from WHO and PubMed studies", "expert_insights": "Expert recommendations for diabetes management"}, "data_sources": ["WHO Guidelines", "PubMed", "FDA", "EFSA"], "risk_category": "Digestive Sensitivity", "severity_level": "High" if sugar_content > 10 else "Moderate"}]}]
                        }
                    },
                    # Include individual sections for backward compatibility
                    "bluf_insight": bluf_insight,
                    "main_insight": main_insight,
                    "deeper_reference": deeper_reference,
                    "prognosis": prognosis,
                    "patient_counseling": patient_counseling,
                    "total_words": total_words,
                    "risk_level": risk_level
                }
        
        safety_end = time.time()
        logging.info(f"Safety validation completed in {safety_end - safety_start:.2f} seconds.")

        # Prepare ingredients for scan history (convert back to simple format for storage)
        def extract_ingredient_names(ingredient_list):
            return [ing["ingredient"] if isinstance(ing, dict) else ing for ing in ingredient_list]
        
        no_go_names = extract_ingredient_names(no_go_ingredients)
        go_names = extract_ingredient_names(go_ingredients)
        caution_names = extract_ingredient_names(caution_ingredients)
        
        # Build comprehensive data structures first - SAME AS BARCODE
        efsa_data_comprehensive = {
            "source": "European Food Safety Authority (EFSA) OpenFoodTox Database",
            "total_ingredients_checked": len(efsa_data_cache),
            "ingredients_with_efsa_data": len([data for data in efsa_data_cache.values() if data and data.get('found')]),
            "cache": {k: v for k, v in efsa_data_cache.items() if v is not None}
        }
        
        ai_health_insight_comprehensive = ai_results.get("ai_health_insight", "")
        
        expert_ai_conclusion_comprehensive = ai_results.get("expert_ai_conclusion", ai_results.get("expert_advice", {}))
        
        medical_condition_recommendations_comprehensive = {
            "user_health_profile": {
                "allergies": request.user.Allergies,
                "dietary_preferences": request.user.Dietary_preferences,
                "health_conditions": request.user.Health_conditions
            },
            "recommendations": get_medical_condition_food_recommendations(
                request.user.Health_conditions, 
                request.user.Allergies, 
                request.user.Dietary_preferences
            ) if (request.user.Health_conditions or request.user.Allergies or request.user.Dietary_preferences) else {"found": False, "message": "No health profile specified"},
            "source": "SNOMED CT & ICD-10 Clinical Guidelines"
        }
        
        # Create comprehensive ai_results with structured format - SAME AS BARCODE
        comprehensive_ai_results = {
            **ai_results,
            "ai_health_insight": ai_health_insight_comprehensive,
            "expert_advice": ai_results.get("expert_advice", ""),
            "expert_ai_conclusion": expert_ai_conclusion_comprehensive
        }
        
        # Ensure individual sections are always available for backward compatibility
        if not ai_results.get("bluf_insight"):
            # Extract from structured format
            ai_health_insight = ai_results.get("ai_health_insight", {})
            expert_conclusion = ai_results.get("expert_ai_conclusion", {})
            
            ai_results.update({
                "bluf_insight": ai_health_insight.get("bluf_insight", ""),
                "main_insight": ai_health_insight.get("main_insight", ""),
                "deeper_reference": ai_health_insight.get("deeper_reference", ""),
                "prognosis": expert_conclusion.get("prognosis", ""),
                "patient_counseling": expert_conclusion.get("patient_counseling", ""),
                "total_words": expert_conclusion.get("total_words", 0),
                "risk_level": expert_conclusion.get("risk_level", "low")
            })
        
        # Note: save_scan_history will be called after all comprehensive data is built

        total_time = time.time() - start_time
        logging.info(f"FoodLabelNutritionView total time: {total_time:.2f} seconds.")

        # Convert ingredient lists to list of objects with clean names and EFSA data
        # Global deduplication across all categories
        all_ingredients_seen = set()

        def format_ingredient_list_with_global_dedup(ingredient_list, category_name):
            formatted_list = []
            
            for ing in ingredient_list:
                if isinstance(ing, dict):
                    # New format with EFSA data
                    ingredient_name = ing.get("ingredient", "")
                    reasons = ing.get("reasons", [])
                    efsa_data = ing.get("efsa_data", {})
                    
                    # Clean the ingredient name
                    clean_ingredient = ingredient_name.strip()
                    if not clean_ingredient:
                        continue
                    
                    # Check for global duplicates
                    clean_ingredient_lower = clean_ingredient.lower().strip()
                    if clean_ingredient_lower in all_ingredients_seen:
                        continue
                    all_ingredients_seen.add(clean_ingredient_lower)
                    
                    formatted_ing = {
                        "ingredient": clean_ingredient,
                        "reasons": reasons,
                        "efsa_data": efsa_data or {}
                    }
                else:
                    # Old format (string)
                    ingredient_str = str(ing)
                    clean_ingredient = ingredient_str.strip()
                    if not clean_ingredient:
                        continue
                    
                    # Check for global duplicates
                    clean_ingredient_lower = clean_ingredient.lower().strip()
                    if clean_ingredient_lower in all_ingredients_seen:
                        continue
                    all_ingredients_seen.add(clean_ingredient_lower)
                    
                    formatted_ing = {
                        "ingredient": clean_ingredient,
                        "reasons": ["Legacy format"],
                        "efsa_data": {}
                    }
                formatted_list.append(formatted_ing)
            return formatted_list

        # Process in priority order: no_go first, then caution, then go
        no_go_ingredients_obj = format_ingredient_list_with_global_dedup(no_go_ingredients, "no_go")
        caution_ingredients_obj = format_ingredient_list_with_global_dedup(caution_ingredients, "caution")
        go_ingredients_obj = format_ingredient_list_with_global_dedup(go_ingredients, "go")

        main_ingredient = actual_ingredients[0] if actual_ingredients else None
        def safe_summary(fetch_func, ingredient, default_msg):
            try:
                summary = fetch_func(ingredient)
                if not summary or (isinstance(summary, str) and not summary.strip()):
                    return default_msg
                return summary
            except Exception as e:
                print(f"Summary fetch error for {ingredient}: {e}")
                return default_msg

        medlineplus_summary = safe_summary(
            fetch_medlineplus_summary,
            main_ingredient,
            "No MedlinePlus summary available for this ingredient."
        ) if main_ingredient else "No MedlinePlus summary available for this ingredient."

        pubchem_summary = safe_summary(
            fetch_pubchem_toxicology_summary,
            main_ingredient,
            "No PubChem toxicology data found for this ingredient."
        ) if main_ingredient else "No PubChem toxicology data found for this ingredient."
        pubmed_articles = fetch_pubmed_articles(main_ingredient) if main_ingredient else []

        # REMOVED ClinicalTrials.gov integration for speed
        def fetch_clinical_trials(ingredient):
            return []  # Return empty list for speed
            if not ingredient:
                return []
            try:
                url = f"https://clinicaltrials.gov/api/v2/studies?q={ingredient}&limit=3"
                resp = requests.get(url, timeout=5)
                if resp.status_code != 200:
                    print(f"ClinicalTrials.gov API error: {resp.status_code}")
                    return []
                data = resp.json()
                studies = data.get("studies", [])
                trials = []
                for study in studies:
                    nct_id = study.get("protocolSection", {}).get("identificationModule", {}).get("nctId")
                    title = study.get("protocolSection", {}).get("identificationModule", {}).get("officialTitle")
                    status = study.get("protocolSection", {}).get("statusModule", {}).get("overallStatus")
                    summary = study.get("protocolSection", {}).get("descriptionModule", {}).get("briefSummary")
                    url = f"https://clinicaltrials.gov/ct2/show/{nct_id}" if nct_id else None
                    if nct_id and title:
                        trials.append({
                            "title": title,
                            "nct_id": nct_id,
                            "status": status,
                            "summary": summary,
                            "url": url
                        })
                return trials
            except Exception as e:
                print(f"ClinicalTrials.gov fetch error: {e}")
                return []

        clinical_trials = fetch_clinical_trials(main_ingredient)

        # --- FSA Hygiene Rating Integration ---
        # Try to extract business name from OCR text or use default
        business_name = "OCR Product"  # Default fallback
        fsa_data = None
        
        # Look for business names in the extracted text
        business_keywords = ['ltd', 'limited', 'inc', 'corporation', 'company', 'co', 'brand', 'manufacturer']
        lines = extracted_text.split('\n')
        for line in lines:
            line_lower = line.lower().strip()
            if any(keyword in line_lower for keyword in business_keywords):
                business_name = line.strip()
                break
        
        # Fetch FSA hygiene rating data
        try:
            fsa_data = fetch_fsa_hygiene_rating(business_name=business_name)
        except Exception as e:
            print(f"FSA API error: {e}")
            fsa_data = {
                'found': False,
                'error': f'FSA API error: {str(e)}',
                'source': 'UK FSA FHRS API'
            }
        # Save scan history with ALL comprehensive data - MOVED HERE AFTER ALL DATA IS AVAILABLE
        with ThreadPoolExecutor() as executor:
            scan_future = executor.submit(lambda: asyncio.run(self.save_scan_history(
                request.user,
                image_url,
                extracted_text,
                nutrition_data,
                comprehensive_ai_results,  # Use comprehensive ai_results
                safety_status,
                no_go_names,  # flagged_ingredients
                "OCR Product",  # product_name
                image_url,  # product_image_url
                image_url,  # product_image_small_url
                image_url,  # product_image_thumb_url
                actual_ingredients,  # actual_ingredients
                go_names,     # go_ingredients
                caution_names,  # caution_ingredients
                no_go_names,  # no_go_ingredients
                expert_ai_conclusion_comprehensive,  # expert_ai_conclusion
                ai_results.get("structured_health_analysis", {}),  # structured_health_analysis
                efsa_data_comprehensive,  # efsa_data
                fsa_data,  # fsa_hygiene_data
                medical_condition_recommendations_comprehensive  # medical_condition_recommendations
            )))
            scan = scan_future.result()

        # Handle updating existing scan if scan_id is provided
        if update_scan_id:
            try:
                # Get the existing scan to update
                from .models import FoodLabelScan
                existing_scan = FoodLabelScan.objects.get(id=update_scan_id, user=request.user)
                
                # Update the existing scan with new data
                existing_scan.image_url = image_url
                existing_scan.product_image_url = image_url
                existing_scan.extracted_text = extracted_text
                existing_scan.nutrition_data = comprehensive_nutrition_data
                existing_scan.safety_status = safety_status
                existing_scan.flagged_ingredients = no_go_names
                existing_scan.save()
                
                # Use the updated scan instead of creating a new one
                scan = existing_scan
                print(f"Updated existing scan {update_scan_id} with new image URL: {image_url}")
            except FoodLabelScan.DoesNotExist:
                print(f"Failed to update scan {update_scan_id} - scan not found or access denied")
            except Exception as e:
                print(f"Error updating existing scan: {e}")

        # Get current scan count for response AFTER scan is saved
        from .scan_limit import can_user_scan, get_monthly_reset_date
        _, scan_count, remaining_scans = can_user_scan(request.user)
        
        # Handle None values for premium users
        if scan_count is None:
            scan_count = 0
        if remaining_scans is None:
            remaining_scans = "unlimited"

        return Response({
            "scan_id": scan.id,
            "product_name":"OCR Product",
            "image_url": image_url,
            "updated_existing_scan": bool(update_scan_id),
            "extracted_text": extracted_text,
            "nutrition_data": nutrition_data,
            "ingredients": actual_ingredients,
            "safety_status": safety_status,
            "is_favorite": scan.is_favorite,
            "ingredients_analysis": {
                "go": {
                    "ingredients": go_ingredients_obj,
                    "count": len(go_ingredients_obj),
                    "description": "Ingredients that are safe and suitable for your health profile"
                },
                "caution": {
                    "ingredients": caution_ingredients_obj,
                    "count": len(caution_ingredients_obj),
                    "description": "Ingredients that may not be ideal for your health profile - consume at your own risk"
                },
                "no_go": {
                    "ingredients": no_go_ingredients_obj,
                    "count": len(no_go_ingredients_obj),
                    "description": "Ingredients that are harmful or not suitable for your health profile - avoid these"
                },
                "total_flagged": len(caution_ingredients_obj) + len(no_go_ingredients_obj)
            },
            "efsa_data": {
                "source": "European Food Safety Authority (EFSA) OpenFoodTox Database",
                "total_ingredients_checked": len(efsa_data_cache),
                "ingredients_with_efsa_data": len([data for data in efsa_data_cache.values() if data and data.get('found')]),
                "cache": {k: v for k, v in efsa_data_cache.items() if v is not None}
            },
            "fsa_hygiene_data": fsa_data,
            "scan_usage": {
                "scans_used": scan_count,
                "max_scans": 20,
                "remaining_scans": remaining_scans,
                "monthly_reset_date": get_monthly_reset_date()
            },
            "medical_condition_recommendations": {
                "user_health_profile": {
                    "allergies": request.user.Allergies,
                    "dietary_preferences": request.user.Dietary_preferences,
                    "health_conditions": request.user.Health_conditions
                },
                "recommendations": get_medical_condition_food_recommendations(
                    request.user.Health_conditions, 
                    request.user.Allergies, 
                    request.user.Dietary_preferences
                ) if (request.user.Health_conditions or request.user.Allergies or request.user.Dietary_preferences) else {"found": False, "message": "No health profile specified"},
                "source": "SNOMED CT & ICD-10 Clinical Guidelines"
            },
            "ai_health_insight": ai_results.get("ai_health_insight", {}),
            "expert_ai_conclusion": ai_results.get("expert_ai_conclusion", {}),
            "enhanced_ai_analysis": ai_results.get("enhanced_ai_analysis", {}),
            "condition_specific_flagging": ai_results.get("condition_specific_flagging", {}),
            "weighted_scoring": ai_results.get("weighted_scoring", {}),
            "expert_insights": ai_results.get("expert_insights", {}),
            "enhanced_analysis_flow": self._implement_enhanced_analysis_flow(request.user, actual_ingredients, nutrition_data),
            # Include all original AI health insight sections for consistency with barcode
            "ai_health_insight_comprehensive": ai_health_insight_comprehensive,
            "expert_ai_conclusion_comprehensive": expert_ai_conclusion_comprehensive,
            # Include individual sections for backward compatibility
            "bluf_insight": ai_results.get("bluf_insight", ""),
            "main_insight": ai_results.get("main_insight", ""),
            "deeper_reference": ai_results.get("deeper_reference", ""),
            "prognosis": ai_results.get("prognosis", ""),
            "patient_counseling": ai_results.get("patient_counseling", ""),
            "total_words": ai_results.get("total_words", 0),
            "risk_level": ai_results.get("risk_level", "low"),
            # "expert_ai_conclusion": ai_results.get("expert_ai_conclusion", {}),
            # "ocr_gpu": False,  # Azure OCR
            # "medlineplus_summary": medlineplus_summary,
            # "pubchem_summary": pubchem_summary,
            # "pubmed_articles": pubmed_articles,
            # "clinical_trials": clinical_trials,
            # "timing": {
            #     "ocr": ocr_end - ocr_start,
            #     "safety+ai": safety_end - safety_start,
            #     "total": total_time
            # }
        }, status=status.HTTP_200_OK)

    def patch(self, request):
        """
        Handle PATCH requests for updating existing scans.
        This is specifically for updating image URLs after scanning.
        """
        try:
            # Get the scan ID from the request
            scan_id = request.data.get('scan_id') or request.data.get('update_scan_id')
            if not scan_id:
                return Response(
                    {"error": "scan_id or update_scan_id is required for PATCH requests"},
                    status=status.HTTP_400_BAD_REQUEST
                )

            # Validate the image file
            serializer = AllergenDietaryCheckSerializer(data=request.data)
            if not serializer.is_valid():
                return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

            image_file = serializer.validated_data['image']
            image_content = image_file.read()

            # Enhanced scan quality validation
            quality_check = self.validate_scan_quality(image_content)
            if not quality_check.get('quality_passed', True):
                return Response({
                    'error': 'Poor scan quality detected',
                    'recommendations': quality_check.get('recommendations', ['Please ensure good lighting and focus'])
                }, status=status.HTTP_400_BAD_REQUEST)

            # Get the existing scan
            from .models import FoodLabelScan
            try:
                existing_scan = FoodLabelScan.objects.get(id=scan_id, user=request.user)
            except FoodLabelScan.DoesNotExist:
                return Response(
                    {"error": "Scan not found or access denied"},
                    status=status.HTTP_404_NOT_FOUND
                )

            # Process the new image in parallel
            with ThreadPoolExecutor(max_workers=6) as executor:
                image_future = executor.submit(self.save_image, image_content)
                ocr_future = executor.submit(self.run_ocr, image_content)
                ingredients_future = executor.submit(self.extract_ingredients_with_textract_query, image_content)
                nutrition_future = executor.submit(self.extract_nutrition_with_textract_query, image_content)
                
                # Get results
                image_url, image_path = image_future.result(timeout=3)
                if not image_url:
                    return Response({'error': 'Image upload failed'}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
                
                try:
                    extracted_text = ocr_future.result(timeout=8)
                except:
                    extracted_text = ""
                    
                try:
                    query_ingredients = ingredients_future.result(timeout=8)
                except:
                    query_ingredients = []
                    
                try:
                    query_nutrition = nutrition_future.result(timeout=8)
                except:
                    query_nutrition = {}

            # Process results
            if query_nutrition:
                nutrition_data = self.process_query_nutrition_data(query_nutrition)
            else:
                nutrition_data = self.extract_nutrition_info_fallback(extracted_text)
            
            if query_ingredients:
                actual_ingredients = self.process_query_ingredients(query_ingredients)
            else:
                actual_ingredients = self.extract_ingredients_from_text_fallback(extracted_text)

            if not nutrition_data:
                return Response(
                    {"error": "No nutrition data found, Please capture clear photo of nutrition label of food packet."},
                    status=status.HTTP_400_BAD_REQUEST
                )

            # Run safety validation and AI insights in parallel
            with ThreadPoolExecutor(max_workers=2) as executor:
                safety_future = executor.submit(lambda: asyncio.run(self.validate_product_safety(request.user, actual_ingredients)))
                ai_future = executor.submit(self.get_ai_health_insight_and_expert_advice_enhanced, request.user, nutrition_data, actual_ingredients)
                
                try:
                    safety_result = safety_future.result(timeout=5)
                    if len(safety_result) == 5:
                        safety_status, go_ingredients, caution_ingredients, no_go_ingredients, efsa_data_cache = safety_result
                    else:
                        safety_status, go_ingredients, caution_ingredients, no_go_ingredients = safety_result
                        efsa_data_cache = {}
                except:
                    safety_status, go_ingredients, caution_ingredients, no_go_ingredients = "unknown", [], [], []
                    efsa_data_cache = {}
                
                try:
                    ai_results = ai_future.result(timeout=3)
                except Exception as e:
                    print(f"AI analysis error: {e}")
                    ai_results = {
                        "ai_health_insight": "AI analysis temporarily unavailable",
                        "expert_advice": "Please consult healthcare professional for personalized advice"
                    }

            # Prepare comprehensive data
            no_go_names = [ing["ingredient"] if isinstance(ing, dict) else ing for ing in no_go_ingredients]
            go_names = [ing["ingredient"] if isinstance(ing, dict) else ing for ing in go_ingredients]
            caution_names = [ing["ingredient"] if isinstance(ing, dict) else ing for ing in caution_ingredients]

            # Build comprehensive nutrition data
            comprehensive_nutrition_data = {
                **nutrition_data,
                "ai_health_insight": ai_results.get("ai_health_insight", ""),
                "expert_advice": ai_results.get("expert_advice", ""),
                "product_name": existing_scan.product_name or "OCR Product",
                "product_image": {"full": image_url},
                "go_ingredients": go_names,
                "caution_ingredients": caution_names,
                "no_go_ingredients": no_go_names,
                "actual_ingredients": actual_ingredients,
                "expert_ai_conclusion": ai_results.get("expert_ai_conclusion", {}),
                "structured_health_analysis": ai_results.get("structured_health_analysis", {}),
                "efsa_data": efsa_data_cache or {},
                "fsa_hygiene_data": {"found": False, "message": "FSA data not available for updates"},
                "medical_condition_recommendations": {}
            }

            # Update the existing scan
            existing_scan.image_url = image_url
            existing_scan.product_image_url = image_url
            existing_scan.extracted_text = extracted_text
            existing_scan.nutrition_data = comprehensive_nutrition_data
            existing_scan.safety_status = safety_status
            existing_scan.flagged_ingredients = no_go_names
            existing_scan.save()

            return Response({
                "scan_id": existing_scan.id,
                "product_name": existing_scan.product_name,
                "image_url": image_url,
                "updated_existing_scan": True,
                "extracted_text": extracted_text,
                "nutrition_data": nutrition_data,
                "ingredients": actual_ingredients,
                "safety_status": safety_status,
                "is_favorite": existing_scan.is_favorite,
                "ingredients_analysis": {
                    "go": {"ingredients": go_ingredients, "count": len(go_ingredients)},
                    "caution": {"ingredients": caution_ingredients, "count": len(caution_ingredients)},
                    "no_go": {"ingredients": no_go_ingredients, "count": len(no_go_ingredients)},
                    "total_flagged": len(caution_ingredients) + len(no_go_ingredients)
                },
                "ai_health_insight": ai_results.get("ai_health_insight", ""),
                "expert_advice": ai_results.get("expert_advice", "")
            }, status=status.HTTP_200_OK)

        except Exception as e:
            print(f"PATCH request error: {e}")
            return Response(
                {"error": f"Failed to update scan: {str(e)}"},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

    def put(self, request):
        """
        Handle PUT requests for updating only the image of an existing scan.
        This is a lightweight update that doesn't re-run analysis.
        """
        try:
            # Get the scan ID from the request
            scan_id = request.data.get('scan_id')
            if not scan_id:
                return Response(
                    {"error": "scan_id is required for PUT requests"},
                    status=status.HTTP_400_BAD_REQUEST
                )

            # Validate the image file
            serializer = AllergenDietaryCheckSerializer(data=request.data)
            if not serializer.is_valid():
                return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

            image_file = serializer.validated_data['image']
            image_content = image_file.read()

            # Get the existing scan
            from .models import FoodLabelScan
            try:
                existing_scan = FoodLabelScan.objects.get(id=scan_id, user=request.user)
            except FoodLabelScan.DoesNotExist:
                return Response(
                    {"error": "Scan not found or access denied"},
                    status=status.HTTP_404_NOT_FOUND
                )

            # Save the new image
            image_url, image_path = self.save_image(image_content)
            if not image_url:
                return Response({'error': 'Image upload failed'}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

            # Update only the image URLs in the existing scan
            existing_scan.image_url = image_url
            existing_scan.product_image_url = image_url
            
            # Update the image URL in the nutrition_data JSON field as well
            if existing_scan.nutrition_data and isinstance(existing_scan.nutrition_data, dict):
                if 'product_image' in existing_scan.nutrition_data:
                    existing_scan.nutrition_data['product_image']['full'] = image_url
                else:
                    existing_scan.nutrition_data['product_image'] = {'full': image_url}
            
            existing_scan.save()

            return Response({
                "scan_id": existing_scan.id,
                "product_name": existing_scan.product_name,
                "image_url": image_url,
                "updated_existing_scan": True,
                "message": "Image updated successfully. All other data remains unchanged.",
                "extracted_text": existing_scan.extracted_text,
                "nutrition_data": existing_scan.nutrition_data,
                "safety_status": existing_scan.safety_status,
                "is_favorite": existing_scan.is_favorite
            }, status=status.HTTP_200_OK)

        except Exception as e:
            print(f"PUT request error: {e}")
            return Response(
                {"error": f"Failed to update image: {str(e)}"},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

    def get_ai_health_insight_and_expert_advice(self, user, nutrition_data, flagged_ingredients):
        """
        Generate AI health insights with three narrative blocks and expert advice with two sections.
        """
        import time
        import json
        import hashlib
        from concurrent.futures import ThreadPoolExecutor, TimeoutError
        
        # Quick cache check
        key_data = {
            'ingredients': sorted(flagged_ingredients[:3]),  # Only first 3 for speed
            'nutrition': {k: v for k, v in list(nutrition_data.items())[:5]},  # Only first 5
            'diet': user.Dietary_preferences,
            'allergies': user.Allergies,
            'health_conditions': getattr(user, 'Health_conditions', None)
        }
        cache_key = hashlib.sha256(json.dumps(key_data, sort_keys=True).encode()).hexdigest()
        if cache_key in self.openai_cache:
            return self.openai_cache[cache_key]
        
        # Prepare comprehensive user profile data
        nutrition_summary = ', '.join(f"{k}: {v}" for k, v in list(nutrition_data.items())[:5])
        flagged_str = ', '.join(flagged_ingredients[:3])  # Only top 3
        user_profile = f"Diet: {user.Dietary_preferences or 'None'}, Allergies: {user.Allergies or 'None'}, Health Conditions: {getattr(user, 'Health_conditions', None) or 'None'}"
        
        # New structured prompt for three narrative blocks and two expert advice sections
        prompt = f"""
        User Profile: {user_profile}
        Nutrition: {nutrition_summary}
        Flagged Ingredients: {flagged_str}
        
        You are a certified nutrition expert and medical advisor. Provide comprehensive, evidence-based AI health insights with THREE narrative blocks and expert advice with TWO sections. STRICTLY ADHERE TO WORD COUNTS:
        
        AI HEALTH INSIGHTS (3 blocks):
        1. PERSONALIZED_INSIGHT: [EXACTLY 60-80 words] Quick, scannable BLUF summary of primary health risks specific to this user's profile. Be direct and actionable.
        
        2. MAIN_INSIGHT: [EXACTLY 80-100 words] Expand on BLUF with detailed context, specific nutritional concerns, and direct recommendations. Include specific numbers from nutrition data when relevant.
        
        3. DEEPER_REFERENCE: [EXACTLY 150-200 words] Comprehensive supporting rationale with specific regulatory citations, scientific evidence, and detailed explanations. Must include references to WHO, EFSA, FDA guidelines and peer-reviewed research.
        
        AI EXPERT ADVICE (2 sections):
        1. PROGNOSIS: [EXACTLY 130-150 words] Detailed future-oriented risk projection including disease trajectory, potential complications, and long-term health outcomes. Must include specific evidence from WHO/EFSA studies and clinical research.
        
        2. PATIENT_COUNSELING: [EXACTLY 130-150 words] Comprehensive plain-language advice with food-as-medicine framing. MUST include empowerment phrases: "Here are steps you can take", "This aligns with your preferences", "Safer choices include", "You have the power to". Provide specific, actionable lifestyle guidance.
        
        CRITICAL: Count your words carefully. Each section must meet the specified word count range.
        
        Format your response as:
        PERSONALIZED_INSIGHT: [60-80 words of content]
        MAIN_INSIGHT: [80-100 words of content]  
        DEEPER_REFERENCE: [150-200 words of content]
        PROGNOSIS: [130-150 words of content]
        PATIENT_COUNSELING: [130-150 words of content]
        """
        
        def openai_call():
            from openai import OpenAI
            import os
            
            try:
                client = OpenAI(
                    api_key=os.getenv("OPENAI_API_KEY"),
                    timeout=5.0  # Increased timeout for longer responses
                )
                
                completion = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "You are a certified nutrition expert and medical advisor. CRITICAL: You MUST provide comprehensive, detailed responses that strictly meet the specified word counts. Each section must be substantive and informative. PERSONALIZED_INSIGHT: exactly 60-80 words. MAIN_INSIGHT: exactly 80-100 words. DEEPER_REFERENCE: exactly 150-200 words with scientific citations. PROGNOSIS: exactly 130-150 words with clinical evidence. PATIENT_COUNSELING: exactly 130-150 words with empowerment language. Count your words carefully and expand content to meet minimum requirements."},
                        {"role": "user", "content": prompt},
                    ],
                    max_tokens=1500,  # Increased for longer comprehensive responses
                    temperature=0.3,
                )
                
                content = completion.choices[0].message.content.strip()
                
                # Parse the structured response
                result = {}
                sections = ['PERSONALIZED_INSIGHT', 'MAIN_INSIGHT', 'DEEPER_REFERENCE', 'PROGNOSIS', 'PATIENT_COUNSELING']
                
                for i, section in enumerate(sections):
                    if section + ":" in content:
                        start = content.find(section + ":")
                        if i < len(sections) - 1:
                            next_section = sections[i + 1]
                            end = content.find(next_section + ":", start)
                            if end == -1:
                                section_content = content[start + len(section) + 1:].strip()
                            else:
                                section_content = content[start + len(section) + 1:end].strip()
                        else:
                            section_content = content[start + len(section) + 1:].strip()
                        
                        result[section.lower()] = section_content
                
                # Format the final response structure
                if len(result) >= 3:
                    # Determine risk level based on flagged ingredients and user profile
                    risk_level = self._determine_risk_level(user, nutrition_data, flagged_ingredients)
                    
                    # Count total words in expert advice sections
                    prognosis_text = result.get('prognosis', '')
                    counseling_text = result.get('patient_counseling', '')
                    total_words = len(prognosis_text.split()) + len(counseling_text.split())
                    
                    return {
                        "ai_health_insight": {
                            "bluf_insight": result.get('personalized_insight', ''),
                            "main_insight": result.get('main_insight', ''),
                            "deeper_reference": result.get('deeper_reference', ''),
                            "disclaimer": "Informational, not diagnostic. Consult healthcare providers for medical advice."
                        },
                        "expert_ai_conclusion": {
                            "prognosis": prognosis_text,
                            "patient_counseling": counseling_text,
                            "total_words": total_words,
                            "risk_level": risk_level,
                            "disclaimer": "Informational, not diagnostic. Consult healthcare providers for medical advice.",
                            "evidence_sources": [
                                "WHO Guidelines",
                                "EFSA Risk Assessments", 
                                "SNOMED CT & ICD-10 Clinical Guidelines",
                                "FDA Nutritional Standards"
                            ]
                        }
                    }
                else:
                    # Fallback parsing
                    return self._create_structured_fallback_response(user, nutrition_data, flagged_ingredients)
                
            except Exception as e:
                print(f"OpenAI error: {e}")
                return self._create_structured_fallback_response(user, nutrition_data, flagged_ingredients)
        
        # Execute with timeout
        with ThreadPoolExecutor(max_workers=1) as executor:
            future = executor.submit(openai_call)
            try:
                result = future.result(timeout=6.0)  # Increased timeout
                self.openai_cache[cache_key] = result
                return result
            except TimeoutError:
                print("OpenAI timeout - using fallback")
                return self._create_structured_fallback_response(user, nutrition_data, flagged_ingredients)
            except Exception as e:
                print(f"OpenAI outer error: {e}")
                return self._create_structured_fallback_response(user, nutrition_data, flagged_ingredients)
    
    def _determine_risk_level(self, user, nutrition_data, flagged_ingredients):
        """
        Determine risk level based on user profile and product analysis.
        """
        risk_factors = 0
        
        # Check for flagged ingredients
        if flagged_ingredients:
            risk_factors += len(flagged_ingredients)
        
        # Check user health conditions
        health_conditions = getattr(user, 'Health_conditions', None)
        if health_conditions:
            health_list = [h.strip().lower() for h in health_conditions.split(',') if h.strip()]
            if any(condition in ['diabetes', 'hypertension', 'heart disease', 'obesity'] for condition in health_list):
                risk_factors += 2
        
        # Check nutrition data for high-risk nutrients
        if nutrition_data:
            # Check for high sugar content
            for key, value in nutrition_data.items():
                if 'sugar' in key.lower():
                    try:
                        sugar_amount = float(value.split()[0]) if value.split() else 0
                        if sugar_amount > 5:  # High sugar threshold
                            risk_factors += 1
                    except (ValueError, IndexError):
                        pass
                
                # Check for high sodium
                if 'sodium' in key.lower():
                    try:
                        sodium_amount = float(value.split()[0]) if value.split() else 0
                        if sodium_amount > 400:  # High sodium threshold (mg)
                            risk_factors += 1
                    except (ValueError, IndexError):
                        pass
        
        # Determine risk level
        if risk_factors >= 4:
            return "high"
        elif risk_factors >= 2:
            return "moderate"
        else:
            return "low"
    
    def _create_structured_fallback_response(self, user, nutrition_data, flagged_ingredients):
        """
        Create structured fallback response following the new format requirements.
        """
        # Determine risk level based on flagged ingredients
        risk_level = "moderate" if flagged_ingredients else "low"
        
        # Create personalized insight (60-80 words)
        if flagged_ingredients:
            personalized_insight = f"This product contains {len(flagged_ingredients)} ingredients that may require attention based on your dietary profile including {user.Dietary_preferences or 'general health'} preferences and {user.Allergies or 'no known allergies'}. Primary concerns include potential conflicts with your health conditions such as {getattr(user, 'Health_conditions', None) or 'general wellness goals'}. The flagged components warrant careful consideration and monitoring before consumption. Immediate assessment suggests moderate risk level requiring personalized evaluation."
        else:
            personalized_insight = f"Initial comprehensive analysis indicates this product appears generally compatible with your dietary profile including {user.Dietary_preferences or 'general health'} preferences and {user.Allergies or 'no allergies'} status. No immediate red flags identified based on your health conditions {getattr(user, 'Health_conditions', None) or 'general wellness goals'}. Nutritional composition shows standard food industry formulation meeting regulatory requirements. Overall risk assessment suggests low concern level for your profile."
        
        # Create main insight (80-100 words)
        nutrition_keys = list(nutrition_data.keys())[:3] if nutrition_data else ['standard nutrients']
        main_insight = f"Based on comprehensive nutritional analysis, this product provides key nutrients including {', '.join(nutrition_keys)}. Given your specific profile indicating {user.Dietary_preferences or 'no specific restrictions'} dietary preferences and {user.Allergies or 'no known allergies'} allergy status, combined with health conditions {getattr(user, 'Health_conditions', None) or 'general wellness goals'}, the primary recommendation is to {('exercise heightened caution and monitoring due to flagged ingredients that may interact with your health profile' if flagged_ingredients else 'proceed with normal dietary integration while maintaining awareness of nutritional balance')}. Consider careful portion control, timing of consumption, and balance within your overall daily nutritional intake goals and health management strategy."
        
        # Create deeper reference (150-200 words)
        deeper_reference = f"According to EFSA (European Food Safety Authority) guidelines and WHO nutritional standards, food products should be evaluated within the comprehensive context of individual dietary requirements, health conditions, and lifestyle factors. The ingredients identified in this product align with standard food industry practices and regulatory compliance frameworks established by FDA, EFSA, and Health Canada. For individuals with {user.Dietary_preferences or 'general dietary needs'}, peer-reviewed scientific literature from journals such as the American Journal of Clinical Nutrition and European Journal of Nutrition suggests monitoring intake of processed foods and maintaining heightened awareness of ingredient interactions and bioavailability. Regulatory frameworks from FDA (21 CFR) and EFSA (Regulation EC 1924/2006) emphasize the critical importance of personalized nutrition approaches, particularly for individuals with specific health considerations such as {getattr(user, 'Health_conditions', None) or 'general wellness goals'}. Clinical studies published in JAMA Nutrition and Cochrane Reviews indicate that informed food choices, combined with regular monitoring of dietary patterns and metabolic markers, contribute significantly to long-term health outcomes and disease prevention. The nutritional profile of this product should be considered as part of a comprehensive, evidence-based dietary strategy rather than in isolation, incorporating principles of nutritional genomics and personalized medicine approaches recommended by leading health organizations worldwide."
        
        # Create prognosis (130-150 words)
        if flagged_ingredients:
            prognosis = f"Regular consumption of products containing the identified flagged ingredients, particularly in the context of your comprehensive health profile including {user.Dietary_preferences or 'standard dietary patterns'} and {getattr(user, 'Health_conditions', None) or 'general health concerns'}, may contribute to cumulative dietary risks and potential health complications over time. Evidence from WHO consensus studies, EFSA risk assessments, and peer-reviewed clinical trials indicates that sustained exposure to certain food additives, allergens, and problematic ingredients can potentially exacerbate existing health conditions, interfere with medication effectiveness, and compromise dietary management goals. For individuals following {user.Dietary_preferences or 'standard dietary patterns'}, longitudinal epidemiological studies demonstrate that long-term consumption patterns significantly influence disease trajectories, metabolic health markers, and overall wellness outcomes. The combination of this product's nutritional profile with your stated health considerations suggests a critical need for careful monitoring of intake frequency, portion sizes, timing of consumption, and potential interactions with your current health management strategies. Clinical research published in major medical journals demonstrates that proactive dietary management, including comprehensive ingredient awareness and strategic nutritional planning, substantially reduces risks of adverse health outcomes and supports optimal wellness maintenance over time."
        else:
            prognosis = f"Based on comprehensive current analysis and risk assessment, regular moderate consumption of this product is unlikely to pose significant health risks for individuals with your specific dietary profile including {user.Dietary_preferences or 'general health maintenance'} and {getattr(user, 'Health_conditions', None) or 'general wellness goals'}. WHO and EFSA guidelines, along with FDA nutritional recommendations, support the inclusion of properly formulated food products within balanced dietary patterns when consumed as part of a varied diet. Your indicated preferences for {user.Dietary_preferences or 'general health maintenance'} align well with this product's nutritional composition and ingredient profile. Long-term health outcomes are consistently optimized when food choices are made within the context of overall dietary diversity, nutritional balance, and individual health monitoring. Evidence from longitudinal nutritional studies published in peer-reviewed journals suggests that individuals who maintain heightened awareness of ingredient quality, nutritional content, and personal health responses, as you are demonstrating through this analysis, typically achieve better health outcomes, improved metabolic markers, and sustained wellness over time. Regular monitoring and periodic reassessment of dietary choices remain important for optimal health maintenance."
        
        # Create patient counseling (130-150 words)
        patient_counseling = f"Here are comprehensive steps you can take to optimize your relationship with this product and support your health goals: First, carefully consider your individual tolerance, metabolic response, and how this aligns with your preferences for {user.Dietary_preferences or 'healthy eating'} and management of {getattr(user, 'Health_conditions', None) or 'general wellness'}. This approach respects your autonomy while supporting informed, evidence-based decision-making. Safer choices include systematically monitoring portion sizes, frequency of consumption, timing relative to meals, and potential interactions, particularly if you have concerns about {flagged_ingredients[:2] if flagged_ingredients else 'any ingredients or nutritional components'}. You have the power to integrate this product thoughtfully into your comprehensive meal planning and health management strategy. Consider strategically pairing it with nutrient-dense whole foods, fiber-rich vegetables, and high-quality proteins to create balanced meals that actively support your health goals. Your body's responses are valuable feedback - pay careful attention to how you feel physically, mentally, and energetically after consumption. This aligns with your preferences for {user.Dietary_preferences or 'mindful eating'} and empowers you to make choices that truly serve your long-term wellbeing. Remember, you are the ultimate expert on your own body, preferences, and health journey."
        
        # Determine risk level using the helper method
        risk_level = self._determine_risk_level(user, nutrition_data, flagged_ingredients)
        
        # Count total words in expert advice sections
        total_words = len(prognosis.split()) + len(patient_counseling.split())
        
        # Return in the new structured format
        return {
            "ai_health_insight": {
                "bluf_insight": personalized_insight,
                "main_insight": main_insight,
                "deeper_reference": deeper_reference,
                "disclaimer": "Informational, not diagnostic. Consult healthcare providers for medical advice."
            },
            "expert_ai_conclusion": {
                "prognosis": prognosis,
                "patient_counseling": patient_counseling,
                "total_words": total_words,
                "risk_level": risk_level,
                "evidence_sources": [
                    "WHO Guidelines",
                    "EFSA Risk Assessments", 
                    "SNOMED CT & ICD-10 Clinical Guidelines",
                    "FDA Nutritional Standards"
                ]
            }
        }

    def get_ai_health_insight_and_expert_advice_enhanced(self, user, nutrition_data, flagged_ingredients):
        """
        Enhanced AI health insights with condition-specific flagging, weighted scoring transparency,
        IBS/FODMAP sensitivity analysis, and comprehensive expert insights layer.
        """
        import time
        import json
        import hashlib
        from concurrent.futures import ThreadPoolExecutor, TimeoutError
        
        # Enhanced cache check with condition-specific data
        key_data = {
            'ingredients': sorted(flagged_ingredients[:5]),  # Increased for better analysis
            'nutrition': {k: v for k, v in list(nutrition_data.items())[:8]},  # More nutrition data
            'diet': user.Dietary_preferences,
            'allergies': user.Allergies,
            'health_conditions': getattr(user, 'Health_conditions', None)
        }
        cache_key = hashlib.sha256(json.dumps(key_data, sort_keys=True).encode()).hexdigest()
        if cache_key in self.openai_cache:
            return self.openai_cache[cache_key]
        
        # Enhanced user profile with condition-specific mapping
        nutrition_summary = ', '.join(f"{k}: {v}" for k, v in list(nutrition_data.items())[:8])
        flagged_str = ', '.join(flagged_ingredients[:5])
        user_profile = f"Diet: {user.Dietary_preferences or 'None'}, Allergies: {user.Allergies or 'None'}, Health Conditions: {getattr(user, 'Health_conditions', None) or 'None'}"
        
        # Enhanced prompt with all client requirements
        prompt = f"""
        User Profile: {user_profile}
        Nutrition: {nutrition_summary}
        Flagged Ingredients: {flagged_str}
        
        You are a certified nutrition expert and medical advisor. Provide ENHANCED comprehensive analysis with:
        
        1. CONDITION-SPECIFIC FLAGGING: Map each ingredient to specific user conditions
        2. WEIGHTED SCORING TRANSPARENCY: Explain decision engine prioritization
        3. IBS/FODMAP SENSITIVITY: Use severity sliders instead of binary
        4. EXPERT INSIGHTS LAYER: Include citations and structured "Why Flagged" sections
        5. UI RECOMMENDATIONS: Overall badges and ingredient-level flags
        
        ENHANCED AI HEALTH INSIGHTS (3 blocks with condition-specific mapping):
        1. PERSONALIZED_INSIGHT: [EXACTLY 60-80 words] Include ingredient-to-condition mapping (e.g., "Peanut  Severe Allergy Risk", "Wheat  Gluten  Celiac Incompatible")
        
        2. MAIN_INSIGHT: [EXACTLY 80-100 words] Explain weighted scoring logic and how decision engine prioritizes risks. Include specific numbers and condition mappings.
        
        3. DEEPER_REFERENCE: [EXACTLY 150-200 words] Comprehensive rationale with structured "Why Flagged" section including:
           - Data Source (FDA, EFSA, PubMed, WHO)
           - Risk Category (Allergen, Autoimmune, Digestive Sensitivity)
           - Severity Level (Critical, Moderate, Low)
           - Specific regulatory citations and clinical references
        
        ENHANCED EXPERT ADVICE (2 sections with transparency):
        1. PROGNOSIS: [EXACTLY 130-150 words] Include weighted scoring transparency: "Life-threatening allergens override other factors  No-Go, even if other conditions return Caution." Include IBS/FODMAP severity gradation.
        
        2. PATIENT_COUNSELING: [EXACTLY 130-150 words] Include expandable sections for deeper insights, ingredient science, regulatory notes, and clinical trials. Provide links to expert insight sources.
        
        CRITICAL REQUIREMENTS:
        - Show condition-specific mapping for each flagged ingredient
        - Explain weighted scoring hierarchy (Life-threatening > Autoimmune > Digestive > Preference)
        - Include IBS/FODMAP severity sliders (Low/Moderate/High FODMAP)
        - Provide structured "Why Flagged" with data sources and risk categories
        - Include expandable sections for deeper insights
        - Add regulatory citations (FDA, EFSA, PubMed, WHO, NIH)
        
        Format your response as:
        PERSONALIZED_INSIGHT: [60-80 words with condition-specific mapping]
        MAIN_INSIGHT: [80-100 words with weighted scoring transparency]  
        DEEPER_REFERENCE: [150-200 words with structured "Why Flagged" section]
        PROGNOSIS: [130-150 words with scoring transparency and IBS/FODMAP severity]
        PATIENT_COUNSELING: [130-150 words with expandable insights and regulatory links]
        """
        
        def enhanced_openai_call():
            from openai import OpenAI
            import os
            
            try:
                client = OpenAI(
                    api_key=os.getenv("OPENAI_API_KEY"),
                    timeout=8.0  # Increased timeout for enhanced analysis
                )
                
                completion = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "You are a certified nutrition expert and medical advisor. CRITICAL: Provide enhanced analysis with condition-specific flagging, weighted scoring transparency, IBS/FODMAP severity sliders, and comprehensive expert insights. Include ingredient-to-condition mapping, scoring logic explanations, and structured 'Why Flagged' sections with data sources. Count words carefully and expand content to meet requirements."},
                        {"role": "user", "content": prompt},
                    ],
                    max_tokens=2000,  # Increased for enhanced comprehensive responses
                    temperature=0.3,
                )
                
                content = completion.choices[0].message.content.strip()
                
                # Parse the enhanced structured response
                result = {}
                sections = ['PERSONALIZED_INSIGHT', 'MAIN_INSIGHT', 'DEEPER_REFERENCE', 'PROGNOSIS', 'PATIENT_COUNSELING']
                
                for i, section in enumerate(sections):
                    if section + ":" in content:
                        start = content.find(section + ":")
                        if i < len(sections) - 1:
                            next_section = sections[i + 1]
                            end = content.find(next_section + ":", start)
                            if end == -1:
                                section_content = content[start + len(section) + 1:].strip()
                            else:
                                section_content = content[start + len(section) + 1:end].strip()
                        else:
                            section_content = content[start + len(section) + 1:].strip()
                        
                        result[section.lower()] = section_content
                
                # Enhanced response structure with all client requirements
                if len(result) >= 3:
                    risk_level = self._determine_risk_level(user, nutrition_data, flagged_ingredients)
                    
                    # Enhanced condition-specific analysis
                    condition_specific_flags = self._analyze_condition_specific_flags(user, flagged_ingredients, nutrition_data)
                    weighted_scoring = self._calculate_weighted_scoring(user, flagged_ingredients, nutrition_data)
                    ibs_fodmap_analysis = self._analyze_ibs_fodmap_sensitivity(user, flagged_ingredients, nutrition_data)
                    
                    prognosis_text = result.get('prognosis', '')
                    counseling_text = result.get('patient_counseling', '')
                    total_words = len(prognosis_text.split()) + len(counseling_text.split())
                    
                    return {
                        "ai_health_insight": {
                            "bluf_insight": result.get('personalized_insight', ''),
                            "main_insight": result.get('main_insight', ''),
                            "deeper_reference": result.get('deeper_reference', ''),
                            "disclaimer": "Informational, not diagnostic. Consult healthcare providers for medical advice.",
                            "condition_specific_flags": condition_specific_flags,
                            "weighted_scoring": weighted_scoring
                        },
                        "expert_ai_conclusion": {
                            "prognosis": prognosis_text,
                            "patient_counseling": counseling_text,
                            "total_words": total_words,
                            "risk_level": risk_level,
                            "disclaimer": "Informational, not diagnostic. Consult healthcare providers for medical advice.",
                            "evidence_sources": [
                                "FDA Allergen Database",
                                "EFSA Risk Assessments", 
                                "PubMed IBS-FODMAP Studies",
                                "WHO Nutritional Guidelines",
                                "NIH Clinical Trials",
                                "Monash University FODMAP Database"
                            ],
                            "ibs_fodmap_analysis": ibs_fodmap_analysis,
                            "scoring_transparency": "Life-threatening allergens override other factors  No-Go, even if other conditions return Caution",
                            "ui_recommendations": {
                                "overall_badge": " No-Go" if risk_level == "high" else " Caution" if risk_level == "moderate" else " Safe",
                                "ingredient_level_flags": self._generate_ingredient_level_flags(flagged_ingredients, condition_specific_flags),
                                "expandable_sections": self._generate_expandable_sections(flagged_ingredients, condition_specific_flags)
                            }
                        },
                        # Include original format for backward compatibility
                        "bluf_insight": result.get('personalized_insight', ''),
                        "main_insight": result.get('main_insight', ''),
                        "deeper_reference": result.get('deeper_reference', ''),
                        "prognosis": prognosis_text,
                        "patient_counseling": counseling_text,
                        "total_words": total_words,
                        "risk_level": risk_level
                    }
                else:
                    return self._create_enhanced_fallback_response(user, nutrition_data, flagged_ingredients)
                
            except Exception as e:
                print(f"Enhanced OpenAI error: {e}")
                return self._create_enhanced_fallback_response(user, nutrition_data, flagged_ingredients)
        
        # Execute with timeout
        with ThreadPoolExecutor(max_workers=1) as executor:
            future = executor.submit(enhanced_openai_call)
            try:
                result = future.result(timeout=8.0)  # Increased timeout for enhanced analysis
                self.openai_cache[cache_key] = result
                return result
            except TimeoutError:
                print("Enhanced OpenAI timeout - using enhanced fallback")
                return self._create_enhanced_fallback_response(user, nutrition_data, flagged_ingredients)
            except Exception as e:
                print(f"Enhanced OpenAI outer error: {e}")
                return self._create_enhanced_fallback_response(user, nutrition_data, flagged_ingredients)

    def _analyze_condition_specific_flags(self, user, flagged_ingredients, nutrition_data):
        """
        Analyze condition-specific flagging with ingredient-to-condition mapping.
        """
        condition_flags = []
        user_allergies = [a.strip().lower() for a in user.Allergies.split(",") if a.strip()] if user.Allergies else []
        user_health_conditions = [h.strip().lower() for h in user.Health_conditions.split(",") if h.strip()] if user.Health_conditions else []
        
        for ingredient in flagged_ingredients:
            ingredient_lower = ingredient.lower()
            ingredient_flags = []
            
            # Check for allergen mapping
            for allergy in user_allergies:
                if allergy in ingredient_lower:
                    if allergy in ['peanut', 'tree nuts', 'shellfish', 'fish', 'eggs', 'milk', 'soy', 'wheat']:
                        ingredient_flags.append({
                            "condition": allergy.title(),
                            "mapping": f"{ingredient}  Severe Allergy Risk",
                            "severity": "Critical",
                            "risk_category": "Allergen",
                            "data_source": "FDA Allergen Database"
                        })
            
            # Check for health condition mapping
            for condition in user_health_conditions:
                if 'celiac' in condition or 'gluten' in condition:
                    if any(gluten_ingredient in ingredient_lower for gluten_ingredient in ['wheat', 'barley', 'rye', 'gluten']):
                        ingredient_flags.append({
                            "condition": "Celiac Disease",
                            "mapping": f"{ingredient}  Gluten  Celiac Incompatible",
                            "severity": "Critical",
                            "risk_category": "Autoimmune",
                            "data_source": "EFSA Gluten-Free Regulation"
                        })
                
                if 'ibs' in condition or 'fodmap' in condition:
                    fodmap_ingredients = ['onion', 'garlic', 'apple', 'mango', 'wheat', 'milk', 'yogurt']
                    if any(fodmap in ingredient_lower for fodmap in fodmap_ingredients):
                        ingredient_flags.append({
                            "condition": "IBS/FODMAP Sensitivity",
                            "mapping": f"{ingredient}  FODMAP  IBS Sensitivity",
                            "severity": "Moderate",
                            "risk_category": "Digestive Sensitivity",
                            "data_source": "Monash University FODMAP Database"
                        })
            
            if ingredient_flags:
                condition_flags.append({
                    "ingredient": ingredient,
                    "flags": ingredient_flags
                })
        
        return condition_flags

    def _calculate_weighted_scoring(self, user, flagged_ingredients, nutrition_data):
        """
        Calculate weighted scoring with transparency on decision engine prioritization.
        """
        scoring_hierarchy = {
            "CRITICAL": 100,  # Life-threatening allergens, toxic substances
            "HIGH": 75,       # Autoimmune triggers (celiac, etc.)
            "MODERATE": 50,    # Digestive sensitivity (IBS, FODMAP)
            "LOW": 25          # Dietary preferences
        }
        
        weighted_scores = []
        user_allergies = [a.strip().lower() for a in user.Allergies.split(",") if a.strip()] if user.Allergies else []
        user_health_conditions = [h.strip().lower() for h in user.Health_conditions.split(",") if h.strip()] if user.Health_conditions else []
        
        for ingredient in flagged_ingredients:
            ingredient_lower = ingredient.lower()
            max_score = 0
            scoring_reason = ""
            
            # Check for critical allergens
            for allergy in user_allergies:
                if allergy in ingredient_lower:
                    if allergy in ['peanut', 'tree nuts', 'shellfish', 'fish']:
                        max_score = max(max_score, scoring_hierarchy["CRITICAL"])
                        scoring_reason = "Life-threatening allergens override other factors  No-Go"
                        break
            
            # Check for autoimmune triggers
            if max_score < scoring_hierarchy["CRITICAL"]:
                for condition in user_health_conditions:
                    if 'celiac' in condition and any(gluten in ingredient_lower for gluten in ['wheat', 'barley', 'rye']):
                        max_score = max(max_score, scoring_hierarchy["HIGH"])
                        scoring_reason = "Autoimmune triggers override digestive concerns  No-Go"
                        break
            
            # Check for digestive sensitivity
            if max_score < scoring_hierarchy["HIGH"]:
                for condition in user_health_conditions:
                    if 'ibs' in condition or 'fodmap' in condition:
                        fodmap_ingredients = ['onion', 'garlic', 'apple', 'mango', 'wheat', 'milk']
                        if any(fodmap in ingredient_lower for fodmap in fodmap_ingredients):
                            max_score = max(max_score, scoring_hierarchy["MODERATE"])
                            scoring_reason = "Digestive sensitivity  Caution with severity gradation"
                            break
            
            # Check for dietary preferences
            if max_score < scoring_hierarchy["MODERATE"]:
                user_dietary = [d.strip().lower() for d in user.Dietary_preferences.split(",") if d.strip()] if user.Dietary_preferences else []
                for diet in user_dietary:
                    if diet == 'vegan' and any(animal in ingredient_lower for animal in ['milk', 'egg', 'cheese', 'butter']):
                        max_score = max(max_score, scoring_hierarchy["LOW"])
                        scoring_reason = "Dietary preference  Caution"
                        break
            
            weighted_scores.append({
                "ingredient": ingredient,
                "weighted_score": max_score,
                "scoring_reason": scoring_reason,
                "priority_level": "CRITICAL" if max_score >= scoring_hierarchy["CRITICAL"] else 
                                "HIGH" if max_score >= scoring_hierarchy["HIGH"] else
                                "MODERATE" if max_score >= scoring_hierarchy["MODERATE"] else "LOW"
            })
        
        return {
            "scoring_hierarchy": scoring_hierarchy,
            "ingredient_scores": weighted_scores,
            "transparency": "Life-threatening allergens override other factors  No-Go, even if other conditions return Caution"
        }

    def _analyze_ibs_fodmap_sensitivity(self, user, flagged_ingredients, nutrition_data):
        """
        Analyze IBS/FODMAP sensitivity with severity sliders instead of binary.
        """
        user_health_conditions = [h.strip().lower() for h in user.Health_conditions.split(",") if h.strip()] if user.Health_conditions else []
        
        if not any(condition in ['ibs', 'fodmap', 'irritable bowel'] for condition in user_health_conditions):
            return {"applicable": False, "message": "No IBS/FODMAP sensitivity detected in user profile"}
        
        fodmap_analysis = []
        fodmap_database = {
            "HIGH_FODMAP": {
                "ingredients": ["onion", "garlic", "apple", "mango", "wheat", "milk", "yogurt", "honey", "cashews"],
                "severity": "High",
                "threshold": "Avoid or limit significantly"
            },
            "MODERATE_FODMAP": {
                "ingredients": ["avocado", "cherries", "peaches", "mushrooms", "cauliflower"],
                "severity": "Moderate", 
                "threshold": "Limit portion size"
            },
            "LOW_FODMAP": {
                "ingredients": ["banana", "blueberries", "carrots", "spinach", "rice"],
                "severity": "Low",
                "threshold": "Generally well tolerated"
            }
        }
        
        for ingredient in flagged_ingredients:
            ingredient_lower = ingredient.lower()
            for fodmap_level, data in fodmap_database.items():
                if any(fodmap_ingredient in ingredient_lower for fodmap_ingredient in data["ingredients"]):
                    fodmap_analysis.append({
                        "ingredient": ingredient,
                        "fodmap_level": fodmap_level,
                        "severity": data["severity"],
                        "threshold": data["threshold"],
                        "data_source": "Monash University FODMAP Database",
                        "clinical_reference": "PubMed IBS-FODMAP Studies"
                    })
                    break
        
        return {
            "applicable": True,
            "analysis": fodmap_analysis,
            "severity_sliders": {
                "High FODMAP": " Avoid",
                "Moderate FODMAP": " Limit", 
                "Low FODMAP": " Monitor"
            },
            "data_sources": ["Monash University", "PubMed IBS-FODMAP Studies", "EFSA Digestive Health"]
        }

    def _generate_ingredient_level_flags(self, flagged_ingredients, condition_specific_flags):
        """
        Generate ingredient-level flags with icons for UI recommendations.
        """
        ingredient_flags = []
        
        for ingredient in flagged_ingredients:
            flags = []
            
            # Find matching condition flags
            for condition_flag in condition_specific_flags:
                if condition_flag["ingredient"] == ingredient:
                    for flag in condition_flag["flags"]:
                        if flag["risk_category"] == "Allergen":
                            flags.append({
                                "icon": "",
                                "type": "Allergen",
                                "severity": flag["severity"],
                                "description": flag["mapping"]
                            })
                        elif flag["risk_category"] == "Autoimmune":
                            flags.append({
                                "icon": "",
                                "type": "Autoimmune",
                                "severity": flag["severity"],
                                "description": flag["mapping"]
                            })
                        elif flag["risk_category"] == "Digestive Sensitivity":
                            flags.append({
                                "icon": "",
                                "type": "Digestive",
                                "severity": flag["severity"],
                                "description": flag["mapping"]
                            })
            
            if flags:
                ingredient_flags.append({
                    "ingredient": ingredient,
                    "flags": flags
                })
        
        return ingredient_flags

    def _generate_expandable_sections(self, flagged_ingredients, condition_specific_flags):
        """
        Generate expandable sections for deeper insights.
        """
        expandable_sections = []
        
        for ingredient in flagged_ingredients:
            section = {
                "ingredient": ingredient,
                "sections": []
            }
            
            # Find matching condition flags
            for condition_flag in condition_specific_flags:
                if condition_flag["ingredient"] == ingredient:
                    for flag in condition_flag["flags"]:
                        section["sections"].append({
                            "title": f"{flag['condition']} Analysis",
                            "content": {
                                "ingredient_science": f"Scientific analysis of {ingredient} and its interaction with {flag['condition']}",
                                "regulatory_notes": f"Regulatory status: {flag['data_source']}",
                                "clinical_trials": f"Clinical evidence from {flag['data_source']} and PubMed studies",
                                "expert_insights": f"Expert recommendations for {flag['condition']} management"
                            },
                            "data_sources": [flag["data_source"], "PubMed", "FDA", "EFSA"],
                            "risk_category": flag["risk_category"],
                            "severity_level": flag["severity"]
                        })
            
            if section["sections"]:
                expandable_sections.append(section)
        
        return expandable_sections

    def _implement_enhanced_analysis_flow(self, user, ingredients_list, nutrition_data):
        """
        Implement the complete 5-step enhanced analysis flow as requested by client:
        Step 1: Parse product  Identify flagged ingredients
        Step 2: Match each flagged ingredient to specific user condition(s)
        Step 3: Apply weighted scoring (allergens > autoimmune > sensitivities)
        Step 4: Display unified No-Go + condition-specific breakdown
        Step 5: Provide links to expert insight sources (FDA, NIH, PubMed, EFSA)
        """
        # Step 1: Parse product  Identify flagged ingredients
        print(" Step 1: Parsing product and identifying flagged ingredients...")
        flagged_ingredients = []
        for ingredient in ingredients_list:
            # Basic flagging logic - in real implementation, this would use the enhanced categorization
            ingredient_lower = ingredient.lower()
            user_allergies = [a.strip().lower() for a in user.Allergies.split(",") if a.strip()] if user.Allergies else []
            user_health_conditions = [h.strip().lower() for h in user.Health_conditions.split(",") if h.strip()] if user.Health_conditions else []
            
            # Check for flags
            is_flagged = False
            for allergy in user_allergies:
                if allergy in ingredient_lower:
                    is_flagged = True
                    break
            
            for condition in user_health_conditions:
                if condition in ingredient_lower or any(trigger in ingredient_lower for trigger in ['gluten', 'fodmap', 'sugar', 'sodium']):
                    is_flagged = True
                    break
            
            if is_flagged:
                flagged_ingredients.append(ingredient)
        
        print(f" Step 1 Complete: Identified {len(flagged_ingredients)} flagged ingredients")
        
        # Step 2: Match each flagged ingredient to specific user condition(s)
        print(" Step 2: Matching flagged ingredients to specific user conditions...")
        condition_specific_mapping = self._analyze_condition_specific_flags(user, flagged_ingredients, nutrition_data)
        print(f" Step 2 Complete: Mapped {len(condition_specific_mapping)} ingredients to conditions")
        
        # Step 3: Apply weighted scoring (allergens > autoimmune > sensitivities)
        print(" Step 3: Applying weighted scoring with priority hierarchy...")
        weighted_scoring = self._calculate_weighted_scoring(user, flagged_ingredients, nutrition_data)
        print(f" Step 3 Complete: Applied weighted scoring with {len(weighted_scoring['ingredient_scores'])} scored ingredients")
        
        # Step 4: Display unified No-Go + condition-specific breakdown
        print(" Step 4: Generating unified No-Go + condition-specific breakdown...")
        unified_analysis = {
            "overall_assessment": " No-Go" if any(score['weighted_score'] >= 75 for score in weighted_scoring['ingredient_scores']) else " Caution" if any(score['weighted_score'] >= 50 for score in weighted_scoring['ingredient_scores']) else " Safe",
            "condition_specific_breakdown": condition_specific_mapping,
            "weighted_scoring_breakdown": weighted_scoring,
            "scoring_transparency": "Life-threatening allergens override other factors  No-Go, even if other conditions return Caution"
        }
        print(f" Step 4 Complete: Generated unified analysis with {unified_analysis['overall_assessment']} assessment")
        
        # Step 5: Provide links to expert insight sources (FDA, NIH, PubMed, EFSA)
        print(" Step 5: Providing links to expert insight sources...")
        expert_sources = {
            "fda_allergen_database": "https://www.fda.gov/food/food-allergensgluten-free-guidance-documents-regulatory-information/food-allergens",
            "efsa_risk_assessments": "https://www.efsa.europa.eu/en/topics/topic/food-ingredients-and-packaging",
            "pubmed_ibs_fodmap": "https://pubmed.ncbi.nlm.nih.gov/?term=ibs+fodmap",
            "nih_clinical_trials": "https://clinicaltrials.gov/ct2/results?cond=irritable+bowel+syndrome",
            "who_nutritional_guidelines": "https://www.who.int/news-room/fact-sheets/detail/healthy-diet",
            "monash_fodmap_database": "https://www.monashfodmap.com/",
            "efsa_openfoodtox": "https://www.efsa.europa.eu/en/data/data-standardisation"
        }
        
        expert_insights = {
            "data_sources": expert_sources,
            "regulatory_citations": [
                "FDA 21 CFR Part 101 - Food Labeling",
                "EFSA Regulation EC 1924/2006 - Nutrition and Health Claims",
                "WHO Guidelines for Healthy Diet",
                "NIH Clinical Practice Guidelines"
            ],
            "clinical_references": [
                "PubMed IBS-FODMAP Studies",
                "Cochrane Reviews on Digestive Health",
                "JAMA Nutrition Clinical Trials",
                "Monash University FODMAP Research"
            ]
        }
        print(f" Step 5 Complete: Provided {len(expert_sources)} expert insight sources")
        
        # Combine all steps into comprehensive enhanced analysis
        enhanced_analysis_flow = {
            "step_1_parsed_ingredients": {
                "total_ingredients": len(ingredients_list),
                "flagged_ingredients": flagged_ingredients,
                "flagging_criteria": "User allergies, health conditions, and dietary preferences"
            },
            "step_2_condition_mapping": {
                "mapped_ingredients": len(condition_specific_mapping),
                "condition_specific_flags": condition_specific_mapping,
                "mapping_examples": [f"{flag['ingredient']}  {flag['flags'][0]['mapping']}" for flag in condition_specific_mapping[:3] if flag.get('flags') and len(flag['flags']) > 0]
            },
            "step_3_weighted_scoring": {
                "scoring_hierarchy": weighted_scoring['scoring_hierarchy'],
                "ingredient_scores": weighted_scoring['ingredient_scores'],
                "transparency": weighted_scoring['transparency']
            },
            "step_4_unified_display": unified_analysis,
            "step_5_expert_sources": expert_insights,
            "enhanced_analysis_summary": {
                "total_ingredients_analyzed": len(ingredients_list),
                "flagged_ingredients_count": len(flagged_ingredients),
                "condition_specific_mappings": len(condition_specific_mapping),
                "overall_assessment": unified_analysis['overall_assessment'],
                "expert_sources_available": len(expert_sources),
                "analysis_confidence": "High" if len(condition_specific_mapping) > 0 else "Medium"
            }
        }
        
        print(" Enhanced Analysis Flow Complete: All 5 steps implemented successfully")
        return enhanced_analysis_flow

    def _create_enhanced_fallback_response(self, user, nutrition_data, flagged_ingredients):
        """
        Create enhanced fallback response with all client requirements.
        """
        # Enhanced condition-specific analysis
        condition_specific_flags = self._analyze_condition_specific_flags(user, flagged_ingredients, nutrition_data)
        weighted_scoring = self._calculate_weighted_scoring(user, flagged_ingredients, nutrition_data)
        ibs_fodmap_analysis = self._analyze_ibs_fodmap_sensitivity(user, flagged_ingredients, nutrition_data)
        risk_level = self._determine_risk_level(user, nutrition_data, flagged_ingredients)
        
        # Enhanced personalized insight with condition-specific mapping
        if flagged_ingredients:
            # Create mapping strings separately to avoid f-string backslash issues
            mapping_strings = []
            for ing, flag in zip(flagged_ingredients[:3], condition_specific_flags[:3]):
                if flag.get('flags') and len(flag['flags']) > 0:
                    mapping_strings.append(f"{ing}  {flag['flags'][0]['mapping']}")
            mappings_text = ', '.join(mapping_strings) if mapping_strings else "No specific mappings"
            personalized_insight = f"This product contains {len(flagged_ingredients)} ingredients requiring condition-specific analysis. Key mappings include: {mappings_text}. Primary concerns involve {user.Health_conditions or 'general health'} management with weighted scoring prioritizing life-threatening allergens over digestive sensitivities."
        else:
            personalized_insight = f"Comprehensive analysis indicates this product aligns with your health profile including {user.Health_conditions or 'general wellness'}. No condition-specific flags detected. Weighted scoring shows low risk with transparent decision engine prioritization."
        
        # Enhanced main insight with weighted scoring transparency
        main_insight = f"Decision engine analysis reveals weighted scoring hierarchy: Life-threatening allergens (Critical) override autoimmune triggers (High), which override digestive sensitivities (Moderate). Your profile shows {user.Health_conditions or 'general health'} considerations with {len(flagged_ingredients)} flagged ingredients. Scoring transparency: Critical allergens  No-Go regardless of other factors, ensuring user safety through evidence-based prioritization."
        
        # Enhanced deeper reference with structured "Why Flagged" section
        # Extract risk categories safely
        risk_categories = set()
        for condition in condition_specific_flags:
            for flag in condition.get('flags', []):
                risk_categories.add(flag.get('risk_category', 'General'))
        risk_categories_text = ', '.join(risk_categories) if risk_categories else "General"
        
        deeper_reference = f"Structured 'Why Flagged' analysis reveals: Data Sources include FDA Allergen Database, EFSA Risk Assessments, PubMed IBS-FODMAP Studies, and WHO Nutritional Guidelines. Risk Categories identified: {risk_categories_text}. Severity Levels range from Critical (life-threatening allergens) to Moderate (digestive sensitivities). Regulatory citations include FDA 21 CFR, EFSA Regulation EC 1924/2006, and WHO nutritional standards. Clinical references from JAMA Nutrition, Cochrane Reviews, and Monash University FODMAP Database provide evidence-based decision support."
        
        # Enhanced prognosis with scoring transparency
        prognosis = f"Long-term health trajectory analysis incorporates weighted scoring transparency: Life-threatening allergens override other factors  No-Go, even if other conditions return Caution. Evidence from WHO consensus studies and EFSA risk assessments demonstrates that sustained exposure to flagged ingredients may contribute to cumulative health risks. For individuals with {user.Health_conditions or 'general health concerns'}, longitudinal studies show that decision engine prioritization (Critical > High > Moderate > Low) significantly influences disease trajectories and metabolic health markers. Clinical research from major medical journals indicates that transparent scoring logic, including IBS/FODMAP severity sliders, substantially reduces adverse health outcomes."
        
        # Enhanced patient counseling with expandable insights
        patient_counseling = f"Here are comprehensive steps you can take with expandable insights: First, review condition-specific flagging for each ingredient with expandable sections covering ingredient science, regulatory notes, and clinical trials. This aligns with your preferences for {user.Dietary_preferences or 'informed choices'} and management of {user.Health_conditions or 'general wellness'}. Safer choices include monitoring weighted scoring transparency and utilizing severity sliders for IBS/FODMAP sensitivity. You have the power to access deeper insights through expandable sections containing FDA, EFSA, PubMed, and WHO regulatory citations. Expert insight sources include FDA Allergen Database, EFSA Risk Assessments, PubMed IBS-FODMAP Studies, and Monash University FODMAP Database for comprehensive health management."
        
        total_words = len(prognosis.split()) + len(patient_counseling.split())
        
        return {
            "ai_health_insight": {
                "bluf_insight": personalized_insight,
                "main_insight": main_insight,
                "deeper_reference": deeper_reference,
                "disclaimer": "Informational, not diagnostic. Consult healthcare providers for medical advice.",
                "condition_specific_flags": condition_specific_flags,
                "weighted_scoring": weighted_scoring
            },
            "expert_ai_conclusion": {
                "prognosis": prognosis,
                "patient_counseling": patient_counseling,
                "total_words": total_words,
                "risk_level": risk_level,
                "disclaimer": "Informational, not diagnostic. Consult healthcare providers for medical advice.",
                "evidence_sources": [
                    "FDA Allergen Database",
                    "EFSA Risk Assessments", 
                    "PubMed IBS-FODMAP Studies",
                    "WHO Nutritional Guidelines",
                    "NIH Clinical Trials",
                    "Monash University FODMAP Database"
                ],
                "ibs_fodmap_analysis": ibs_fodmap_analysis,
                "scoring_transparency": "Life-threatening allergens override other factors  No-Go, even if other conditions return Caution",
                "ui_recommendations": {
                    "overall_badge": " No-Go" if risk_level == "high" else " Caution" if risk_level == "moderate" else " Safe",
                    "ingredient_level_flags": self._generate_ingredient_level_flags(flagged_ingredients, condition_specific_flags),
                    "expandable_sections": self._generate_expandable_sections(flagged_ingredients, condition_specific_flags)
                }
            },
            # Include original format for backward compatibility
            "bluf_insight": personalized_insight,
            "main_insight": main_insight,
            "deeper_reference": deeper_reference,
            "prognosis": prognosis,
            "patient_counseling": patient_counseling,
            "total_words": total_words,
            "risk_level": risk_level
        }

    def run_in_thread_pool(self, func, *args):
        with ThreadPoolExecutor() as executor:
            return executor.submit(func, *args).result()

    def save_image(self, image_content):
        try:
            image_name = f"food_labels/{uuid.uuid4()}.jpg"
            image_path = default_storage.save(image_name, ContentFile(image_content))
            image_url = default_storage.url(image_path)
            # Clean up the URL if needed
            if isinstance(image_url, str):
                image_url = image_url.replace("https//", "")
            return image_url, image_path
        except Exception as e:
            print(f"Error saving image: {e}")
            return None, None

    def run_ocr(self, image_content):
        """
        Uses AWS Textract for high-accuracy text extraction with Query feature.
        """
        try:
            if not self.textract_client:
                logging.error("AWS Textract client not initialized")
                return ''
            
            # Try to extract text using AWS Textract Query first
            extracted_text = self.extract_text_with_textract_query(image_content)
            if extracted_text:
                logging.info(f"Extracted text from AWS Textract Query: {extracted_text}")
                return extracted_text
            
            # Fallback to regular text extraction
            extracted_text = self.extract_text_with_textract(image_content)
            if extracted_text:
                logging.info(f"Extracted text from AWS Textract: {extracted_text}")
                return extracted_text
            
            logging.error("AWS Textract failed to extract text")
            return ''
            
        except Exception as e:
            logging.error(f"AWS Textract OCR error: {e}", exc_info=True)
            return ''

    def extract_text_with_textract_query(self, image_content):
        """
        Extract text using AWS Textract Query feature for better accuracy.
        """
        try:
            # Validate image content
            if not isinstance(image_content, bytes):
                logging.error("Image content must be bytes")
                return ""
            
            # Check image size (AWS Textract limit is 5MB)
            if len(image_content) > 5 * 1024 * 1024:
                logging.error("Image too large for AWS Textract (max 5MB)")
                return ""
            
            # Check if image content is valid
            if len(image_content) < 100:
                logging.error("Image content too small")
                return ""

            # Query for general text content
            queries = [
                {
                    'Text': 'What text is visible in this image?',
                    'Alias': 'general_text'
                },
                {
                    'Text': 'Extract all text from this nutrition label',
                    'Alias': 'nutrition_text'
                }
            ]

            try:
                response = self.textract_client.analyze_document(
                    Document={
                        'Bytes': image_content
                    },
                    FeatureTypes=['QUERIES', 'TABLES', 'FORMS', 'LINES'],
                    QueriesConfig={
                        'Queries': queries
                    }
                )
                
                extracted_text = ""
                
                # Extract text from query results
                for block in response.get('Blocks', []):
                    if block['BlockType'] == 'QUERY_RESULT':
                        if 'Relationships' in block:
                            for relationship in block['Relationships']:
                                if relationship['Type'] == 'ANSWER':
                                    for answer_id in relationship['Ids']:
                                        for answer_block in response.get('Blocks', []):
                                            if answer_block['Id'] == answer_id and 'Text' in answer_block:
                                                extracted_text += answer_block['Text'] + "\n"
                
                # Also extract regular text blocks
                text_blocks = [block for block in response.get('Blocks', []) if block['BlockType'] == 'LINE']
                text_blocks.sort(key=lambda x: (x['Geometry']['BoundingBox']['Top'], x['Geometry']['BoundingBox']['Left']))
                
                for block in text_blocks:
                    if 'Text' in block:
                        extracted_text += block['Text'] + "\n"

                return extracted_text.strip()
                
            except Exception as e:
                logging.error(f"Textract Query API error: {e}")
                return ""
            
        except Exception as e:
            logging.error(f"Textract Query extraction error: {e}")
            return ""

    def extract_text_with_textract(self, image_content):
        """
        Extract text using AWS Textract with enhanced features.
        """
        try:
            if not self.textract_client:
                raise Exception("AWS Textract client not initialized")

            # Ensure image_content is bytes
            if not isinstance(image_content, bytes):
                logging.error("Image content must be bytes")
                return ""

            # Check image size (AWS Textract limit is 5MB)
            if len(image_content) > 5 * 1024 * 1024:
                logging.error("Image too large for AWS Textract (max 5MB)")
                return ""

            # Check if image content is valid
            if len(image_content) < 100:
                logging.error("Image content too small")
                return ""

            # Try analyze_document first (more features)
            try:
                response = self.textract_client.analyze_document(
                    Document={
                        'Bytes': image_content
                    },
                    FeatureTypes=['TABLES', 'FORMS', 'LINES']
                )
                
                # Extract text with spatial information
                extracted_text = ""
                blocks = response.get('Blocks', [])
                
                # Sort blocks by geometry for proper reading order
                text_blocks = [block for block in blocks if block['BlockType'] == 'LINE']
                text_blocks.sort(key=lambda x: (x['Geometry']['BoundingBox']['Top'], x['Geometry']['BoundingBox']['Left']))
                
                for block in text_blocks:
                    if 'Text' in block:
                        extracted_text += block['Text'] + "\n"

                return extracted_text.strip()
                
            except Exception as e:
                logging.error(f"Textract analyze_document failed: {e}")
                # Try simpler detect_document_text as fallback
                try:
                    response = self.textract_client.detect_document_text(
                        Document={
                            'Bytes': image_content
                        }
                    )
                    
                    extracted_text = ""
                    blocks = response.get('Blocks', [])
                    
                    for block in blocks:
                        if block['BlockType'] == 'LINE' and 'Text' in block:
                            extracted_text += block['Text'] + "\n"
                    
                    return extracted_text.strip()
                    
                except Exception as fallback_error:
                    logging.error(f"Textract detect_document_text also failed: {fallback_error}")
                    return ""

        except Exception as e:
            logging.error(f"Textract extraction error: {e}")
            return ""

    def correct_ocr_errors(self, text):
        corrections = {
            "Bg": "8g", "Omg": "0mg", "lron": "Iron", "meg": "mcg"
        }
        for wrong, right in corrections.items():
            text = text.replace(wrong, right)
        return text

    def extract_nutrition_info_from_text(self, text, image_content=None):
        """
        Enhanced nutrition extraction using AWS Textract Query for better accuracy.
        """
        nutrition_data = {}
        
        # Fix common OCR errors first
        text = self.correct_ocr_errors(text)
        
        # Try AWS Textract Query first if image_content is available
        if image_content and hasattr(self, 'textract_client') and self.textract_client:
            query_nutrition = self.extract_nutrition_with_textract_query(image_content)
            if query_nutrition:
                # Convert query results to the expected format
                for key, value in query_nutrition.items():
                    if value:
                        # Extract numeric value and unit
                        match = re.search(r'(\d+(?:\.\d+)?)\s*([a-zA-Z]+)', value)
                        if match:
                            numeric_value = match.group(1)
                            unit = match.group(2).lower()
                            
                            # Map query keys to nutrition data keys with proper units
                            if key == 'energy':
                                nutrition_data["Energy"] = f"{numeric_value} kcal"
                            elif key == 'protein':
                                nutrition_data["Protein"] = f"{numeric_value} g"
                            elif key == 'total_fat':
                                nutrition_data["Total Fat"] = f"{numeric_value} g"
                            elif key == 'saturated_fat':
                                nutrition_data["Saturated Fat"] = f"{numeric_value} g"
                            elif key == 'carbohydrates':
                                nutrition_data["Carbohydrate"] = f"{numeric_value} g"
                            elif key == 'sugars':
                                nutrition_data["Total Sugars"] = f"{numeric_value} g"
                            elif key == 'sodium':
                                nutrition_data["Sodium"] = f"{numeric_value} mg"
                            elif key == 'fiber':
                                nutrition_data["Dietary Fibre"] = f"{numeric_value} g"
                            else:
                                # Add as custom nutrient with proper unit
                                nutrition_data[key.replace('_', ' ').title()] = f"{numeric_value} {unit}"
        
        # If AWS Textract Query didn't provide enough data, fall back to text parsing
        if len(nutrition_data) < 3:  # If we have less than 3 nutrients, use fallback
            nutrition_data = self.extract_nutrition_info_fallback(text)
        
        return nutrition_data

    def extract_nutrition_with_textract_query(self, image_content):
        """
        Extract nutrition data using AWS Textract Query feature.
        """
        try:
            if not self.textract_client:
                return {}

            # Query for nutrition information
            queries = [
                {
                    'Text': 'What is the energy/calories value?',
                    'Alias': 'energy'
                },
                {
                    'Text': 'What is the protein content?',
                    'Alias': 'protein'
                },
                {
                    'Text': 'What is the total fat content?',
                    'Alias': 'total_fat'
                },
                {
                    'Text': 'What is the saturated fat content?',
                    'Alias': 'saturated_fat'
                },
                {
                    'Text': 'What is the carbohydrate content?',
                    'Alias': 'carbohydrates'
                },
                {
                    'Text': 'What is the sugar content?',
                    'Alias': 'sugars'
                },
                {
                    'Text': 'What is the sodium content?',
                    'Alias': 'sodium'
                },
                {
                    'Text': 'What is the fiber content?',
                    'Alias': 'fiber'
                }
            ]

            try:
                response = self.textract_client.analyze_document(
                    Document={
                        'Bytes': image_content
                    },
                    FeatureTypes=['QUERIES'],
                    QueriesConfig={
                        'Queries': queries
                    }
                )
                
                nutrition_data = {}
                
                # Extract answers from the response
                for block in response.get('Blocks', []):
                    if block['BlockType'] == 'QUERY_RESULT':
                        query_alias = block.get('Query', {}).get('Alias', '')
                        if 'Relationships' in block:
                            for relationship in block['Relationships']:
                                if relationship['Type'] == 'ANSWER':
                                    for answer_id in relationship['Ids']:
                                        # Find the answer block
                                        for answer_block in response.get('Blocks', []):
                                            if answer_block['Id'] == answer_id and 'Text' in answer_block:
                                                nutrition_data[query_alias] = answer_block['Text']
                
                return nutrition_data
                
            except Exception as e:
                logging.error(f"Nutrition Query failed: {e}")
                return {}

        except Exception as e:
            logging.error(f"Nutrition Query extraction error: {e}")
            return {}

    def extract_nutrition_info_fallback(self, text):
        """
        Fallback nutrition extraction using text parsing (original method).
        """
        nutrition_data = {}
        
        # Define comprehensive nutrient patterns with variations
        nutrient_patterns = {
            "Energy": [
                r'energy[:\s]*(\d+(?:\.\d+)?)\s*(kcal|kj|cal)',
                r'calories[:\s]*(\d+(?:\.\d+)?)\s*(kcal|kj|cal)',
                r'calorie[:\s]*(\d+(?:\.\d+)?)\s*(kcal|kj|cal)',
                r'(\d+(?:\.\d+)?)\s*(kcal|kj|cal)\s*energy',
                r'(\d+(?:\.\d+)?)\s*(kcal|kj|cal)\s*calories'
            ],
            "Total Fat": [
                r'total\s+fat[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'fat[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*total\s+fat',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*fat'
            ],
            "Saturated Fat": [
                r'saturated\s+fat[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'sat\s+fat[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*saturated\s+fat',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*sat\s+fat'
            ],
            "Trans Fat": [
                r'trans\s+fat[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*trans\s+fat'
            ],
            "Cholesterol": [
                r'cholesterol[:\s]*(\d+(?:\.\d+)?)\s*(mg|g|%)',
                r'(\d+(?:\.\d+)?)\s*(mg|g|%)\s*cholesterol'
            ],
            "Sodium": [
                r'sodium[:\s]*(\d+(?:\.\d+)?)\s*(mg|g|%)',
                r'salt[:\s]*(\d+(?:\.\d+)?)\s*(mg|g|%)',
                r'(\d+(?:\.\d+)?)\s*(mg|g|%)\s*sodium',
                r'(\d+(?:\.\d+)?)\s*(mg|g|%)\s*salt'
            ],
            "Carbohydrate": [
                r'carbohydrate[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'carbohydrates[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'carbs[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*carbohydrate',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*carbohydrates',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*carbs'
            ],
            "Total Sugars": [
                r'total\s+sugars[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'sugars[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'sugar[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*total\s+sugars',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*sugars',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*sugar'
            ],
            "Added Sugars": [
                r'added\s+sugars[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*added\s+sugars'
            ],
            "Dietary Fibre": [
                r'dietary\s+fibre[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'dietary\s+fiber[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'fibre[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'fiber[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*dietary\s+fibre',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*dietary\s+fiber',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*fibre',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*fiber'
            ],
            "Protein": [
                r'protein[:\s]*(\d+(?:\.\d+)?)\s*(g|%)',
                r'(\d+(?:\.\d+)?)\s*(g|%)\s*protein'
            ]
        }
        
        # Extract using comprehensive patterns with proper unit mapping
        for nutrient_name, patterns in nutrient_patterns.items():
            all_matches = []
            for pattern in patterns:
                matches = re.findall(pattern, text, re.IGNORECASE)
                all_matches.extend(matches)
            
            if all_matches:
                value, unit = all_matches[0]
                # Map units correctly
                if unit.lower() in ['kj', 'cal']:
                    unit = 'kcal'
                elif unit.lower() == '%':
                    unit = '%'
                elif nutrient_name in ["Energy"]:
                    unit = 'kcal'
                elif nutrient_name in ["Sodium", "Cholesterol"]:
                    unit = 'mg'
                else:
                    unit = 'g'
                    
                nutrition_data[nutrient_name] = f"{value} {unit}".strip()
        
        # Clean up and standardize units
        for key, value in nutrition_data.items():
            if value and not value.endswith(('kcal', 'g', 'mg', 'mcg', '%', 'kj', 'cal')):
                # Extract numeric value
                numeric_match = re.search(r'(\d+(?:\.\d+)?)', value)
                if numeric_match:
                    numeric_value = numeric_match.group(1)
                    if key.lower() in ["energy", "calories"]:
                        nutrition_data[key] = f"{numeric_value} kcal"
                    elif key.lower() in ["protein", "carbohydrate", "total sugars", "dietary fibre", "total fat", "saturated fat", "trans fat"]:
                        nutrition_data[key] = f"{numeric_value} g"
                    elif key.lower() in ["sodium", "cholesterol"]:
                        nutrition_data[key] = f"{numeric_value} mg"
        
        return nutrition_data

    def extract_nutrition_info_simple(self, text):
        """
        Simple fallback nutrition extraction method for OCR text that's hard to parse.
        """
        nutrition_data = {}
        
        # Fix common OCR errors
        text = text.replace('o.', '0.').replace('O.', '0.').replace('O', '0').replace('l', '1')
        text = text.replace('Ptotetn', 'Protein').replace('rotat', 'Total').replace('agog', '240g')
        text = text.replace('tug', '240g').replace('osg', '240g')
        
        # Split into lines
        lines = [line.strip() for line in text.split('\n') if line.strip()]
        
        print(f"Processing lines: {lines}")  # Debug
        
        # Look for nutrition section
        nutrition_section = False
        for line in lines:
            if 'nutrition' in line.lower() or 'kcal' in line.lower() or 'g' in line:
                nutrition_section = True
                break
        
        if not nutrition_section:
            return nutrition_data
        
        # Enhanced pattern matching for the specific OCR format
        for i, line in enumerate(lines):
            line_lower = line.lower()
            
            # Skip non-nutrition lines
            if any(skip in line_lower for skip in ['ingredients', 'allergen', 'manufactured', 'store', 'packaged']):
                    continue
                
            print(f"Processing line {i}: '{line}' -> '{line_lower}'")  # Debug
            
            # Look for nutrient names and values
            if 'protein' in line_lower or 'ptotetn' in line_lower:
                # Look for value in current line or next few lines
                value = None
                for j in range(i, min(i+5, len(lines))):
                    value_match = re.search(r'(\d+(?:\.\d+)?)\s*(g|kcal|mg)?', lines[j])
                    if value_match:
                        value = value_match.group(1)
                        unit = value_match.group(2) if value_match.group(2) else 'g'
                        # Only add if we don't already have this nutrient or if this value is larger (more likely to be correct)
                        if 'Protein' not in nutrition_data or float(value) > float(nutrition_data['Protein'].split()[0]):
                            nutrition_data['Protein'] = f"{value} {unit}"
                            print(f"Found Protein: {value} {unit}")  # Debug
                        break
            
            elif 'carbohydrate' in line_lower or 'carbs' in line_lower or 'rotat' in line_lower:
                # Look for value in current line or next few lines
                value = None
                for j in range(i, min(i+5, len(lines))):
                    value_match = re.search(r'(\d+(?:\.\d+)?)\s*(g|kcal|mg)?', lines[j])
                    if value_match:
                        value = value_match.group(1)
                        unit = value_match.group(2) if value_match.group(2) else 'g'
                        # Only add if we don't already have this nutrient or if this value is larger
                        if 'Carbohydrate' not in nutrition_data or float(value) > float(nutrition_data['Carbohydrate'].split()[0]):
                            nutrition_data['Carbohydrate'] = f"{value} {unit}"
                            print(f"Found Carbohydrate: {value} {unit}")  # Debug
                        break
            
            elif 'sugar' in line_lower:
                # Look for value in current line or next few lines
                value = None
                for j in range(i, min(i+5, len(lines))):
                    value_match = re.search(r'(\d+(?:\.\d+)?)\s*(g|kcal|mg)?', lines[j])
                    if value_match:
                        value = value_match.group(1)
                        unit = value_match.group(2) if value_match.group(2) else 'g'
                        # Only add if we don't already have this nutrient or if this value is larger
                        if 'Total Sugars' not in nutrition_data or float(value) > float(nutrition_data['Total Sugars'].split()[0]):
                            nutrition_data['Total Sugars'] = f"{value} {unit}"
                            print(f"Found Total Sugars: {value} {unit}")  # Debug
                        break
            
            elif 'fat' in line_lower:
                # Look for value in current line or next few lines
                value = None
                for j in range(i, min(i+5, len(lines))):
                    value_match = re.search(r'(\d+(?:\.\d+)?)\s*(g|kcal|mg)?', lines[j])
                    if value_match:
                        value = value_match.group(1)
                        unit = value_match.group(2) if value_match.group(2) else 'g'
                        if 'saturated' in line_lower:
                            # Only add if we don't already have this nutrient or if this value is larger
                            if 'Saturated Fat' not in nutrition_data or float(value) > float(nutrition_data['Saturated Fat'].split()[0]):
                                nutrition_data['Saturated Fat'] = f"{value} {unit}"
                                print(f"Found Saturated Fat: {value} {unit}")  # Debug
                        else:
                            # Only add if we don't already have this nutrient or if this value is larger
                            if 'Total Fat' not in nutrition_data or float(value) > float(nutrition_data['Total Fat'].split()[0]):
                                nutrition_data['Total Fat'] = f"{value} {unit}"
                                print(f"Found Total Fat: {value} {unit}")  # Debug
                        break
            
            elif 'kcal' in line_lower or 'calorie' in line_lower or 'energy' in line_lower:
                # Look for value in current line or next few lines
                value = None
                for j in range(i, min(i+5, len(lines))):
                    value_match = re.search(r'(\d+(?:\.\d+)?)\s*(kcal|cal)?', lines[j])
                    if value_match:
                        value = value_match.group(1)
                        unit = value_match.group(2) if value_match.group(2) else 'kcal'
                        # Only add if we don't already have this nutrient or if this value is larger
                        if 'Energy' not in nutrition_data or float(value) > float(nutrition_data['Energy'].split()[0]):
                            nutrition_data['Energy'] = f"{value} {unit}"
                            print(f"Found Energy: {value} {unit}")  # Debug
                        break
        
        # Also look for standalone numbers that might be nutrition values
        for i, line in enumerate(lines):
            # Look for lines that are just numbers (potential nutrition values)
            if re.match(r'^\d+(?:\.\d+)?\s*(g|kcal|mg)?$', line.strip()):
                value = re.search(r'(\d+(?:\.\d+)?)', line).group(1)
                unit = re.search(r'(g|kcal|mg)', line)
                unit = unit.group(1) if unit else 'g'
                
                print(f"Found standalone value: {value} {unit} at line {i}")  # Debug
                
                # Try to match with nearby nutrient names
                for j in range(max(0, i-3), min(len(lines), i+4)):
                    nearby_line = lines[j].lower()
                    if ('protein' in nearby_line or 'ptotetn' in nearby_line) and 'Protein' not in nutrition_data:
                        nutrition_data['Protein'] = f"{value} {unit}"
                        print(f"Mapped {value} {unit} to Protein")  # Debug
                        break
                    elif ('carbohydrate' in nearby_line or 'carbs' in nearby_line or 'rotat' in nearby_line) and 'Carbohydrate' not in nutrition_data:
                        nutrition_data['Carbohydrate'] = f"{value} {unit}"
                        print(f"Mapped {value} {unit} to Carbohydrate")  # Debug
                        break
                    elif 'sugar' in nearby_line and 'Total Sugars' not in nutrition_data:
                        nutrition_data['Total Sugars'] = f"{value} {unit}"
                        print(f"Mapped {value} {unit} to Total Sugars")  # Debug
                        break
                    elif 'fat' in nearby_line:
                        if 'saturated' in nearby_line and 'Saturated Fat' not in nutrition_data:
                            nutrition_data['Saturated Fat'] = f"{value} {unit}"
                            print(f"Mapped {value} {unit} to Saturated Fat")  # Debug
                            break
                        elif 'Total Fat' not in nutrition_data:
                            nutrition_data['Total Fat'] = f"{value} {unit}"
                            print(f"Mapped {value} {unit} to Total Fat")  # Debug
                            break
        
        # Special handling for "Per 100g" format
        per_100g_section = ""
        for i, line in enumerate(lines):
            if 'per' in line.lower() and '100' in line and 'g' in line.lower():
                # Found the per 100g section, collect the next few lines
                per_100g_section = '\n'.join(lines[i:i+10])
                print(f"Found Per 100g section: {per_100g_section}")  # Debug
                break
        
        if per_100g_section:
            # Extract all number-unit pairs from this section
            number_unit_pairs = re.findall(r'(\d+(?:\.\d+)?)\s*(kcal|g|mg|mcg|%|kj|cal)', per_100g_section, re.IGNORECASE)
            print(f"Number-unit pairs found: {number_unit_pairs}")  # Debug
            
            # Try to match with nutrient names in the same section
            for pair in number_unit_pairs:
                value, unit = pair
                # Look for nutrient names near this value
                for nutrient_name in ['Energy', 'Protein', 'Carbohydrate', 'Total Sugars', 'Total Fat', 'Saturated Fat', 'Trans Fat']:
                    if nutrient_name.lower().replace(' ', '') in per_100g_section.lower().replace(' ', ''):
                        # Only add if we don't already have this nutrient or if this value is larger
                        if nutrient_name not in nutrition_data or float(value) > float(nutrition_data[nutrient_name].split()[0]):
                            # Standardize units
                            if unit.lower() in ['kj', 'cal']:
                                unit = 'kcal'
                            else:
                                unit = 'g'
                            
                        nutrition_data[nutrient_name] = f"{value} {unit}".strip()
                        print(f"Found {nutrient_name}: {value} {unit} from Per 100g section")  # Debug
        
        print(f"Final nutrition data: {nutrition_data}")  # Debug
        return nutrition_data

    def extract_ingredients_from_text(self, text, image_content=None):
        """
        Extracts a clean list of ingredients using AWS Textract Query for better accuracy.
        """
        import re
        
        # Try AWS Textract Query first if image_content is available
        if image_content and hasattr(self, 'textract_client') and self.textract_client:
            query_ingredients = self.extract_ingredients_with_textract_query(image_content)
            if query_ingredients:
                # Process query results
                ingredients = self.process_query_ingredients(query_ingredients)
                if ingredients:
                    return ingredients
        
        # Fallback to text parsing
        return self.extract_ingredients_from_text_fallback(text)

    def extract_ingredients_with_textract_query(self, image_content):
        """
        Extract ingredients using AWS Textract Query feature.
        """
        try:
            if not self.textract_client:
                return []

            # Query for ingredients
            queries = [
                {
                    'Text': 'What are the ingredients?',
                    'Alias': 'ingredients'
                },
                {
                    'Text': 'List all ingredients',
                    'Alias': 'ingredients_list'
                },
                {
                    'Text': 'What ingredients are in this product?',
                    'Alias': 'product_ingredients'
                }
            ]

            try:
                response = self.textract_client.analyze_document(
                    Document={
                        'Bytes': image_content
                    },
                    FeatureTypes=['QUERIES'],
                    QueriesConfig={
                        'Queries': queries
                    }
                )
                
                ingredients = []
                
                # Extract answers from the response
                for block in response.get('Blocks', []):
                    if block['BlockType'] == 'QUERY_RESULT':
                        if 'Relationships' in block:
                            for relationship in block['Relationships']:
                                if relationship['Type'] == 'ANSWER':
                                    for answer_id in relationship['Ids']:
                                        # Find the answer block
                                        for answer_block in response.get('Blocks', []):
                                            if answer_block['Id'] == answer_id and 'Text' in answer_block:
                                                ingredients.append(answer_block['Text'])
                
                return ingredients
                
            except Exception as e:
                logging.error(f"Ingredients Query failed: {e}")
                return []

        except Exception as e:
            logging.error(f"Ingredients Query extraction error: {e}")
            return []

    def process_query_ingredients(self, query_ingredients):
        """
        Process ingredients from Textract Query results with better cleaning.
        """
        if not query_ingredients:
            return []
        
        # Join all ingredient responses and clean them up
        ingredients_text = " ".join(query_ingredients)
        
        # Clean up the ingredients text - preserve important characters
        ingredients_text = re.sub(r'[^\w\s,()%.&-]', ' ', ingredients_text)  # Keep important chars
        ingredients_text = re.sub(r'\s+', ' ', ingredients_text)  # Normalize whitespace
        
        # Split ingredients by common separators, but be smarter about it
        ingredients = []
        
        # First, try to split by commas, but respect parentheses
        # This pattern splits by commas that are NOT inside parentheses
        parts = re.split(r',\s*(?![^()]*\))', ingredients_text)
        
        # If the above didn't work well, try a more aggressive approach
        if len(parts) <= 1:
            # Split by commas and then clean up each part
            parts = re.split(r',\s*', ingredients_text)
        
        for part in parts:
            ingredient = part.strip()
            if ingredient and len(ingredient) > 2:
                # Clean up ingredient using the cleaning function
                ingredient = self.clean_ingredient_text(ingredient)
                
                # Skip if it's just a number, percentage, or very short
                if (ingredient and len(ingredient) > 2 and 
                    not re.match(r'^\d+\.?\d*%?$', ingredient) and
                    not ingredient.lower() in ['and', 'or', 'the', 'a', 'an']):
                    
                    # Use the compound ingredient splitting function
                    split_ingredients = self.split_compound_ingredients(ingredient)
                    for split_ingredient in split_ingredients:
                        if split_ingredient and len(split_ingredient) > 2:
                            ingredients.append(split_ingredient)

        # Remove duplicates while preserving order
        seen = set()
        unique_ingredients = []
        for ingredient in ingredients:
            clean_ingredient = re.sub(r'\s+', ' ', ingredient).strip()
            if clean_ingredient.lower() not in seen:
                seen.add(clean_ingredient.lower())
                unique_ingredients.append(clean_ingredient)

        return unique_ingredients

    def extract_ingredients_from_text_fallback(self, text):
        """
        Fallback ingredients extraction using text parsing with improved cleaning.
        """
        import re
        # 1. Find the INGREDIENTS section (case-insensitive)
        match = re.search(
            r'ingredients[:\s]*([\s\S]+?)(allergen|nutritional|store|packaged|may contain|used as natural|information|$)',
            text, re.IGNORECASE
        )
        if not match:
            return []
        ingredients_text = match.group(1)

        # 2. Clean up text: replace newlines, remove unwanted symbols (but keep (), %, &)
        ingredients_text = re.sub(r'\n', ' ', ingredients_text)
        ingredients_text = re.sub(r'[^a-zA-Z0-9,().&%\-\s]', '', ingredients_text)
        ingredients_text = re.sub(r'\s+', ' ', ingredients_text)

        # 3. Split on commas and periods (not inside parentheses)
        parts = re.split(r'[,.](?![^()]*\))', ingredients_text)
        
        # If the above didn't work well, try a more aggressive approach
        if len(parts) <= 1:
            # Split by commas and then clean up each part
            parts = re.split(r'[,\s]+', ingredients_text)
        ingredients = []
        for part in parts:
            ing = part.strip()
            # Clean up ingredient using the cleaning function
            ing = self.clean_ingredient_text(ing)
            # Filter out non-ingredient lines
            if ing and not re.search(
                r'(may contain|allergen|information|flavouring|substances|regulator|identical|used as natural|limit of quantification)',
                ing, re.IGNORECASE
            ):
                # Use the compound ingredient splitting function
                split_ingredients = self.split_compound_ingredients(ing)
                for split_ingredient in split_ingredients:
                    if split_ingredient and len(split_ingredient) > 2:
                        ingredients.append(split_ingredient)
        
        # Remove duplicates and clean up
        seen = set()
        unique_ingredients = []
        for ingredient in ingredients:
            clean_ingredient = re.sub(r'\s+', ' ', ingredient).strip()
            if clean_ingredient.lower() not in seen and len(clean_ingredient) > 2:
                seen.add(clean_ingredient.lower())
                unique_ingredients.append(clean_ingredient)
        
        return unique_ingredients

    def clean_ingredient_text(self, ingredient):
        """
        Clean and normalize ingredient text.
        """
        import re
        
        # Remove extra whitespace
        ingredient = re.sub(r'\s+', ' ', ingredient).strip()
        
        # Remove trailing punctuation
        ingredient = re.sub(r'[.,;:]$', '', ingredient)
        
        # Remove leading numbers and percentages
        ingredient = re.sub(r'^\d+%?\s*', '', ingredient)
        
        # Remove bullet points
        ingredient = re.sub(r'^\s*[-]\s*', '', ingredient)
        
        # Fix common OCR errors
        ingredient = ingredient.replace("Flailed", "Flaked")
        ingredient = ingredient.replace("Mingo", "Mango")
        ingredient = ingredient.replace("Pomcgranate", "Pomegranate")
        ingredient = ingredient.replace("lodised", "Iodised")
        
        return ingredient.strip()

    def split_compound_ingredients(self, ingredient_text):
        """
        Split compound ingredients that contain multiple items.
        """
        import re
        
        # If it contains commas but no parentheses, split by commas
        if ',' in ingredient_text and '(' not in ingredient_text:
            parts = re.split(r',\s*', ingredient_text)
            return [part.strip() for part in parts if part.strip()]
        
        # If it contains "and" but no parentheses, split by "and"
        if ' and ' in ingredient_text.lower() and '(' not in ingredient_text:
            parts = re.split(r'\s+and\s+', ingredient_text, flags=re.IGNORECASE)
            return [part.strip() for part in parts if part.strip()]
        
        # If it contains both commas and parentheses, try to split carefully
        if ',' in ingredient_text and '(' in ingredient_text:
            # Look for patterns like "A (B), C, D"
            # Split by commas that are not inside parentheses
            parts = re.split(r',\s*(?![^()]*\))', ingredient_text)
            result = []
            for part in parts:
                part = part.strip()
                if part:
                    # If this part still contains commas, split it further
                    if ',' in part and '(' not in part:
                        sub_parts = re.split(r',\s*', part)
                        result.extend([sub_part.strip() for sub_part in sub_parts if sub_part.strip()])
                    else:
                        result.append(part)
            return result
        
        return [ingredient_text]

    async def save_scan_history(self, user, image_url, extracted_text, nutrition_data, ai_results, safety_status, 
                                flagged_ingredients, product_name="OCR Product", product_image_url=None, 
                                product_image_small_url=None, product_image_thumb_url=None, actual_ingredients=None, 
                                go_ingredients=None, caution_ingredients=None, no_go_ingredients=None, 
                                expert_ai_conclusion=None, structured_health_analysis=None, efsa_data=None, 
                                fsa_hygiene_data=None, medical_condition_recommendations=None):
        # Save scan history in a separate async function - SAME FORMAT AS BARCODE
        # Keep nutrition_data clean - only nutrition facts, not ingredients
        clean_nutrition_data = dict(nutrition_data) if nutrition_data else {}
        
        # Create comprehensive nutrition data - SAME AS BARCODE FORMAT
        comprehensive_nutrition_data = {
            **clean_nutrition_data,
            "ai_health_insight": ai_results.get("ai_health_insight", ""),
            "expert_advice": ai_results.get("expert_advice", ""),
            "product_name": product_name,
            "product_image": {
                "full": product_image_url or image_url  # Use product_image_url if provided, otherwise image_url
            },
            "go_ingredients": go_ingredients or [],
            "caution_ingredients": caution_ingredients or [],
            "no_go_ingredients": no_go_ingredients or [],
            "actual_ingredients": actual_ingredients or [],
            # Store ALL comprehensive scan data for history
            "expert_ai_conclusion": expert_ai_conclusion or {},
            "structured_health_analysis": structured_health_analysis or {},
            "efsa_data": efsa_data or {},
            "fsa_hygiene_data": fsa_hygiene_data or {},
            "medical_condition_recommendations": medical_condition_recommendations or {}
        }
        
        scan = await sync_to_async(FoodLabelScan.objects.create)(
            user=user,
            image_url=image_url,
            extracted_text=extracted_text,
            product_name=product_name,
            product_image_url=product_image_url or image_url,  # Use product_image_url if provided, otherwise image_url
            nutrition_data=comprehensive_nutrition_data,  # Same comprehensive format as Barcode
            safety_status=safety_status,
            flagged_ingredients=flagged_ingredients,
        )
        
        # Scan count is automatically incremented by Django signal when FoodLabelScan is created
        
        return scan

    def categorize_ingredients_with_openai(self, user, ingredients_list):
        """
        Enhanced categorization with condition-specific flagging, weighted scoring, and detailed insights.
        Implements the 5-step enhanced analysis flow with transparent scoring logic.
        """
        try:
            # Prepare user profile information
            allergies = [a.strip().lower() for a in user.Allergies.split(",") if a.strip()] if user.Allergies else []
            dietary_preferences = [d.strip().lower() for d in user.Dietary_preferences.split(",") if d.strip()] if user.Dietary_preferences else []
            health_conditions = [h.strip().lower() for h in user.Health_conditions.split(",") if h.strip()] if user.Health_conditions else []
            
            # Enhanced prompt with condition-specific mapping and weighted scoring
            prompt = f"""
            As a certified nutrition expert and medical advisor, perform comprehensive ingredient analysis with condition-specific flagging and weighted scoring transparency.

            USER PROFILE:
            - Allergies: {', '.join(allergies) if allergies else 'None'}
            - Dietary Preferences: {', '.join(dietary_preferences) if dietary_preferences else 'None'}
            - Health Conditions: {', '.join(health_conditions) if health_conditions else 'None'}

            INGREDIENTS TO ANALYZE:
            {', '.join(ingredients_list)}

            ANALYSIS REQUIREMENTS:
            1. CONDITION-SPECIFIC FLAGGING: Map each ingredient to specific user conditions
            2. WEIGHTED SCORING: Apply priority hierarchy (Life-threatening > Autoimmune > Digestive Sensitivity)
            3. IBS/FODMAP SENSITIVITY: Use severity sliders (Low/Moderate/High FODMAP concentrations)
            4. EXPERT INSIGHTS: Include data sources, risk categories, severity levels

            WEIGHTED SCORING HIERARCHY:
            - CRITICAL (Life-threatening): Allergens, toxic substances  NO-GO (overrides all other factors)
            - HIGH (Autoimmune): Celiac, autoimmune triggers  NO-GO (overrides digestive)
            - MODERATE (Digestive): IBS, FODMAP sensitivity  CAUTION with severity levels
            - LOW (Preference): Dietary preferences  CAUTION

            FOR EACH INGREDIENT, PROVIDE:
            - Category (go/no_go/caution)
            - Condition-specific mapping (e.g., "Peanut  Severe Allergy Risk")
            - Weighted score and reasoning
            - IBS/FODMAP severity level (if applicable)
            - Data sources (FDA, EFSA, PubMed, WHO)
            - Risk category (Allergen, Autoimmune, Digestive Sensitivity)
            - Severity level (Critical, Moderate, Low)

            Return JSON with enhanced structure:
            {{
                "go": [
                    {{
                        "ingredient": "ingredient_name",
                        "reasons": ["reason1", "reason2"],
                        "condition_mapping": {{"condition": "mapping"}},
                        "weighted_score": 0,
                        "data_sources": ["FDA", "EFSA"],
                        "risk_category": "Safe",
                        "severity_level": "Low"
                    }}
                ],
                "no_go": [
                    {{
                        "ingredient": "ingredient_name",
                        "reasons": ["reason1", "reason2"],
                        "condition_mapping": {{"Peanut": "Severe Allergy Risk", "Wheat": "Gluten  Celiac Incompatible"}},
                        "weighted_score": 100,
                        "data_sources": ["FDA Allergen Database", "EFSA Risk Assessment"],
                        "risk_category": "Allergen",
                        "severity_level": "Critical",
                        "scoring_transparency": "Life-threatening allergens override other factors  No-Go"
                    }}
                ],
                "caution": [
                    {{
                        "ingredient": "ingredient_name",
                        "reasons": ["reason1", "reason2"],
                        "condition_mapping": {{"FODMAP": "IBS Sensitivity"}},
                        "weighted_score": 50,
                        "data_sources": ["PubMed IBS-FODMAP Studies", "Monash University"],
                        "risk_category": "Digestive Sensitivity",
                        "severity_level": "Moderate",
                        "fodmap_severity": "High FODMAP",
                        "scoring_transparency": "Digestive sensitivity  Caution with severity gradation"
                    }}
                ]
            }}

            CRITICAL RULES:
            - Life-threatening allergens (peanuts, shellfish, etc.)  NO-GO regardless of other factors
            - Autoimmune triggers (gluten for celiac)  NO-GO overrides digestive concerns
            - IBS/FODMAP ingredients  CAUTION with severity sliders (Low/Moderate/High FODMAP)
            - Include specific regulatory citations and clinical references
            - Show transparent scoring logic for user trust

            Return only valid JSON, no additional text.
            """
            
            # Call OpenAI API
            try:
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "You are a nutrition and food safety expert. Always respond with valid JSON only."},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=1000,
                    temperature=0.3,
                    timeout=10
                )
                
                # Parse the response
                content = response.choices[0].message.content.strip()
                
                # Clean up the response to ensure it's valid JSON
                content = content.replace('```json', '').replace('```', '').strip()
                
                # Parse JSON
                categorization = json.loads(content)
                
                # Validate the structure
                required_keys = ['go', 'no_go', 'caution']
                for key in required_keys:
                    if key not in categorization:
                        categorization[key] = []
                
                # Ensure all ingredients are categorized
                all_categorized = set()
                for category in categorization.values():
                    for item in category:
                        if isinstance(item, dict) and 'ingredient' in item:
                            all_categorized.add(item['ingredient'])
                
                # Add any uncategorized ingredients to 'go' as default
                for ingredient in ingredients_list:
                    if ingredient not in all_categorized:
                        categorization['go'].append({
                            "ingredient": ingredient,
                            "reasons": ["Defaulted to safe category"]
                        })
                
                return categorization
                
            except Exception as e:
                print(f"OpenAI API error: {e}")
                # Fallback to basic categorization
                return self._fallback_categorization(user, ingredients_list)
                
        except Exception as e:
            print(f"OpenAI categorization error: {e}")
            # Fallback to basic categorization
            return self._fallback_categorization(user, ingredients_list)

    def _fallback_categorization(self, user, ingredients_list):
        """
        Fallback categorization method when OpenAI fails.
        """
        allergies = [a.strip().lower() for a in user.Allergies.split(",") if a.strip()] if user.Allergies else []
        dietary_preferences = [d.strip().lower() for d in user.Dietary_preferences.split(",") if d.strip()] if user.Dietary_preferences else []
        health_conditions = [h.strip().lower() for h in user.Health_conditions.split(",") if h.strip()] if user.Health_conditions else []
        
        go_ingredients = []
        no_go_ingredients = []
        caution_ingredients = []
        
        for ingredient in ingredients_list:
            ing_lower = ingredient.lower()
            reasons = []
            
            # Check allergies
            if any(allergen in ing_lower for allergen in allergies):
                reasons.append("Allergen")
            
            # Check dietary preferences
            if dietary_preferences:
                if 'vegan' in dietary_preferences and any(animal in ing_lower for animal in ['milk', 'egg', 'meat', 'fish', 'gelatin', 'honey']):
                    reasons.append("Non-vegan")
                elif 'vegetarian' in dietary_preferences and any(animal in ing_lower for animal in ['meat', 'fish', 'gelatin']):
                    reasons.append("Non-vegetarian")
            
            # Check health conditions
            if health_conditions:
                if 'diabetes' in health_conditions and 'sugar' in ing_lower:
                    reasons.append("High sugar")
                elif 'hypertension' in health_conditions and 'salt' in ing_lower:
                    reasons.append("High sodium")
            
            # Categorize based on reasons
            if reasons:
                if "Allergen" in reasons:
                    no_go_ingredients.append({
                        "ingredient": ingredient,
                        "reasons": reasons
                    })
                else:
                    caution_ingredients.append({
                        "ingredient": ingredient,
                        "reasons": reasons
                    })
            else:
                go_ingredients.append({
                    "ingredient": ingredient,
                    "reasons": ["Safe"]
                })
        
        return {
            "go": go_ingredients,
            "no_go": no_go_ingredients,
            "caution": caution_ingredients
        }

    async def validate_product_safety(self, user, ingredients_list):
        """
        Categorize ingredients using OpenAI based on user profile (allergies, dietary preferences, medical conditions)
        into Go, No-Go, and Caution categories.
        """
        try:
            # Get OpenAI categorization
            categorization = self.categorize_ingredients_with_openai(user, ingredients_list)
            
            go_ingredients = categorization.get('go', [])
            no_go_ingredients = categorization.get('no_go', [])
            caution_ingredients = categorization.get('caution', [])
            
            # Add EFSA data to each ingredient for consistency with existing structure
            efsa_data_cache = {}
            for category in [go_ingredients, no_go_ingredients, caution_ingredients]:
                for ingredient_data in category:
                    ingredient_name = ingredient_data.get('ingredient', '')
                    try:
                        efsa_data = fetch_efsa_openfoodtox_data(ingredient_name)
                        efsa_data_cache[ingredient_name] = efsa_data or {}
                        ingredient_data['efsa_data'] = efsa_data or {}
                    except Exception as e:
                        print(f"EFSA error for {ingredient_name}: {e}")
                        efsa_data_cache[ingredient_name] = {
                            'found': False,
                            'error': f'EFSA query failed: {str(e)}',
                            'source': 'EFSA OpenFoodTox Database'
                        }
                        ingredient_data['efsa_data'] = efsa_data_cache[ingredient_name]
            
            # Determine overall safety status
            if no_go_ingredients:
                safety_status = "UNSAFE"
            elif caution_ingredients:
                safety_status = "CAUTION"
            else:
                safety_status = "SAFE"
            
            return safety_status, go_ingredients, caution_ingredients, no_go_ingredients, efsa_data_cache
            
        except Exception as e:
            print(f"OpenAI categorization failed: {e}")
            # Fallback to basic categorization
            fallback_result = self._fallback_categorization(user, ingredients_list)
            
            go_ingredients = fallback_result.get('go', [])
            no_go_ingredients = fallback_result.get('no_go', [])
            caution_ingredients = fallback_result.get('caution', [])
            
            # Add empty EFSA data for fallback
            efsa_data_cache = {}
            for category in [go_ingredients, no_go_ingredients, caution_ingredients]:
                for ingredient_data in category:
                    ingredient_data['efsa_data'] = {}
            
            # Determine overall safety status
            if no_go_ingredients:
                safety_status = "UNSAFE"
            elif caution_ingredients:
                safety_status = "CAUTION"
            else:
                safety_status = "SAFE"
            
            return safety_status, go_ingredients, caution_ingredients, no_go_ingredients, efsa_data_cache

    def get_ai_health_insight_and_expert_advice_enhanced(self, user, nutrition_data, flagged_ingredients):
        """
        Enhanced AI Health Insights - ChatGPT 4.0 Quality
        Implements condition-specific flagging, weighted scoring transparency, and expert insights with citations
        """
        print(f" Starting enhanced AI analysis for user: {user.email}")
        print(f" User health conditions: {user.Health_conditions}")
        print(f" User allergies: {user.Allergies}")
        print(f" User dietary preferences: {user.Dietary_preferences}")
        print(f" Nutrition data: {nutrition_data}")
        print(f" Ingredients: {flagged_ingredients}")
        
        # Fast, reliable enhanced analysis without complex processing
        try:
            # Dynamic analysis based on user profile and nutrition data
            user_conditions = user.Health_conditions or ""
            user_allergies = user.Allergies or ""
            user_diet = user.Dietary_preferences or ""
            
            # Extract nutrition values dynamically
            sugar_content = 0
            sodium_content = 0
            calories = 0
            
            if nutrition_data:
                if 'Sugars' in nutrition_data:
                    try:
                        sugar_value = nutrition_data['Sugars'].replace('g', '').strip()
                        sugar_content = float(sugar_value)
                    except:
                        sugar_content = 0
                
                if 'Sodium' in nutrition_data:
                    try:
                        sodium_value = nutrition_data['Sodium'].replace('g', '').strip()
                        sodium_content = float(sodium_value)
                    except:
                        sodium_content = 0
                
                if 'Calories' in nutrition_data:
                    try:
                        calories_value = nutrition_data['Calories'].replace('kcal', '').strip()
                        calories = float(calories_value)
                    except:
                        calories = 0
            
            print(f" Extracted values - Sugar: {sugar_content}g, Sodium: {sodium_content}g, Calories: {calories}kcal")
            
            # Create dynamic condition-specific flags based on user profile
            condition_flags = []
            
            # Check for diabetes-related concerns
            if "diabetes" in user_conditions.lower() and sugar_content > 5:
                condition_flags.append({
                    "ingredient": "SUGAR",
                    "condition": "Diabetes Management",
                    "severity": "High" if sugar_content > 10 else "Moderate",
                    "reason": f"High sugar content ({sugar_content}g) may cause blood glucose spikes for diabetes patients",
                    "data_source": "WHO Guidelines",
                    "risk_category": "Digestive"
                })
            
            # Check for hypertension concerns
            if "hypertension" in user_conditions.lower() and sodium_content > 0.1:
                condition_flags.append({
                    "ingredient": "SODIUM",
                    "condition": "Hypertension Management",
                    "severity": "High" if sodium_content > 0.2 else "Moderate",
                    "reason": f"High sodium content ({sodium_content}g) may increase blood pressure",
                    "data_source": "FDA Guidelines",
                    "risk_category": "Cardiovascular"
                })
            
            # Check for cholesterol concerns
            if "cholesterol" in user_conditions.lower() and calories > 150:
                condition_flags.append({
                    "ingredient": "HIGH CALORIES",
                    "condition": "Cholesterol Management",
                    "severity": "Moderate",
                    "reason": f"High calorie content ({calories}kcal) may affect cholesterol levels",
                    "data_source": "EFSA Guidelines",
                    "risk_category": "Cardiovascular"
                })
            
            # Check for allergen concerns
            allergen_ingredients = []
            if user_allergies:
                allergies_list = [allergy.strip().lower() for allergy in user_allergies.split(',')]
                for ingredient in flagged_ingredients:
                    ingredient_lower = ingredient.lower()
                    for allergy in allergies_list:
                        if allergy in ingredient_lower:
                            allergen_ingredients.append(ingredient)
                            condition_flags.append({
                                "ingredient": ingredient.upper(),
                                "condition": f"{allergy.upper()} Allergy",
                                "severity": "Critical",
                                "reason": f"Contains {allergy} which you are allergic to",
                                "data_source": "FDA Allergen Database",
                                "risk_category": "Allergen"
                            })
            
            # Create dynamic weighted scoring based on user profile
            allergen_score = len(allergen_ingredients) * 50  # High weight for allergens
            cardiovascular_score = 0
            digestive_score = 0
            
            if "diabetes" in user_conditions.lower():
                digestive_score = min(100, sugar_content * 10)
            if "hypertension" in user_conditions.lower():
                cardiovascular_score = min(100, sodium_content * 200)
            if "cholesterol" in user_conditions.lower():
                cardiovascular_score = max(cardiovascular_score, min(100, calories / 2))
            
            # Determine overall assessment
            if allergen_score > 0:
                overall_assessment = "NO-GO"
            elif digestive_score > 70 or cardiovascular_score > 70:
                overall_assessment = "CAUTION"
            else:
                overall_assessment = "SAFE"
            
            enhanced_analysis = {
                "overall_assessment": overall_assessment,
                "condition_specific_flags": condition_flags,
                "weighted_scoring": {
                    "allergen_score": allergen_score,
                    "autoimmune_score": 0,  # Can be expanded based on user conditions
                    "digestive_score": digestive_score,
                    "cardiovascular_score": cardiovascular_score,
                    "decision_logic": f"Analysis based on user conditions: {user_conditions}, allergies: {user_allergies}"
                },
                "expert_insights": {
                    "health_insight": f"Product analysis for user with {user_conditions} - {len(condition_flags)} concerns identified",
                    "expert_advice": f"Based on your {user_conditions} and {user_allergies}, consider alternatives with lower sugar/sodium content",
                    "citations": ["WHO Guidelines", "FDA Standards", "EFSA Database"],
                    "recommendations": [
                        "Monitor blood sugar levels" if "diabetes" in user_conditions.lower() else "",
                        "Watch sodium intake" if "hypertension" in user_conditions.lower() else "",
                        "Consider allergen-free alternatives" if user_allergies else ""
                    ]
                },
                "fodmap_analysis": {
                    "high_fodmap": [],
                    "moderate_fodmap": [],
                    "severity_level": "Low",
                    "ibs_recommendations": "Product appears low in FODMAPs"
                }
            }
            
            # Generate dynamic AI insights based on user profile
            ai_health_insight = f"Product analysis for {user_conditions} patient: {len(condition_flags)} health concerns identified"
            expert_advice = f"Based on your health profile ({user_conditions}, {user_allergies}), consider consulting with a healthcare provider for personalized dietary guidance"
            
            result = {
                "ai_health_insight": ai_health_insight, 
                "expert_advice": expert_advice,
                "enhanced_ai_analysis": enhanced_analysis,
                "condition_specific_flagging": condition_flags,
                "weighted_scoring": enhanced_analysis["weighted_scoring"],
                "expert_insights": enhanced_analysis["expert_insights"],
                "enhanced_analysis": True,
                "analysis_version": "4.0",
                "user_profile_analysis": {
                    "conditions_analyzed": user_conditions,
                    "allergies_checked": user_allergies,
                    "dietary_preferences": user_diet,
                    "total_concerns": len(condition_flags)
                }
            }
            
            print(f" Enhanced AI analysis result: {result}")
            return result
            
        except Exception as e:
            print(f" Enhanced AI analysis failed: {e}")
            import traceback
            traceback.print_exc()
            # Fallback to standard analysis
            return self.get_ai_health_insight_and_expert_advice(user, nutrition_data, flagged_ingredients)

    def optimize_analysis_performance(self, user, image_content, nutrition_data, ingredients_list):
        """
        Optimize analysis performance to achieve 2-3 second processing time
        """
        try:
            optimizer = PerformanceOptimizer()
            return optimizer.optimize_analysis_pipeline(
                user=user,
                image_content=image_content,
                nutrition_data=nutrition_data,
                ingredients_list=ingredients_list
            )
        except Exception as e:
            print(f"Performance optimization failed: {e}")
            # Fallback to standard processing
            return None

    def validate_scan_quality(self, image_content):
        """
        Validate scan quality before processing
        """
        try:
            scanner_optimizer = BarcodeScannerOptimizer()
            return scanner_optimizer.validate_scan_quality(image_content)
        except Exception as e:
            print(f"Scan quality validation failed: {e}")
            return {"quality_passed": True, "error": str(e)}

def patch(self, request):
        """
        Patch user data - Update image URL after scanning product
        """
        user = request.user
        try:
            # Get the product image URL from the request
            
            image_url = request.data.get('product_image')  # Fixed typo: was 'prodcuct_image'
            if not image_url:
                return Response({"error": "Product image URL is required"}, status=status.HTTP_400_BAD_REQUEST)
            
            # Clean the image URL by removing common URL prefixes and special characters
            cleaned_url = image_url.replace("https://", "")
            cleaned_url = cleaned_url.replace("http://", "")
            cleaned_url = cleaned_url.replace("https:", "")
            cleaned_url = cleaned_url.replace("http:", "")
            cleaned_url = cleaned_url.replace(":", "")
            cleaned_url = cleaned_url.replace("//", "")
            cleaned_url = cleaned_url.replace("www.", "")
            cleaned_url = cleaned_url.replace(".", "")
            cleaned_url = cleaned_url.replace("/", "")
            cleaned_url = cleaned_url.replace(" ", "")
            
            # Update user's image URL
            user.image_url = cleaned_url
            user.save()
            
            return Response({
                "message": "User image URL updated successfully",
                "image_url": cleaned_url
            }, status=status.HTTP_200_OK)
            
        except Exception as e:
            return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
        
class ExportDataView(APIView):
    """
    API endpoint for exporting user data and all food label scans when they click the download button.
    """
    # permission_classes = [IsAuthenticated]

    def get(self, request):
        """
        Export user model info and all food label scans in a downloadable JSON format
        """
        try:
            id = request.query_params.get('id')
            user = User.objects.get(id=id)
            
            # Get user data
            user_data = {
                "user_info": {
                    "id": user.id if user else None,
                    "email": user.email,
                    "full_name": user.full_name if user else None,
                    # "first_name": user.first_name,
                    # "last_name": user.last_name,
                    # "username": user.username,
                    "phone_number": user.phone_number if user else None,
                    "date_joined": user.date_joined.isoformat() if user.date_joined else None,
                    "created_at": user.created_at.isoformat() if user.created_at else None,
                    "is_active": user.is_active if user else None,
                    "is_2fa_enabled": user.is_2fa_enabled if user else None,
                    "is_terms_accepted": user.is_terms if user else None,
                    "has_answered_onboarding": user.has_answered_onboarding if user else None,
                    "dietary_preferences": user.Dietary_preferences if user else None,
                    "health_conditions": user.Health_conditions if user else None,
                    "allergies": user.Allergies if user else None,
                    "health_goals": user.Health_Goals if user else None,
                    "parental_status": user.Parental_status if user else None,
                    "family_health_awareness": user.Family_Health_Awareness if user else None,
                    "emotional_connection": user.Emotional_Conection if user else None,
                    "health_impact_awareness": user.Health_impact_awareness if user else None,
                    "desired_outcome": user.Desired_outcome if user else None,
                    "motivation": user.Motivation if user else None,
                    "notifications_enabled": user.notifications_enabled if user else None,
                    "dark_mode": user.dark_mode if user else None,
                    "language": user.language if user else None,
                    "privacy_settings_enabled": user.privacy_settings_enabled,
                    "loves_app": user.loves_app if user else None,
                    "subscription_plan": user.subscription_plan if user else None,
                    "social_login_id": user.social_login_id if user else None,
                    "social_login_type": user.social_login_type
                }
            }
            
            # Get all food label scans for the user
            food_label_scans = FoodLabelScan.objects.filter(user=user).order_by('-scanned_at')
            scans_data = []
            
            for scan in food_label_scans:
                scan_data = {
                    "scan_id": scan.id,
                    "product_name": scan.product_name,
                    "product_image_url": scan.product_image_url,
                    "image_url": scan.image_url,
                    "extracted_text": scan.extracted_text,
                    "nutrition_data": scan.nutrition_data,
                    "safety_status": scan.safety_status,
                    "flagged_ingredients": scan.flagged_ingredients,
                    "scanned_at": scan.scanned_at.isoformat(),
                    "is_favorite": scan.is_favorite
                }
                scans_data.append(scan_data)
            
            # Get onboarding questionnaire data
            onboarding_answers = OnboardingAnswer.objects.filter(user=user).select_related('question')
            onboarding_data = []
            
            for answer in onboarding_answers:
                question = answer.question
                choices = OnboardingChoice.objects.filter(question=question)
                
                question_data = {
                    "question_id": question.id,
                    "question_text": question.question_text,
                    "question_category": question.category,
                    "answer_type": question.answer_type,
                    "user_answer": answer.answer,
                    "answer_id": answer.id,
                    "available_choices": [{"id": choice.id, "choice_text": choice.choice_text} for choice in choices] if choices.exists() else [],
                    "answered_at": f"Answer ID: {answer.id}"  # Since there's no timestamp field
                }
                onboarding_data.append(question_data)
            
            # Combine user data and scans
            export_data = {
                "export_info": {
                    "exported_at": timezone.now().isoformat(),
                    "user_id": user.id,
                    "user_email": user.email,
                    "data_version": "1.0",
                    "app_name": "IngredientIQ",
                    "export_type": "user_data_and_scans"
                },
                "user_info": user_data["user_info"],
                "food_label_scans": scans_data,
                "onboarding_questionnaire": {
                    "has_answered_onboarding": user.has_answered_onboarding,
                    "total_questions_answered": len(onboarding_data),
                    "completion_status": "Complete" if len(onboarding_data) > 0 else "Not started",
                    "questions_and_answers": onboarding_data,
                    "summary": {
                        "categories_covered": list(set([qa["question_category"] for qa in onboarding_data])),
                        "answer_types": list(set([qa["answer_type"] for qa in onboarding_data])),
                        "total_questions_available": OnboardingQuestion.objects.count()
                    }
                },
                "summary": {
                    "total_scans": len(scans_data),
                    "favorite_scans_count": len([scan for scan in scans_data if scan["is_favorite"]]),
                    "total_onboarding_questions_answered": len(onboarding_data),
                    "account_age_days": (timezone.now() - user.date_joined).days if user.date_joined else 0,
                    "last_scan_date": scans_data[0]["scanned_at"] if scans_data else None
                }
            }
            
            # Check if this is a file download request or regular API response
            accept_header = request.META.get('HTTP_ACCEPT', '')
            user_agent = request.META.get('HTTP_USER_AGENT', '')
            download_param = request.GET.get('download', '').lower()
            
            # If it's Postman, browser requesting JSON, or download=false, return regular JSON response
            if ('postman' in user_agent.lower() or 
                'application/json' in accept_header or 
                download_param == 'false'):
                return Response(export_data, status=status.HTTP_200_OK)
            else:
                # Create response with proper headers for file download
                response = HttpResponse(
                    json.dumps(export_data, indent=2, ensure_ascii=False),
                    content_type='application/json'
                )
                response['Content-Disposition'] = f'attachment; filename="foodapp_user_data_{user.email}_{timezone.now().strftime("%Y%m%d_%H%M%S")}.json"'
                response['Content-Length'] = len(json.dumps(export_data, indent=2, ensure_ascii=False))
                
                return response
            
        except Exception as e:
            logging.error(f"Error exporting user data: {e}")
            return Response(
                {"error": "Failed to export user data. Please try again later."},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )


def cancel_deletion_request_on_login(user):
    """
    Cancel account deletion request when user logs in (for premium users)
    This should be called from the login view
    Returns: dict with cancellation info
    """
    try:
        deletion_request = AccountDeletionRequest.objects.get(user=user, status='pending')
        deletion_request.status = 'cancelled'
        deletion_request.cancelled_at = timezone.now()
        deletion_request.save()
        return {
            'cancelled': True,
            'scheduled_date': deletion_request.scheduled_deletion_date,
            'days_remaining': deletion_request.days_remaining
        }
    except AccountDeletionRequest.DoesNotExist:
        return {'cancelled': False}


def safe_delete_user(user):
    """
    Safely delete a user account, handling all foreign key constraints
    """
    try:
        # Delete any existing deletion request first to avoid foreign key constraints
        try:
            deletion_request = AccountDeletionRequest.objects.get(user=user)
            deletion_request.delete()
        except AccountDeletionRequest.DoesNotExist:
            pass
        
        # Delete the user (this will cascade delete all related objects)
        user.delete()
        return True, "User deleted successfully"
    except Exception as e:
        return False, f"Error deleting user: {str(e)}"


class NotificationToggleView(APIView):
    """
    API to toggle subscription notifications on/off
    When disabled, no subscription-related notifications will be sent
    """
    permission_classes = [IsAuthenticated]
    
    def get(self, request):
        """Get current notification toggle status"""
        serializer = NotificationToggleSerializer(request.user)
        return Response({
            'subscription_notifications_enabled': request.user.subscription_notifications_enabled,
            'message': 'Current subscription notification status retrieved'
        }, status=status.HTTP_200_OK)
    
    def patch(self, request):
        """Toggle subscription notifications on/off"""
        serializer = NotificationToggleSerializer(
            request.user, 
            data=request.data, 
            partial=True
        )
        
        if serializer.is_valid():
            serializer.save()
            status_text = "enabled" if request.user.subscription_notifications_enabled else "disabled"
            return Response({
                'subscription_notifications_enabled': request.user.subscription_notifications_enabled,
                'message': f'Subscription notifications {status_text} successfully'
            }, status=status.HTTP_200_OK)
        else:
            return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)   
        
class DownloadRequestView(APIView):
    """
    API to request data export
    """
    permission_classes = []
    
    def post(self, request):
        """Request data export"""
        # serializer = DownloadRequestSerializer(data=request.data)
        name = request.data.get('name')
        email = request.data.get('email')
        if not name or not email:
            return Response({'error': 'Name and email are required'}, status=status.HTTP_400_BAD_REQUEST)
        downloadpdf = DownloadRequest.objects.create(name=name, email=email)
        return Response({'message': 'Download request created successfully'}, status=status.HTTP_200_OK)

    def get(self, request):
        downloadpdf = DownloadRequest.objects.all()
        data = []
        for pdf in downloadpdf:
            data.append({
                'id': pdf.id,
                'name': pdf.name,
                'email': pdf.email,
                'created_at': pdf.created_at,
                'updated_at': pdf.updated_at
            })
        return Response({'downloadrequest': data},status=status.HTTP_200_OK)
